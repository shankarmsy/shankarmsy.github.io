<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet type="text/xsl" href="assets/xml/rss.xsl" media="all"?><rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Shankar's Data Science Blog</title><link>https://shankarmsy.github.io/</link><description>musings and ramblings on Data Science &amp; more</description><atom:link href="https://shankarmsy.github.io/rss.xml" type="application/rss+xml" rel="self"></atom:link><language>en</language><lastBuildDate>Sun, 11 Jan 2015 15:50:00 GMT</lastBuildDate><generator>http://getnikola.com/</generator><docs>http://blogs.law.harvard.edu/tech/rss</docs><item><title>Visually differentiating PCA and Linear Regression</title><link>https://shankarmsy.github.io/posts/pca-vs-lr.html</link><dc:creator>Shankar Muthuswamy</dc:creator><description>&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;I've always been fascinated by the concept of PCA. Considering its wide range of applications and how inherently mathematical the idea is, I feel PCA is one of the pillars of the intersection between Pure Mathematics and Real-world analytics. Besides, the fact that you could think about real data as just raw numbers and then transform it down to something you can visualize and relate to, is extremely powerful and essential in any learning process.&lt;/p&gt;
&lt;p&gt;Just in case you're wondering, Principle Component Analysis (PCA) simply put is a dimensionality reduction technique that can find the combinations of variables that explain the most variance. So you can transform a 1000-feature dataset into 2D so you can visualize it in a plot or you could bring it down to x features where x&amp;lt;&amp;lt;1000 while preserving most of the variance in the data. I've previously explored &lt;a href="https://shankarmsy.github.io/posts/pca-sklearn.html"&gt;Facial image compression and reconstruction using PCA&lt;/a&gt; using scikit-learn.&lt;/p&gt;
&lt;p&gt;In this post I would like to delve into the concept of linearity in Principal Component Analysis.&lt;/p&gt;&lt;p&gt;&lt;a href="https://shankarmsy.github.io/posts/pca-vs-lr.html"&gt;Read more…&lt;/a&gt; (6 min remaining to read)&lt;/p&gt;&lt;/div&gt;</description><category>dimensionality reduction</category><category>image compression</category><category>linear regression</category><category>pca</category><category>scikit-learn</category><category>unsupervised learning</category><guid>https://shankarmsy.github.io/posts/pca-vs-lr.html</guid><pubDate>Fri, 12 Dec 2014 17:01:00 GMT</pubDate></item><item><title>Predicting Forest Cover Types with Ensemble Learning</title><link>https://shankarmsy.github.io/posts/forest-cover-types.html</link><dc:creator>Shankar Muthuswamy</dc:creator><description>&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;This is a documentation of one of my approaches to solving the forest cover type prediction challenge hosted by Kaggle. Feel free to use for your own reference and let me know if you have any suggestions on how I can improve the model :-)&lt;/p&gt;
&lt;p&gt;I found this topic very engaging being a nature lover. Also the features are very friendly and don't require much domain knowledge to explore (and hopefully engineer new features).&lt;/p&gt;
&lt;p&gt;OK let's get started.&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="https://shankarmsy.github.io/posts/forest-cover-types.html"&gt;Read more…&lt;/a&gt; (30 min remaining to read)&lt;/p&gt;&lt;/div&gt;</description><category>blending</category><category>ensemble</category><category>extra trees</category><category>random forests</category><category>scikit-learn</category><category>supervised learning</category><guid>https://shankarmsy.github.io/posts/forest-cover-types.html</guid><pubDate>Tue, 02 Dec 2014 12:15:33 GMT</pubDate></item><item><title>Saving the Titanic with R &amp; IPython</title><link>https://shankarmsy.github.io/posts/saving-titanic-r.html</link><dc:creator>Shankar Muthuswamy</dc:creator><description>&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;The following is an illustration of one of my approaches to solving the Titanic Survival prediction challenge hosted by Kaggle. Below is an excerpt from the competition page.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;The sinking of the RMS Titanic is one of the most infamous shipwrecks in history. On April 15, 1912, during her maiden voyage, the Titanic sank after colliding with an iceberg, killing 1502 out of 2224 passengers and crew. This sensational tragedy shocked the international community and led to better safety regulations for ships.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;a href="https://shankarmsy.github.io/posts/saving-titanic-r.html"&gt;Read more…&lt;/a&gt; (55 min remaining to read)&lt;/p&gt;&lt;/div&gt;</description><category>R</category><category>conditional trees</category><category>kaggle</category><category>logistic regression</category><category>random forests</category><category>scikit-learn</category><category>supervised learning</category><category>svm</category><category>titanic</category><guid>https://shankarmsy.github.io/posts/saving-titanic-r.html</guid><pubDate>Sun, 23 Nov 2014 10:11:09 GMT</pubDate></item><item><title>Recognizing Hand Written Digits (UCI ML Repo) with Support Vector Machines (SVM)</title><link>https://shankarmsy.github.io/posts/svm-sklearn.html</link><dc:creator>Shankar Muthuswamy</dc:creator><description>&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;Support Vector Machines (SVMs) are a powerful supervised learning algorithm used for &lt;strong&gt;classification&lt;/strong&gt; or for &lt;strong&gt;regression&lt;/strong&gt;. SVMs are a &lt;strong&gt;discriminative&lt;/strong&gt; classifier: that is, they draw a boundary between clusters of data. In this post I will demonstrate hand-written digit recognition using the SVC classifier in scikit-learn. We'll make use of the online dataset available in the UCI machine learning repository.&lt;/p&gt;
&lt;p&gt;&lt;a href="https://shankarmsy.github.io/posts/svm-sklearn.html"&gt;Read more…&lt;/a&gt; (10 min remaining to read)&lt;/p&gt;&lt;/div&gt;</description><category>digit recognition</category><category>scikit-learn</category><category>supervised learning</category><category>svm</category><guid>https://shankarmsy.github.io/posts/svm-sklearn.html</guid><pubDate>Wed, 19 Nov 2014 09:00:03 GMT</pubDate></item><item><title>Data Munging with Pandas (Advanced)</title><link>https://shankarmsy.github.io/posts/munging-pandas.html</link><dc:creator>Shankar Muthuswamy</dc:creator><description>&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;Pandas is a Python library for doing data analysis. It's really fast and lets you do exploratory work incredibly quickly.&lt;/p&gt;
&lt;p&gt;In this post I will demonstrate some advanced data munging/wrangling concepts with the awesome Pandas. I intend to code more and write less but will add help text as much as possible. Check out the pandas help documentation to learn more.&lt;/p&gt;
&lt;p&gt;OK, let's get started. &lt;/p&gt;&lt;p&gt;&lt;a href="https://shankarmsy.github.io/posts/munging-pandas.html"&gt;Read more…&lt;/a&gt; (17 min remaining to read)&lt;/p&gt;&lt;/div&gt;</description><category>data munging</category><category>pandas</category><category>python</category><category>scikit-learn</category><guid>https://shankarmsy.github.io/posts/munging-pandas.html</guid><pubDate>Mon, 17 Nov 2014 10:03:44 GMT</pubDate></item><item><title>Facial Image Compression and Reconstruction with PCA</title><link>https://shankarmsy.github.io/posts/pca-sklearn.html</link><dc:creator>Shankar Muthuswamy</dc:creator><description>&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;Principle Component Analysis (PCA) is a dimension reduction technique that can find the combinations of variables that explain the most variance. In this post I will demonstrate dimensionality reduction concepts including facial image compression and reconstruction using PCA.&lt;/p&gt;
&lt;p&gt;Let's get started. &lt;/p&gt;&lt;p&gt;&lt;a href="https://shankarmsy.github.io/posts/pca-sklearn.html"&gt;Read more…&lt;/a&gt; (8 min remaining to read)&lt;/p&gt;&lt;/div&gt;</description><category>dimensionality reduction</category><category>image compression</category><category>pca</category><category>scikit-learn</category><category>unsupervised learning</category><guid>https://shankarmsy.github.io/posts/pca-sklearn.html</guid><pubDate>Wed, 12 Nov 2014 18:04:24 GMT</pubDate></item><item><title>Dive-in to Pandas (Basic)</title><link>https://shankarmsy.github.io/posts/dive-in-pandas.html</link><dc:creator>Shankar Muthuswamy</dc:creator><description>&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;Pandas is a Python library for doing data analysis. It's really fast and lets you do exploratory work incredibly quickly.&lt;/p&gt;
&lt;p&gt;It provides an R-like DataFrame, produces high quality plots with matplotlib, and integrates nicely with other libraries that expect NumPy arrays. In this post, I'll go through the basics of pandas. Check out the (very readable) pandas docs or the pandas cookbook if you want to learn more.&lt;/p&gt;
&lt;p&gt;OK, let's get started.&lt;/p&gt;
&lt;p&gt;&lt;a href="https://shankarmsy.github.io/posts/dive-in-pandas.html"&gt;Read more…&lt;/a&gt; (11 min remaining to read)&lt;/p&gt;&lt;/div&gt;</description><category>data munging</category><category>pandas</category><category>python</category><category>scikit-learn</category><guid>https://shankarmsy.github.io/posts/dive-in-pandas.html</guid><pubDate>Wed, 05 Nov 2014 09:36:11 GMT</pubDate></item><item><title>Why I want to be a Data Scientist</title><link>https://shankarmsy.github.io/posts/why-data-scientist.html</link><dc:creator>Shankar Muthuswamy</dc:creator><description>&lt;div&gt;&lt;p&gt;After having completed my Bachelors in Computer Science &amp;amp; Engineering, I was drawn to the deep waters of IT and then onto the even deeper chasm of Consulting. For over 12 years I did consulting work in Business Intelligence and did it fairly well to make a career out of it. I had the opportunity to travel, work and meet great interesting people and more importantly had a good learning curve.&lt;/p&gt;
&lt;p&gt;Learning is key because it instills hope.&lt;/p&gt;&lt;p&gt;&lt;a href="https://shankarmsy.github.io/posts/why-data-scientist.html"&gt;Read more…&lt;/a&gt; (2 min remaining to read)&lt;/p&gt;&lt;/div&gt;</description><category>blogging</category><category>data science</category><category>fundamentals</category><guid>https://shankarmsy.github.io/posts/why-data-scientist.html</guid><pubDate>Wed, 24 Sep 2014 18:21:49 GMT</pubDate></item><item><title>Blogging with the awesome Nikola, IPython and Github</title><link>https://shankarmsy.github.io/posts/blogging-with-the-awesome-nikola-ipython-and-github.html</link><dc:creator>Shankar Muthuswamy</dc:creator><description>&lt;div&gt;&lt;p&gt;So glad to finally be writing my first post with &lt;a href="https://www.getnikola.com"&gt;&lt;strong&gt;Nikola&lt;/strong&gt;&lt;/a&gt;. It truly provides an awesome, fun way of setting up a static website/blog and gives you complete control every step of the way. It took me a while to get this setup working but boy am I pleased with the results. It's written completely in Python, is blazingly fast, features an &lt;strong&gt;IPython&lt;/strong&gt; plugin that lets you create and share IPython content directly and deploys easily to &lt;strong&gt;Github&lt;/strong&gt;, giving you version control for your blog. Everything is 100% customizable and to top it off, is completely free. &lt;em&gt;Can it get any better?&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;So without further ado, below I will attempt explain the steps I followed to successfully set up a site with Nikola, configure the IPython plugin for Nikola and setup a Github page to deploy the website. Before I begin, a quick disclaimer. These are steps that worked well for me and I hope will help you too. But I would recommend you take a look at &lt;a href="http://www.damian.oquanta.info/index.html"&gt;Damian Avila's blog posts&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Let's get started.
&lt;/p&gt;&lt;p&gt;&lt;a href="https://shankarmsy.github.io/posts/blogging-with-the-awesome-nikola-ipython-and-github.html"&gt;Read more…&lt;/a&gt; (10 min remaining to read)&lt;/p&gt;&lt;/div&gt;</description><category>IPython</category><category>blogging</category><category>github</category><category>nikola</category><category>octopress</category><category>tutorial</category><guid>https://shankarmsy.github.io/posts/blogging-with-the-awesome-nikola-ipython-and-github.html</guid><pubDate>Tue, 23 Sep 2014 09:57:19 GMT</pubDate></item></channel></rss>