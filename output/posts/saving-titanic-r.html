<!DOCTYPE html>
<html prefix="
og: http://ogp.me/ns#
article: http://ogp.me/ns/article#
" lang="en">
    <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>Saving the Titanic with R | Shankar Muthuswamy</title>

                <link href="../assets/css/all-nocdn.css" rel="stylesheet" type="text/css">

                <link rel="alternate" type="application/rss+xml" title="RSS" href="../rss.xml">

      <link rel="canonical" href="https://shankarmsy.github.io/posts/saving-titanic-r.html">




    
        <!--[if lt IE 9]><script src="../assets/js/html5.js"></script><![endif]-->

    

    
    <meta name="author" content="Shankar Muthuswamy">
        <meta property="og:site_name" content="Shankar Muthuswamy">
    <meta property="og:title" content="Saving the Titanic with R">
    <meta property="og:url" content="https://shankarmsy.github.io/posts/saving-titanic-r.html">
    <meta property="og:description" content="The following is an illustration of one of my approaches to solving the Titanic Survival prediction challenge hosted by Kaggle. Below is an excerpt from the competition page.

The sinking of the RMS T">
    <meta property="og:type" content="article">
    <meta property="article:published_time" content="2014-11-23T02:11:09-08:00">

    
    

</head>
<body>
<a href="#content" class="sr-only sr-only-focusable">Skip to main content</a>

<!-- Menubar -->

<nav class="navbar navbar-inverse navbar-fixed-top" role="navigation">
    <div class="container">
<!-- This keeps the margins nice -->
        <div class="navbar-header">
            <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".navbar-ex1-collapse">
            <span class="sr-only">Toggle navigation</span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
            </button>
            <a class="navbar-brand" href="https://shankarmsy.github.io/">

                <span id="blog-title">Shankar Muthuswamy</span>
            </a>
        </div>
<!-- /.navbar-header -->
        <div class="collapse navbar-collapse navbar-ex1-collapse">
            <ul class="nav navbar-nav">
                                <li>
<a href="../archive.html">Archive</a>
                </li>
<li>
<a href="../categories/index.html">Tags</a>
                </li>
<li>
<a href="../stories/projects.html">Projects</a>
            </li>
<li class="dropdown">
<a href="#" class="dropdown-toggle" data-toggle="dropdown">About<b class="caret"></b></a>
            <ul class="dropdown-menu">
                    <li>
<a href="../stories/intro.html">Intro</a>
                    </li>
<li>
<a href="../stories/background.html">Background</a>
            </li>
</ul>

                
            </li>
</ul>

            <ul class="nav navbar-nav navbar-right">
    <li>
    <a href="saving-titanic-r.ipynb" id="sourcelink">Source</a>
    </li>
                
            </ul>
        </div>
<!-- /.navbar-collapse -->
    </div>
<!-- /.container -->
</nav>

<!-- End of Menubar -->

<div class="container" id="content">
    <div class="body-content">
        <!--Body content-->
        <div class="row">
            
<article class="post-text h-entry hentry postpage" itemscope="itemscope" itemtype="http://schema.org/Article">
        <header>
            <h1 class="p-name entry-title" itemprop="headline name"><a href="#" class="u-url">Saving the Titanic with R</a></h1>

        <div class="metadata">
            <p class="byline author vcard"><span class="byline-name fn">Shankar Muthuswamy</span></p>
            <p class="dateline"><a href="#" rel="bookmark"><time class="published dt-published" datetime="2014-11-23T02:11:09-08:00" itemprop="datePublished" title="2014-11-23 02:11">2014-11-23 02:11</time></a></p>
                <p class="commentline">            <a href="saving-titanic-r.html#disqus_thread" data-disqus-identifier="cache/posts/saving-titanic-r.html">Comments</a>


                    </p>
<p class="sourceline"><a href="saving-titanic-r.ipynb" id="sourcelink">Source</a></p>

        </div>
        
    </header>

    <div class="e-content entry-content" itemprop="articleBody text">
    <div>
<div class="text_cell_render border-box-sizing rendered_html">
<p>The following is an illustration of one of my approaches to solving the Titanic Survival prediction challenge hosted by Kaggle. Below is an excerpt from the competition page.</p>
<blockquote>
<p>The sinking of the RMS Titanic is one of the most infamous shipwrecks in history. On April 15, 1912, during her maiden voyage, the Titanic sank after colliding with an iceberg, killing 1502 out of 2224 passengers and crew. This sensational tragedy shocked the international community and led to better safety regulations for ships.</p>
</blockquote>
<!-- TEASER_END -->  
<blockquote>
<p>One of the reasons that the shipwreck led to such loss of life was that there were not enough lifeboats for the passengers and crew. Although there was some element of luck involved in surviving the sinking, some groups of people were more likely to survive than others, such as women, children, and the upper-class.</p>
<p>In this challenge, we ask you to complete the analysis of what sorts of people were likely to survive. In particular, we ask you to apply the tools of machine learning to predict which passengers survived the tragedy.</p>
</blockquote>
<p><em>Disclaimer</em><br>This pursuit infuses my own ideas with others I've had the privilege to learn from. I write to further my learning.</p>
<p>To get started, download the data files from Kaggle's website <a href="http://www.kaggle.com/c/titanic-gettingStarted/data">here</a>. You will see two CSV files, train and test. Download them to your working directory.</p>
</div>
<div class="text_cell_render border-box-sizing rendered_html">
<p>OK let's now take a look at the column descriptions provided for the dataset.</p>
<pre><code>VARIABLE DESCRIPTIONS:
survival        Survival
                (0 = No; 1 = Yes)
pclass          Passenger Class
                (1 = 1st; 2 = 2nd; 3 = 3rd)
name            Name
sex             Sex
age             Age
sibsp           Number of Siblings/Spouses Aboard
parch           Number of Parents/Children Aboard
ticket          Ticket Number
fare            Passenger Fare
cabin           Cabin
embarked        Port of Embarkation
                (C = Cherbourg; Q = Queenstown; S = Southampton)

SPECIAL NOTES:
Pclass is a proxy for socio-economic status (SES)
 1st ~ Upper; 2nd ~ Middle; 3rd ~ Lower

Age is in Years; Fractional if Age less than One (1)
 If the Age is Estimated, it is in the form xx.5

With respect to the family relation variables (i.e. sibsp and parch)
some relations were ignored.  The following are the definitions used
for sibsp and parch.

Sibling:  Brother, Sister, Stepbrother, or Stepsister of Passenger Aboard Titanic
Spouse:   Husband or Wife of Passenger Aboard Titanic (Mistresses and Fiances Ignored)
Parent:   Mother or Father of Passenger Aboard Titanic
Child:    Son, Daughter, Stepson, or Stepdaughter of Passenger Aboard Titanic

Other family relatives excluded from this study include cousins,
nephews/nieces, aunts/uncles, and in-laws.  Some children travelled
only with a nanny, therefore parch=0 for them.  As well, some
travelled with very close friends or neighbors in a village, however,
the definitions do not support such relations.</code></pre>
<p>Bottomline, we have some information about passengers traveling aboard the Titanic and we need to predict if train a model that can predict if one survived or not based on data similar to that provided in the dataset. Without further ado, let's get started.</p>
</div>
<div class="cell border-box-sizing code_cell vbox">
<div class="input hbox">
<div class="prompt input_prompt">
In [1]:
</div>
<div class="input_area box-flex1">
<div class="highlight"><pre><span class="c">#Load the R Magic so we can execute R scripts within this notebook</span>
<span class="o">%</span><span class="k">load_ext</span> <span class="n">rmagic</span>
</pre></div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell vbox">
<div class="input hbox">
<div class="prompt input_prompt">
In [2]:
</div>
<div class="input_area box-flex1">
<div class="highlight"><pre><span class="o">%%</span><span class="k">R</span>
<span class="c">#Note that every code block in this notebook will need to have the above line to enable IPython to understand we're coding R.</span>

<span class="c">#I've downloaded the train and test CSV files to my work directory. You should too unless you cloned this repo.</span>
<span class="c">#While downloading the CSV files in R, let's do some data handling so it saves us the headache later on.</span>

<span class="c">#Define a read function so we don't need to do it twice. Column types specifies data types for each column and missing</span>
<span class="c">#types specify different types of null values possible.</span>
<span class="n">read_better</span> <span class="o">&lt;-</span> <span class="n">function</span><span class="p">(</span><span class="nb">file</span><span class="o">.</span><span class="n">name</span><span class="p">,</span> <span class="n">column</span><span class="o">.</span><span class="n">types</span><span class="p">,</span> <span class="n">missing</span><span class="o">.</span><span class="n">types</span><span class="p">)</span> <span class="p">{</span>
  <span class="n">read</span><span class="o">.</span><span class="n">csv</span><span class="p">(</span> <span class="nb">file</span><span class="o">.</span><span class="n">name</span><span class="p">,</span> 
            <span class="n">colClasses</span><span class="o">=</span><span class="n">column</span><span class="o">.</span><span class="n">types</span><span class="p">,</span>
            <span class="n">na</span><span class="o">.</span><span class="n">strings</span><span class="o">=</span><span class="n">missing</span><span class="o">.</span><span class="n">types</span> <span class="p">)</span>
<span class="p">}</span>

<span class="c">#Let's now define the column types</span>
<span class="n">column</span><span class="o">.</span><span class="n">types</span><span class="o">=</span><span class="n">c</span><span class="p">(</span><span class="s">'integer'</span><span class="p">,</span>   <span class="c"># PassengerId</span>
               <span class="s">'factor'</span><span class="p">,</span>    <span class="c"># Survived </span>
               <span class="s">'factor'</span><span class="p">,</span>    <span class="c"># Pclass</span>
               <span class="s">'character'</span><span class="p">,</span> <span class="c"># Name</span>
               <span class="s">'factor'</span><span class="p">,</span>    <span class="c"># Sex</span>
               <span class="s">'numeric'</span><span class="p">,</span>   <span class="c"># Age</span>
               <span class="s">'integer'</span><span class="p">,</span>   <span class="c"># SibSp</span>
               <span class="s">'integer'</span><span class="p">,</span>   <span class="c"># Parch</span>
               <span class="s">'character'</span><span class="p">,</span> <span class="c"># Ticket</span>
               <span class="s">'numeric'</span><span class="p">,</span>   <span class="c"># Fare</span>
               <span class="s">'character'</span><span class="p">,</span> <span class="c"># Cabin</span>
               <span class="s">'factor'</span><span class="p">)</span>    <span class="c"># Embarked</span>
<span class="c">#Different types of null values</span>
<span class="n">missing</span><span class="o">.</span><span class="n">types</span><span class="o">=</span><span class="n">c</span><span class="p">(</span><span class="s">'NA'</span><span class="p">,</span><span class="s">''</span><span class="p">)</span> 

<span class="c">#Alright,let's read train</span>
<span class="n">orig_train</span><span class="o">&lt;-</span><span class="n">read_better</span><span class="p">(</span><span class="s">'train.csv'</span><span class="p">,</span> <span class="n">column</span><span class="o">.</span><span class="n">types</span><span class="p">,</span> <span class="n">missing</span><span class="o">.</span><span class="n">types</span><span class="p">)</span>

<span class="c">#For test, the Survived column (2nd col) doesn't exist, let's remove that type before reading.</span>
<span class="n">orig_test</span><span class="o">&lt;-</span><span class="n">read_better</span><span class="p">(</span><span class="s">'test.csv'</span><span class="p">,</span> <span class="n">column</span><span class="o">.</span><span class="n">types</span><span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">],</span> <span class="n">missing</span><span class="o">.</span><span class="n">types</span><span class="p">)</span>

<span class="c">#Let's make copies so we never have to read again</span>
<span class="n">train</span><span class="o">&lt;-</span><span class="n">orig_train</span>
<span class="n">test</span><span class="o">&lt;-</span><span class="n">orig_test</span>

<span class="c">#Quickly print a summary of train</span>
<span class="n">summary</span><span class="p">(</span><span class="n">train</span><span class="p">)</span>
</pre></div>

</div>
</div>

<div class="vbox output_wrapper">
<div class="output vbox">


<div class="hbox output_area">
<div class="prompt"></div>
<div class="box-flex1 output_subarea output_display_data">


<pre>
  PassengerId    Survived Pclass      Name               Sex     
 Min.   :  1.0   0:549    1:216   Length:891         female:314  
 1st Qu.:223.5   1:342    2:184   Class :character   male  :577  
 Median :446.0            3:491   Mode  :character               
 Mean   :446.0                                                   
 3rd Qu.:668.5                                                   
 Max.   :891.0                                                   
                                                                 
      Age            SibSp           Parch           Ticket         
 Min.   : 0.42   Min.   :0.000   Min.   :0.0000   Length:891        
 1st Qu.:20.12   1st Qu.:0.000   1st Qu.:0.0000   Class :character  
 Median :28.00   Median :0.000   Median :0.0000   Mode  :character  
 Mean   :29.70   Mean   :0.523   Mean   :0.3816                     
 3rd Qu.:38.00   3rd Qu.:1.000   3rd Qu.:0.0000                     
 Max.   :80.00   Max.   :8.000   Max.   :6.0000                     
 NA's   :177                                                        
      Fare           Cabin           Embarked  
 Min.   :  0.00   Length:891         C   :168  
 1st Qu.:  7.91   Class :character   Q   : 77  
 Median : 14.45   Mode  :character   S   :644  
 Mean   : 32.20                      NA's:  2  
 3rd Qu.: 31.00                                
 Max.   :512.33                                
                                               

</pre>

</div>
</div>

</div>
</div>

</div>
<div class="text_cell_render border-box-sizing rendered_html">
<h4 id="data-munging">Data Munging</h4>
<p>Munging is essentially cleansing the data so it's ready for our super sophisticated Machine Learning algorithms :-)</p>
<p>Ideally I'd like to use Pandas which is an awesome tool for these types of things but considering Pandas itself was inspired from R, we will try the whole thing in R this time. I'll create a seperate notebook later to do it all in sklearn/pandas.</p>
<p>Alright let's get started. The first step of any Data Cleansing process is Visualization. Why is that? I asked the question myself but how would you cleanse something when you don't know what it is? And what better way to understand data than by looking at in colourful visualizations. Let's go and create some.</p>
</div>
<div class="cell border-box-sizing code_cell vbox">
<div class="input hbox">
<div class="prompt input_prompt">
In [3]:
</div>
<div class="input_area box-flex1">
<div class="highlight"><pre><span class="o">%%</span><span class="k">R</span>
<span class="c">#I loved the look of this R package that provides the missing map which can give you a super quick peek into the dataset.</span>
<span class="c">#You'll need the Amelia package for this visualization.</span>

<span class="c">#install.packages("Amelia")</span>
<span class="n">require</span><span class="p">(</span><span class="n">Amelia</span><span class="p">)</span>
<span class="n">missmap</span><span class="p">(</span><span class="n">train</span><span class="p">,</span> <span class="n">main</span><span class="o">=</span><span class="s">"Titanic - Missing Data Map"</span><span class="p">,</span> <span class="n">col</span><span class="o">=</span><span class="n">c</span><span class="p">(</span><span class="s">"forestgreen"</span><span class="p">,</span><span class="s">"lightskyblue2"</span><span class="p">),</span> <span class="n">legend</span><span class="o">=</span><span class="n">FALSE</span><span class="p">)</span>
</pre></div>

</div>
</div>

<div class="vbox output_wrapper">
<div class="output vbox">


<div class="hbox output_area">
<div class="prompt"></div>
<div class="box-flex1 output_subarea output_display_data">


<pre>
Loading required package: Amelia
Loading required package: Rcpp
## 
## Amelia II: Multiple Imputation
## (Version 1.7.3, built: 2014-11-14)
## Copyright (C) 2005-2014 James Honaker, Gary King and Matthew Blackwell
## Refer to http://gking.harvard.edu/amelia/ for more information
## 

</pre>

</div>
</div>

<div class="hbox output_area">
<div class="prompt"></div>
<div class="box-flex1 output_subarea output_display_data">


<img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAeAAAAHgCAIAAADytinCAAAgAElEQVR4nO3de1zM6f8//mvGdJBm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%0ARU5ErkJggg==">

</div>
</div>

</div>
</div>

</div>
<div class="text_cell_render border-box-sizing rendered_html">
<p>It's obvious looking at this map that the most values missing are in the Cabin and Age columns. Cabin basically refers to the cabin# of each passenger and considering how many values are missing, we could as well just drop it. Age however is critical and we need a better mechanism to handle. There is also one missing Embarked value.</p>
</div>
<div class="cell border-box-sizing code_cell vbox">
<div class="input hbox">
<div class="prompt input_prompt">
In [4]:
</div>
<div class="input_area box-flex1">
<div class="highlight"><pre><span class="o">%%</span><span class="k">R</span>
<span class="c">#OK let's plot a series of visualizations that can hopefully explain the data better"</span>

<span class="c">#Proportion of Survivors</span>
<span class="n">barplot</span><span class="p">(</span><span class="n">prop</span><span class="o">.</span><span class="n">table</span><span class="p">(</span><span class="n">table</span><span class="p">(</span><span class="n">train</span><span class="err">$</span><span class="n">Survived</span><span class="p">)),</span> <span class="n">names</span><span class="o">.</span><span class="n">arg</span><span class="o">=</span><span class="n">c</span><span class="p">(</span><span class="s">'Didn</span><span class="se">\'</span><span class="s">t Survive'</span><span class="p">,</span> <span class="s">'Survived'</span><span class="p">),</span> <span class="n">main</span><span class="o">=</span><span class="s">"Proportion of Survivors"</span><span class="p">,</span>
       <span class="n">col</span><span class="o">=</span><span class="n">c</span><span class="p">(</span><span class="s">'mistyrose'</span><span class="p">,</span><span class="s">'lightseagreen'</span><span class="p">))</span>

<span class="c">#Clearly more people died than survived.</span>
</pre></div>

</div>
</div>

<div class="vbox output_wrapper">
<div class="output vbox">


<div class="hbox output_area">
<div class="prompt"></div>
<div class="box-flex1 output_subarea output_display_data">


<img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAeAAAAHgCAMAAABKCk6nAAAC+lBMVEUAAAABAQECAgIDAwMEBAQF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%0AAAAASUVORK5CYII=">

</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell vbox">
<div class="input hbox">
<div class="prompt input_prompt">
In [5]:
</div>
<div class="input_area box-flex1">
<div class="highlight"><pre><span class="o">%%</span><span class="k">R</span>
<span class="c">#Proportion of Survivors by Gender</span>
<span class="n">barplot</span><span class="p">(</span><span class="n">prop</span><span class="o">.</span><span class="n">table</span><span class="p">(</span><span class="n">table</span><span class="p">(</span><span class="n">train</span><span class="err">$</span><span class="n">Sex</span><span class="p">,</span> <span class="n">train</span><span class="err">$</span><span class="n">Survived</span><span class="p">),</span> <span class="mi">1</span><span class="p">),</span> <span class="n">names</span><span class="o">.</span><span class="n">arg</span><span class="o">=</span><span class="n">c</span><span class="p">(</span><span class="s">'Didn</span><span class="se">\'</span><span class="s">t Survive'</span><span class="p">,</span> <span class="s">'Survived'</span><span class="p">),</span> 
        <span class="n">main</span><span class="o">=</span><span class="s">"Proportion of Survivors by Gender"</span><span class="p">,</span> <span class="n">legend</span><span class="o">=</span><span class="n">TRUE</span><span class="p">,</span> <span class="n">col</span><span class="o">=</span><span class="n">c</span><span class="p">(</span><span class="s">'darksalmon'</span><span class="p">,</span><span class="s">'paleturquoise'</span><span class="p">))</span>

<span class="c">#More Females survived than Males. This is understandable considering the ladies and children first approach for survival.</span>
</pre></div>

</div>
</div>

<div class="vbox output_wrapper">
<div class="output vbox">


<div class="hbox output_area">
<div class="prompt"></div>
<div class="box-flex1 output_subarea output_display_data">


<img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAeAAAAHgCAIAAADytinCAAAgAElEQVR4nO3de1hUdeL48Q8wMVwF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">

</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell vbox">
<div class="input hbox">
<div class="prompt input_prompt">
In [6]:
</div>
<div class="input_area box-flex1">
<div class="highlight"><pre><span class="o">%%</span><span class="k">R</span>
<span class="c">#Proportion of Survivors by Class of Travel - let's do a mosaicplot this time for fun.</span>
<span class="n">mosaicplot</span><span class="p">(</span><span class="n">prop</span><span class="o">.</span><span class="n">table</span><span class="p">(</span><span class="n">table</span><span class="p">(</span><span class="n">train</span><span class="err">$</span><span class="n">Pclass</span><span class="p">,</span> <span class="n">train</span><span class="err">$</span><span class="n">Survived</span><span class="p">),</span> <span class="mi">1</span><span class="p">),</span> <span class="n">main</span><span class="o">=</span><span class="s">"Proportion of Survivors by Pclass"</span><span class="p">,</span> 
           <span class="n">xlab</span><span class="o">=</span><span class="s">'Pclass'</span><span class="p">,</span> <span class="n">ylab</span><span class="o">=</span><span class="s">'Survived ?'</span><span class="p">,</span><span class="n">col</span><span class="o">=</span><span class="n">c</span><span class="p">(</span><span class="s">'darkturquoise'</span><span class="p">,</span><span class="s">'mediumspringgreen'</span><span class="p">))</span>

<span class="c">#Looks like those traveling in upper class (3) were more lucky than the rest. We'll keep this in mind.</span>
</pre></div>

</div>
</div>

<div class="vbox output_wrapper">
<div class="output vbox">


<div class="hbox output_area">
<div class="prompt"></div>
<div class="box-flex1 output_subarea output_display_data">


<img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAeAAAAHgCAIAAADytinCAAAc70lEQVR4nO3de1RVZfrA8fdwGC5y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">

</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell vbox">
<div class="input hbox">
<div class="prompt input_prompt">
In [7]:
</div>
<div class="input_area box-flex1">
<div class="highlight"><pre><span class="o">%%</span><span class="k">R</span>
<span class="c">#OK let's do a quick plot by Age - remember that we need to fill in missing values for this column.</span>
<span class="n">boxplot</span><span class="p">(</span><span class="n">train</span><span class="err">$</span><span class="n">Age</span><span class="o">~</span><span class="n">train</span><span class="err">$</span><span class="n">Survived</span><span class="p">,</span><span class="n">main</span><span class="o">=</span><span class="s">"Proportion of Survivors by Age"</span><span class="p">,</span> <span class="n">col</span><span class="o">=</span><span class="n">c</span><span class="p">(</span><span class="s">'darkseagreen4'</span><span class="p">,</span><span class="s">'salmon4'</span><span class="p">),</span> <span class="n">xlab</span><span class="o">=</span><span class="s">"Survived ?"</span><span class="p">,</span>
       <span class="n">ylab</span><span class="o">=</span><span class="s">"Age"</span><span class="p">)</span>

<span class="c">#OK that was a helpful plot, it clearly tells us that there were more survivors in the 20-35 Age bracket, young legs perhaps?</span>
</pre></div>

</div>
</div>

<div class="vbox output_wrapper">
<div class="output vbox">


<div class="hbox output_area">
<div class="prompt"></div>
<div class="box-flex1 output_subarea output_display_data">


<img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAeAAAAHgCAIAAADytinCAAAgAElEQVR4nO3de1zUdb7H8e/AwHAV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">

</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell vbox">
<div class="input hbox">
<div class="prompt input_prompt">
In [8]:
</div>
<div class="input_area box-flex1">
<div class="highlight"><pre><span class="o">%%</span><span class="k">R</span>
<span class="c">#OK let's get down to business. We'll look at how many values are missing for Age.</span>
<span class="n">summary</span><span class="p">(</span><span class="n">train</span><span class="err">$</span><span class="n">Age</span><span class="p">)</span>

<span class="c">#177 is a lot considering our dataset is really small. Let's try to find a meaningful way to fill these up.</span>

<span class="c">#The determining factors so far has been Gender and Pclass. Can we find out how many Age values are missing by Gender?</span>
<span class="n">barplot</span><span class="p">(</span><span class="n">table</span><span class="p">(</span><span class="n">train</span><span class="err">$</span><span class="n">Sex</span><span class="p">[</span><span class="n">which</span><span class="p">(</span><span class="ow">is</span><span class="o">.</span><span class="n">na</span><span class="p">(</span><span class="n">train</span><span class="err">$</span><span class="n">Age</span><span class="p">))]),</span><span class="n">main</span><span class="o">=</span><span class="s">"Proportion of Missing Ages by Gender"</span><span class="p">,</span> 
        <span class="n">col</span><span class="o">=</span><span class="n">c</span><span class="p">(</span><span class="s">'lightsteelblue'</span><span class="p">,</span><span class="s">'bisque3'</span><span class="p">),</span> <span class="n">xlab</span><span class="o">=</span><span class="s">"Gender"</span><span class="p">,</span> <span class="n">ylab</span><span class="o">=</span><span class="s">"Missing Ages"</span><span class="p">)</span>

<span class="c">#OK that's clearly tilted in favor of males. We're a sloppy bunch, aren't we?</span>
</pre></div>

</div>
</div>

<div class="vbox output_wrapper">
<div class="output vbox">


<div class="hbox output_area">
<div class="prompt"></div>
<div class="box-flex1 output_subarea output_display_data">


<img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAeAAAAHgCAIAAADytinCAAAgAElEQVR4nO3de1xU9b7/8e/gxHAV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%0AG5ngDpEAAAAASUVORK5CYII=">

</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell vbox">
<div class="input hbox">
<div class="prompt input_prompt">
In [9]:
</div>
<div class="input_area box-flex1">
<div class="highlight"><pre><span class="o">%%</span><span class="k">R</span>
<span class="c">#How about missing Age values by Pclass?</span>
<span class="n">barplot</span><span class="p">(</span><span class="n">table</span><span class="p">(</span><span class="n">train</span><span class="err">$</span><span class="n">Pclass</span><span class="p">[</span><span class="n">which</span><span class="p">(</span><span class="ow">is</span><span class="o">.</span><span class="n">na</span><span class="p">(</span><span class="n">train</span><span class="err">$</span><span class="n">Age</span><span class="p">))]),</span><span class="n">main</span><span class="o">=</span><span class="s">"Proportion of Missing Ages by Pclass"</span><span class="p">,</span> 
        <span class="n">col</span><span class="o">=</span><span class="n">c</span><span class="p">(</span><span class="s">'mediumseagreen'</span><span class="p">,</span><span class="s">'rosybrown4'</span><span class="p">,</span><span class="s">'mediumslateblue'</span><span class="p">),</span> <span class="n">xlab</span><span class="o">=</span><span class="s">"Pclass"</span><span class="p">,</span> <span class="n">ylab</span><span class="o">=</span><span class="s">"Missing Ages"</span><span class="p">)</span>

<span class="c">#There's our most important highlight yet. Most of the ages we're missing are in Pclass 3. So this goes to show, we will</span>
<span class="c">#probably be better off taking the median of ages for each Pclass and gender and filling the null values with it. That</span>
<span class="c">#should be better than simply filling all with overall median.</span>
</pre></div>

</div>
</div>

<div class="vbox output_wrapper">
<div class="output vbox">


<div class="hbox output_area">
<div class="prompt"></div>
<div class="box-flex1 output_subarea output_display_data">


<img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAeAAAAHgCAIAAADytinCAAAgAElEQVR4nO3df1yUdb7///fALMNP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%0AAElFTkSuQmCC">

</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell vbox">
<div class="input hbox">
<div class="prompt input_prompt">
In [10]:
</div>
<div class="input_area box-flex1">
<div class="highlight"><pre><span class="o">%%</span><span class="k">R</span>
<span class="c">#Let's go ahead and do the honors. Note that we could do all of this with a single sophisticated function but I am</span>
<span class="c">#choosing to keep things simple at the moment.</span>

<span class="c">#Before we make any changes to Train, let's combine Train and Test temporarily to a new dataset. Since any change we need</span>
<span class="c">#to make to Train needs to be made to Test as well, we can do the changes only once and split the datasets again later.</span>

<span class="c">#We'll first add the Survived Column to the Test set since it doesn't exist and init to NULL values since we won't use it.</span>
<span class="n">test</span><span class="err">$</span><span class="n">Survived</span><span class="o">&lt;-</span><span class="n">rep</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="n">nrow</span><span class="p">(</span><span class="n">test</span><span class="p">))</span>
<span class="n">titanic</span><span class="o">&lt;-</span><span class="n">rbind</span><span class="p">(</span><span class="n">train</span><span class="p">,</span><span class="n">test</span><span class="p">)</span>

<span class="c">#na.rm basically calculates mean for all non-null values. We then plug the medi</span>
<span class="n">titanic</span><span class="err">$</span><span class="n">Age</span><span class="p">[</span><span class="n">which</span><span class="p">(</span><span class="n">titanic</span><span class="err">$</span><span class="n">Pclass</span><span class="o">==</span><span class="mi">3</span> <span class="o">&amp;</span> <span class="n">titanic</span><span class="err">$</span><span class="n">Sex</span><span class="o">==</span><span class="s">"female"</span> <span class="o">&amp;</span> <span class="ow">is</span><span class="o">.</span><span class="n">na</span><span class="p">(</span><span class="n">titanic</span><span class="err">$</span><span class="n">Age</span><span class="p">))]</span><span class="o">&lt;-</span>
        <span class="n">median</span><span class="p">(</span><span class="n">titanic</span><span class="err">$</span><span class="n">Age</span><span class="p">[</span><span class="n">which</span><span class="p">(</span><span class="n">titanic</span><span class="err">$</span><span class="n">Pclass</span><span class="o">==</span><span class="mi">3</span> <span class="o">&amp;</span> <span class="n">titanic</span><span class="err">$</span><span class="n">Sex</span><span class="o">==</span><span class="s">"female"</span><span class="p">)],</span><span class="n">na</span><span class="o">.</span><span class="n">rm</span><span class="o">=</span><span class="n">TRUE</span><span class="p">)</span>
<span class="n">titanic</span><span class="err">$</span><span class="n">Age</span><span class="p">[</span><span class="n">which</span><span class="p">(</span><span class="n">titanic</span><span class="err">$</span><span class="n">Pclass</span><span class="o">==</span><span class="mi">2</span> <span class="o">&amp;</span> <span class="n">titanic</span><span class="err">$</span><span class="n">Sex</span><span class="o">==</span><span class="s">"female"</span> <span class="o">&amp;</span> <span class="ow">is</span><span class="o">.</span><span class="n">na</span><span class="p">(</span><span class="n">titanic</span><span class="err">$</span><span class="n">Age</span><span class="p">))]</span><span class="o">&lt;-</span>
        <span class="n">median</span><span class="p">(</span><span class="n">titanic</span><span class="err">$</span><span class="n">Age</span><span class="p">[</span><span class="n">which</span><span class="p">(</span><span class="n">titanic</span><span class="err">$</span><span class="n">Pclass</span><span class="o">==</span><span class="mi">3</span> <span class="o">&amp;</span> <span class="n">titanic</span><span class="err">$</span><span class="n">Sex</span><span class="o">==</span><span class="s">"female"</span><span class="p">)],</span><span class="n">na</span><span class="o">.</span><span class="n">rm</span><span class="o">=</span><span class="n">TRUE</span><span class="p">)</span>
<span class="n">titanic</span><span class="err">$</span><span class="n">Age</span><span class="p">[</span><span class="n">which</span><span class="p">(</span><span class="n">titanic</span><span class="err">$</span><span class="n">Pclass</span><span class="o">==</span><span class="mi">1</span> <span class="o">&amp;</span> <span class="n">titanic</span><span class="err">$</span><span class="n">Sex</span><span class="o">==</span><span class="s">"female"</span> <span class="o">&amp;</span> <span class="ow">is</span><span class="o">.</span><span class="n">na</span><span class="p">(</span><span class="n">titanic</span><span class="err">$</span><span class="n">Age</span><span class="p">))]</span><span class="o">&lt;-</span>
        <span class="n">median</span><span class="p">(</span><span class="n">titanic</span><span class="err">$</span><span class="n">Age</span><span class="p">[</span><span class="n">which</span><span class="p">(</span><span class="n">titanic</span><span class="err">$</span><span class="n">Pclass</span><span class="o">==</span><span class="mi">3</span> <span class="o">&amp;</span> <span class="n">titanic</span><span class="err">$</span><span class="n">Sex</span><span class="o">==</span><span class="s">"female"</span><span class="p">)],</span><span class="n">na</span><span class="o">.</span><span class="n">rm</span><span class="o">=</span><span class="n">TRUE</span><span class="p">)</span>
<span class="n">titanic</span><span class="err">$</span><span class="n">Age</span><span class="p">[</span><span class="n">which</span><span class="p">(</span><span class="n">titanic</span><span class="err">$</span><span class="n">Pclass</span><span class="o">==</span><span class="mi">3</span> <span class="o">&amp;</span> <span class="n">titanic</span><span class="err">$</span><span class="n">Sex</span><span class="o">==</span><span class="s">"male"</span> <span class="o">&amp;</span> <span class="ow">is</span><span class="o">.</span><span class="n">na</span><span class="p">(</span><span class="n">titanic</span><span class="err">$</span><span class="n">Age</span><span class="p">))]</span><span class="o">&lt;-</span>
        <span class="n">median</span><span class="p">(</span><span class="n">titanic</span><span class="err">$</span><span class="n">Age</span><span class="p">[</span><span class="n">which</span><span class="p">(</span><span class="n">titanic</span><span class="err">$</span><span class="n">Pclass</span><span class="o">==</span><span class="mi">3</span> <span class="o">&amp;</span> <span class="n">titanic</span><span class="err">$</span><span class="n">Sex</span><span class="o">==</span><span class="s">"female"</span><span class="p">)],</span><span class="n">na</span><span class="o">.</span><span class="n">rm</span><span class="o">=</span><span class="n">TRUE</span><span class="p">)</span>
<span class="n">titanic</span><span class="err">$</span><span class="n">Age</span><span class="p">[</span><span class="n">which</span><span class="p">(</span><span class="n">titanic</span><span class="err">$</span><span class="n">Pclass</span><span class="o">==</span><span class="mi">2</span> <span class="o">&amp;</span> <span class="n">titanic</span><span class="err">$</span><span class="n">Sex</span><span class="o">==</span><span class="s">"male"</span> <span class="o">&amp;</span> <span class="ow">is</span><span class="o">.</span><span class="n">na</span><span class="p">(</span><span class="n">titanic</span><span class="err">$</span><span class="n">Age</span><span class="p">))]</span><span class="o">&lt;-</span>
        <span class="n">median</span><span class="p">(</span><span class="n">titanic</span><span class="err">$</span><span class="n">Age</span><span class="p">[</span><span class="n">which</span><span class="p">(</span><span class="n">titanic</span><span class="err">$</span><span class="n">Pclass</span><span class="o">==</span><span class="mi">3</span> <span class="o">&amp;</span> <span class="n">titanic</span><span class="err">$</span><span class="n">Sex</span><span class="o">==</span><span class="s">"female"</span><span class="p">)],</span><span class="n">na</span><span class="o">.</span><span class="n">rm</span><span class="o">=</span><span class="n">TRUE</span><span class="p">)</span>
<span class="n">titanic</span><span class="err">$</span><span class="n">Age</span><span class="p">[</span><span class="n">which</span><span class="p">(</span><span class="n">titanic</span><span class="err">$</span><span class="n">Pclass</span><span class="o">==</span><span class="mi">1</span> <span class="o">&amp;</span> <span class="n">titanic</span><span class="err">$</span><span class="n">Sex</span><span class="o">==</span><span class="s">"male"</span> <span class="o">&amp;</span> <span class="ow">is</span><span class="o">.</span><span class="n">na</span><span class="p">(</span><span class="n">titanic</span><span class="err">$</span><span class="n">Age</span><span class="p">))]</span><span class="o">&lt;-</span>
        <span class="n">median</span><span class="p">(</span><span class="n">titanic</span><span class="err">$</span><span class="n">Age</span><span class="p">[</span><span class="n">which</span><span class="p">(</span><span class="n">titanic</span><span class="err">$</span><span class="n">Pclass</span><span class="o">==</span><span class="mi">3</span> <span class="o">&amp;</span> <span class="n">titanic</span><span class="err">$</span><span class="n">Sex</span><span class="o">==</span><span class="s">"female"</span><span class="p">)],</span><span class="n">na</span><span class="o">.</span><span class="n">rm</span><span class="o">=</span><span class="n">TRUE</span><span class="p">)</span>

<span class="c">#Let's do a quick summary of the Age column to make sure there are no nulls remaining</span>

<span class="n">summary</span><span class="p">(</span><span class="n">titanic</span><span class="err">$</span><span class="n">Age</span><span class="p">)</span>
</pre></div>

</div>
</div>

<div class="vbox output_wrapper">
<div class="output vbox">


<div class="hbox output_area">
<div class="prompt"></div>
<div class="box-flex1 output_subarea output_display_data">


<pre>
   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
   0.17   22.00   24.00   28.30   35.00   80.00 

</pre>

</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell vbox">
<div class="input hbox">
<div class="prompt input_prompt">
In [11]:
</div>
<div class="input_area box-flex1">
<div class="highlight"><pre><span class="o">%%</span><span class="k">R</span>
<span class="c">#Let's turn our attention to the Embarked Column</span>
<span class="n">summary</span><span class="p">(</span><span class="n">titanic</span><span class="err">$</span><span class="n">Embarked</span><span class="p">)</span>

<span class="c">#There are just 2 missing values and S seems to be the majority so let's plug in S</span>
<span class="n">titanic</span><span class="err">$</span><span class="n">Embarked</span><span class="p">[</span><span class="n">which</span><span class="p">(</span><span class="ow">is</span><span class="o">.</span><span class="n">na</span><span class="p">(</span><span class="n">titanic</span><span class="err">$</span><span class="n">Embarked</span><span class="p">))]</span> <span class="o">&lt;-</span> <span class="s">'S'</span>

<span class="n">summary</span><span class="p">(</span><span class="n">titanic</span><span class="err">$</span><span class="n">Embarked</span><span class="p">)</span>
</pre></div>

</div>
</div>

<div class="vbox output_wrapper">
<div class="output vbox">


<div class="hbox output_area">
<div class="prompt"></div>
<div class="box-flex1 output_subarea output_display_data">


<pre>
  C   Q   S 
270 123 916 

</pre>

</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell vbox">
<div class="input hbox">
<div class="prompt input_prompt">
In [12]:
</div>
<div class="input_area box-flex1">
<div class="highlight"><pre><span class="o">%%</span><span class="k">R</span>
<span class="c">#Let's remove the Cabin column which contains way too many NULLs and will probably not give anything new considering</span>
<span class="c">#we already have the port of embarcation.</span>
<span class="n">titanic</span><span class="err">$</span><span class="n">Cabin</span><span class="o">&lt;-</span><span class="n">NULL</span>
</pre></div>

</div>
</div>

</div>
<div class="text_cell_render border-box-sizing rendered_html">
<h5 id="feature-engineering">Feature Engineering</h5>
<p>Feature Engineering refers to manufacturing new features based on the idea that they may replace existing ones because they are easier for the machine learning algorithms to digest or extend the value of existing feature(s) because they're more relevant for the predictions we're trying to make. Let's see what new features we can add to the Titanic dataset.</p>
</div>
<div class="cell border-box-sizing code_cell vbox">
<div class="input hbox">
<div class="prompt input_prompt">
In [13]:
</div>
<div class="input_area box-flex1">
<div class="highlight"><pre><span class="o">%%</span><span class="k">R</span>
<span class="c">#OK we all know that they tried to save the women and children first aboard the titanic. We have gender which identifies</span>
<span class="c">#women but no identifier for children. Let's call all passengers with Age &lt; 18 children shall we?</span>
<span class="n">titanic</span><span class="err">$</span><span class="n">Child</span><span class="o">&lt;-</span><span class="mi">0</span>
<span class="n">titanic</span><span class="err">$</span><span class="n">Child</span><span class="p">[</span><span class="n">which</span><span class="p">(</span><span class="n">titanic</span><span class="err">$</span><span class="n">Age</span><span class="o">&lt;</span><span class="mi">18</span><span class="p">)]</span><span class="o">&lt;-</span><span class="mi">1</span>
</pre></div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell vbox">
<div class="input hbox">
<div class="prompt input_prompt">
In [14]:
</div>
<div class="input_area box-flex1">
<div class="highlight"><pre><span class="o">%%</span><span class="k">R</span>
<span class="c">#We have a column called fare which is a numeric value of the actual fare that was paid for the trip. This column as such</span>
<span class="c">#might not be very useful but what if we can break it down to different buckets - say &lt;20, 20-40, 40-60, 60+. Recall that</span>
<span class="c">#we had noticed a curious fact with respect to the range 20-35, let's make sure that is covered in a single bucket.</span>
<span class="n">titanic</span><span class="err">$</span><span class="n">FareGroup</span><span class="o">&lt;-</span><span class="s">'40+'</span>
<span class="n">titanic</span><span class="err">$</span><span class="n">FareGroup</span><span class="p">[</span><span class="n">which</span><span class="p">(</span><span class="n">titanic</span><span class="err">$</span><span class="n">Fare</span><span class="o">&lt;</span><span class="mi">10</span><span class="p">)]</span> <span class="o">&lt;-</span> <span class="s">'&lt;10'</span>
<span class="n">titanic</span><span class="err">$</span><span class="n">FareGroup</span><span class="p">[</span><span class="n">which</span><span class="p">(</span><span class="n">titanic</span><span class="err">$</span><span class="n">Fare</span><span class="o">&gt;=</span><span class="mi">10</span> <span class="o">&amp;</span> <span class="n">titanic</span><span class="err">$</span><span class="n">Fare</span><span class="o">&lt;</span><span class="mi">20</span><span class="p">)]</span> <span class="o">&lt;-</span> <span class="s">'10-20'</span>
<span class="n">titanic</span><span class="err">$</span><span class="n">FareGroup</span><span class="p">[</span><span class="n">which</span><span class="p">(</span><span class="n">titanic</span><span class="err">$</span><span class="n">Fare</span><span class="o">&gt;=</span><span class="mi">20</span> <span class="o">&amp;</span> <span class="n">titanic</span><span class="err">$</span><span class="n">Fare</span><span class="o">&lt;</span><span class="mi">40</span><span class="p">)]</span> <span class="o">&lt;-</span> <span class="s">'20-40'</span>

<span class="n">titanic</span><span class="err">$</span><span class="n">FareGroup</span><span class="o">&lt;-</span><span class="k">as</span><span class="o">.</span><span class="n">factor</span><span class="p">(</span><span class="n">titanic</span><span class="err">$</span><span class="n">FareGroup</span><span class="p">)</span>

<span class="n">barplot</span><span class="p">(</span><span class="n">table</span><span class="p">(</span><span class="n">titanic</span><span class="err">$</span><span class="n">FareGroup</span><span class="p">),</span><span class="n">col</span><span class="o">=</span><span class="s">'tomato1'</span><span class="p">,</span><span class="n">main</span><span class="o">=</span><span class="s">'Fare Groups'</span><span class="p">)</span>
</pre></div>

</div>
</div>

<div class="vbox output_wrapper">
<div class="output vbox">


<div class="hbox output_area">
<div class="prompt"></div>
<div class="box-flex1 output_subarea output_display_data">


<img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAeAAAAHgCAMAAABKCk6nAAAC31BMVEUAAAABAQECAgIDAwMEBAQG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%0ArkJggg==">

</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell vbox">
<div class="input hbox">
<div class="prompt input_prompt">
In [15]:
</div>
<div class="input_area box-flex1">
<div class="highlight"><pre><span class="o">%%</span><span class="k">R</span>
<span class="c">#Name is another clear candidate that might not be of great value to us. What could a name contribute to predicting if he/she</span>
<span class="c">#actually survived? Well, it may not directly but it could contain things that influence the prediction. Let's print a few </span>
<span class="c">#names to see.</span>
<span class="n">tail</span><span class="p">(</span><span class="n">titanic</span><span class="err">$</span><span class="n">Name</span><span class="p">)</span>

<span class="c">#We can see that the names seem to be in similar format and have a title in between the surname and first name. Can we </span>
<span class="c">#extract the Titles from the names?</span>
</pre></div>

</div>
</div>

<div class="vbox output_wrapper">
<div class="output vbox">


<div class="hbox output_area">
<div class="prompt"></div>
<div class="box-flex1 output_subarea output_display_data">


<pre>
[1] "Henriksson, Miss. Jenny Lovisa" "Spector, Mr. Woolf"            
[3] "Oliva y Ocana, Dona. Fermina"   "Saether, Mr. Simon Sivertsen"  
[5] "Ware, Mr. Frederick"            "Peter, Master. Michael J"      

</pre>

</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell vbox">
<div class="input hbox">
<div class="prompt input_prompt">
In [16]:
</div>
<div class="input_area box-flex1">
<div class="highlight"><pre><span class="o">%%</span><span class="k">R</span>
<span class="c">#We could use the strsplit function to split based on , and . then capture the middle items which should be the title. The</span>
<span class="c">#sapply function helps to perform this for the entire dataframe. function keyword is just like lambda in python. We will</span>
<span class="c">#also remove any extra whitespaces.</span>
<span class="n">titanic</span><span class="err">$</span><span class="n">Title</span><span class="o">&lt;-</span><span class="n">sapply</span><span class="p">(</span><span class="n">titanic</span><span class="err">$</span><span class="n">Name</span><span class="p">,</span> <span class="n">FUN</span><span class="o">=</span><span class="n">function</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="p">{</span><span class="n">strsplit</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">split</span><span class="o">=</span><span class="s">'[,.]'</span><span class="p">)[[</span><span class="mi">1</span><span class="p">]][</span><span class="mi">2</span><span class="p">]})</span>
<span class="n">titanic</span><span class="err">$</span><span class="n">Title</span><span class="o">&lt;-</span><span class="n">sub</span><span class="p">(</span><span class="s">' '</span><span class="p">,</span><span class="s">''</span><span class="p">,</span><span class="n">titanic</span><span class="err">$</span><span class="n">Title</span><span class="p">)</span>
<span class="n">head</span><span class="p">(</span><span class="n">titanic</span><span class="err">$</span><span class="n">Title</span><span class="p">)</span>
</pre></div>

</div>
</div>

<div class="vbox output_wrapper">
<div class="output vbox">


<div class="hbox output_area">
<div class="prompt"></div>
<div class="box-flex1 output_subarea output_display_data">


<pre>
[1] "Mr"   "Mrs"  "Miss" "Mrs"  "Mr"   "Mr"  

</pre>

</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell vbox">
<div class="input hbox">
<div class="prompt input_prompt">
In [17]:
</div>
<div class="input_area box-flex1">
<div class="highlight"><pre><span class="o">%%</span><span class="k">R</span>
<span class="c">#Let's take a look at the different values of Title and see if further grouping is necessary.</span>
<span class="c">#To be safe, we'll perform any analysis only on the training set. Let's temporarily split Train.</span>
<span class="n">temp</span> <span class="o">&lt;-</span> <span class="n">titanic</span><span class="p">[</span><span class="mi">1</span><span class="p">:</span><span class="n">nrow</span><span class="p">(</span><span class="n">train</span><span class="p">),]</span>
<span class="n">table</span><span class="p">(</span><span class="n">temp</span><span class="err">$</span><span class="n">Title</span><span class="p">)</span>

<span class="c">#OK there's obviously only a few titles that are most prominent namely Mr, Miss, Mrs and Master. Perhaps we can group the</span>
<span class="c">#other titles further?</span>
</pre></div>

</div>
</div>

<div class="vbox output_wrapper">
<div class="output vbox">


<div class="hbox output_area">
<div class="prompt"></div>
<div class="box-flex1 output_subarea output_display_data">


<pre>

        Capt          Col          Don           Dr     Jonkheer         Lady 
           1            2            1            7            1            1 
       Major       Master         Miss         Mlle          Mme           Mr 
           2           40          182            2            1          517 
         Mrs           Ms          Rev          Sir the Countess 
         125            1            6            1            1 

</pre>

</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell vbox">
<div class="input hbox">
<div class="prompt input_prompt">
In [18]:
</div>
<div class="input_area box-flex1">
<div class="highlight"><pre><span class="o">%%</span><span class="k">R</span>
<span class="c">#Looking at wikipedia definitions, the following grouping makes reasonable sense because of similar definitions.</span>
<span class="c">#Note it's definitely possible to nitpick these groupings, feel free to make your own judgement call.</span>
<span class="n">titanic</span><span class="err">$</span><span class="n">Title</span><span class="p">[</span><span class="n">titanic</span><span class="err">$</span><span class="n">Title</span> <span class="o">%</span><span class="k">in</span><span class="o">%</span> <span class="n">c</span><span class="p">(</span><span class="s">'Dona'</span><span class="p">,</span><span class="s">'Ms'</span><span class="p">,</span><span class="s">'Lady'</span><span class="p">,</span><span class="s">'the Countess'</span><span class="p">,</span><span class="s">'Jonkheer'</span><span class="p">)]</span> <span class="o">&lt;-</span> <span class="s">'Mrs'</span>
<span class="n">titanic</span><span class="err">$</span><span class="n">Title</span><span class="p">[</span><span class="n">titanic</span><span class="err">$</span><span class="n">Title</span> <span class="o">%</span><span class="k">in</span><span class="o">%</span> <span class="n">c</span><span class="p">(</span><span class="s">'Col'</span><span class="p">,</span><span class="s">'Dr'</span><span class="p">,</span><span class="s">'Rev'</span><span class="p">)]</span> <span class="o">&lt;-</span> <span class="s">'Noble'</span>
<span class="n">titanic</span><span class="err">$</span><span class="n">Title</span><span class="p">[</span><span class="n">titanic</span><span class="err">$</span><span class="n">Title</span> <span class="o">%</span><span class="k">in</span><span class="o">%</span> <span class="n">c</span><span class="p">(</span><span class="s">'Mme'</span><span class="p">,</span><span class="s">'Mile'</span><span class="p">,</span><span class="s">'Mlle'</span><span class="p">)]</span> <span class="o">&lt;-</span> <span class="s">'Miss'</span>
<span class="n">titanic</span><span class="err">$</span><span class="n">Title</span><span class="p">[</span><span class="n">titanic</span><span class="err">$</span><span class="n">Title</span> <span class="o">%</span><span class="k">in</span><span class="o">%</span> <span class="n">c</span><span class="p">(</span><span class="s">'Capt'</span><span class="p">,</span><span class="s">'Don'</span><span class="p">,</span><span class="s">'Major'</span><span class="p">,</span><span class="s">'Sir'</span><span class="p">)]</span> <span class="o">&lt;-</span> <span class="s">'Mr'</span>

<span class="n">titanic</span><span class="err">$</span><span class="n">Title</span><span class="o">&lt;-</span><span class="k">as</span><span class="o">.</span><span class="n">factor</span><span class="p">(</span><span class="n">titanic</span><span class="err">$</span><span class="n">Title</span><span class="p">)</span>

<span class="n">table</span><span class="p">(</span><span class="n">titanic</span><span class="err">$</span><span class="n">Title</span><span class="p">)</span>
</pre></div>

</div>
</div>

<div class="vbox output_wrapper">
<div class="output vbox">


<div class="hbox output_area">
<div class="prompt"></div>
<div class="box-flex1 output_subarea output_display_data">


<pre>

Master   Miss     Mr    Mrs  Noble 
    61    263    762    203     20 

</pre>

</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell vbox">
<div class="input hbox">
<div class="prompt input_prompt">
In [19]:
</div>
<div class="input_area box-flex1">
<div class="highlight"><pre><span class="o">%%</span><span class="k">R</span>
<span class="c">#OK so we split the Titles out, but what about Surnames? Surnames could indicate families traveling together, maybe </span>
<span class="c">#many of them tried to stick together trying to escape? Let's capture the surnames.</span>
<span class="n">titanic</span><span class="err">$</span><span class="n">Surname</span><span class="o">&lt;-</span><span class="n">sapply</span><span class="p">(</span><span class="n">titanic</span><span class="err">$</span><span class="n">Name</span><span class="p">,</span> <span class="n">FUN</span><span class="o">=</span><span class="n">function</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="p">{</span><span class="n">strsplit</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">split</span><span class="o">=</span><span class="s">'[,.]'</span><span class="p">)[[</span><span class="mi">1</span><span class="p">]][</span><span class="mi">1</span><span class="p">]})</span>
<span class="n">titanic</span><span class="err">$</span><span class="n">Surname</span><span class="o">&lt;-</span><span class="n">sub</span><span class="p">(</span><span class="s">' '</span><span class="p">,</span><span class="s">''</span><span class="p">,</span><span class="n">titanic</span><span class="err">$</span><span class="n">Surname</span><span class="p">)</span>
<span class="n">head</span><span class="p">(</span><span class="n">titanic</span><span class="err">$</span><span class="n">Surname</span><span class="p">)</span>
</pre></div>

</div>
</div>

<div class="vbox output_wrapper">
<div class="output vbox">


<div class="hbox output_area">
<div class="prompt"></div>
<div class="box-flex1 output_subarea output_display_data">


<pre>
[1] "Braund"    "Cumings"   "Heikkinen" "Futrelle"  "Allen"     "Moran"    

</pre>

</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell vbox">
<div class="input hbox">
<div class="prompt input_prompt">
In [20]:
</div>
<div class="input_area box-flex1">
<div class="highlight"><pre><span class="o">%%</span><span class="k">R</span>
<span class="c">#Very quickly let's get a quick rundown of the families</span>
<span class="n">temp</span> <span class="o">&lt;-</span> <span class="n">titanic</span><span class="p">[</span><span class="mi">1</span><span class="p">:</span><span class="n">nrow</span><span class="p">(</span><span class="n">train</span><span class="p">),]</span>
<span class="n">fams</span><span class="o">&lt;-</span><span class="n">data</span><span class="o">.</span><span class="n">frame</span><span class="p">(</span><span class="n">table</span><span class="p">(</span><span class="n">temp</span><span class="err">$</span><span class="n">Surname</span><span class="p">))</span>
<span class="k">print</span><span class="p">(</span><span class="n">summary</span><span class="p">(</span><span class="n">fams</span><span class="err">$</span><span class="n">Freq</span><span class="p">))</span>
<span class="c">#There we we have it. Looks like a lot of the passengers don't share a Surname with each other since the Median is 1</span>
<span class="c">#but there are families as well with upto 9 members (in the training set). So we were on the right track.</span>
<span class="n">hist</span><span class="p">(</span><span class="n">fams</span><span class="err">$</span><span class="n">Freq</span><span class="p">,</span> <span class="n">ylim</span><span class="o">=</span><span class="n">c</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">50</span><span class="p">),</span> <span class="n">col</span><span class="o">=</span><span class="s">'darkcyan'</span><span class="p">)</span>

<span class="c">#The histogram tells us there are a lot of ones and about 50 odd families with sizes 2 and 3, the remaining few have</span>
<span class="c">#large families. Perhaps there's a bigger question, how do we which of them are families? There could be multiple passengers</span>
<span class="c">#with the same surname traveling different groups, which would negate our purpose.</span>
</pre></div>

</div>
</div>

<div class="vbox output_wrapper">
<div class="output vbox">


<div class="hbox output_area">
<div class="prompt"></div>
<div class="box-flex1 output_subarea output_display_data">


<pre>
   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
  1.000   1.000   1.000   1.336   1.000   9.000 

</pre>

</div>
</div>

<div class="hbox output_area">
<div class="prompt"></div>
<div class="box-flex1 output_subarea output_display_data">


<img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAeAAAAHgCAIAAADytinCAAAgAElEQVR4nO3de1iUZf748Xtg5CCM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%0AQmCC">

</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell vbox">
<div class="input hbox">
<div class="prompt input_prompt">
In [21]:
</div>
<div class="input_area box-flex1">
<div class="highlight"><pre><span class="o">%%</span><span class="k">R</span>
<span class="c">#To simplify this, let's use the variables we haven't explored so far, SibSp (No. of Siblings and Spouses) and Parch (No.</span>
<span class="c">#Parents and Children). Summing these up (+1 for self) should gives us the family size of each passenger. Making an</span>
<span class="c">#assumption that these attributes were entered correctly, we could then surmise that passengers with the same surname and </span>
<span class="c">#family size belong to same families. Of course, there're still loopholes if we want to nitpick but I am stopping here.</span>
<span class="n">titanic</span><span class="err">$</span><span class="n">FamSize</span><span class="o">&lt;-</span><span class="n">titanic</span><span class="err">$</span><span class="n">SibSp</span> <span class="o">+</span> <span class="n">titanic</span><span class="err">$</span><span class="n">Parch</span> <span class="o">+</span> <span class="mi">1</span>

<span class="c">#Club FamilySize with Surname to create a new Family ID </span>
<span class="n">titanic</span><span class="err">$</span><span class="n">FamID</span><span class="o">&lt;-</span><span class="n">paste</span><span class="p">(</span><span class="n">titanic</span><span class="err">$</span><span class="n">Surname</span><span class="p">,</span><span class="k">as</span><span class="o">.</span><span class="n">character</span><span class="p">(</span><span class="n">titanic</span><span class="err">$</span><span class="n">FamSize</span><span class="p">),</span><span class="n">sep</span><span class="o">=</span><span class="s">''</span><span class="p">)</span>

<span class="c">#We'll call all passengers with Family Size = 1 as traveling Solo.</span>
<span class="n">titanic</span><span class="err">$</span><span class="n">FamID</span><span class="p">[</span><span class="n">which</span><span class="p">(</span><span class="n">titanic</span><span class="err">$</span><span class="n">FamSize</span><span class="o">==</span><span class="mi">1</span><span class="p">)]</span><span class="o">&lt;-</span><span class="s">'Solo'</span>
<span class="n">titanic</span><span class="err">$</span><span class="n">FamID</span><span class="o">&lt;-</span><span class="k">as</span><span class="o">.</span><span class="n">factor</span><span class="p">(</span><span class="n">titanic</span><span class="err">$</span><span class="n">FamID</span><span class="p">)</span>

<span class="c">#Finally let's remove some columns we won't use for model building.</span>
<span class="c">#Name and Ticket are unique for each passenger (we assume) and couldn't possible add any relevance to our prediction. Even</span>
<span class="c">#if multiple passengers had the same name, it shouldn't really help us decide if one or more survived.</span>
<span class="n">titanic</span><span class="err">$</span><span class="n">Name</span><span class="o">&lt;-</span><span class="n">NULL</span>
<span class="n">titanic</span><span class="err">$</span><span class="n">Ticket</span><span class="o">&lt;-</span><span class="n">NULL</span>

<span class="n">head</span><span class="p">(</span><span class="n">titanic</span><span class="p">)</span>
</pre></div>

</div>
</div>

<div class="vbox output_wrapper">
<div class="output vbox">


<div class="hbox output_area">
<div class="prompt"></div>
<div class="box-flex1 output_subarea output_display_data">


<pre>
  PassengerId Survived Pclass    Sex Age SibSp Parch    Fare Embarked Child
1           1        0      3   male  22     1     0  7.2500        S     0
2           2        1      1 female  38     1     0 71.2833        C     0
3           3        1      3 female  26     0     0  7.9250        S     0
4           4        1      1 female  35     1     0 53.1000        S     0
5           5        0      3   male  35     0     0  8.0500        S     0
6           6        0      3   male  22     0     0  8.4583        Q     0
  FareGroup Title   Surname FamSize     FamID
1       &lt;10    Mr    Braund       2   Braund2
2       40+   Mrs   Cumings       2  Cumings2
3       &lt;10  Miss Heikkinen       1      Solo
4       40+   Mrs  Futrelle       2 Futrelle2
5       &lt;10    Mr     Allen       1      Solo
6       &lt;10    Mr     Moran       1      Solo

</pre>

</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell vbox">
<div class="input hbox">
<div class="prompt input_prompt">
In [22]:
</div>
<div class="input_area box-flex1">
<div class="highlight"><pre><span class="o">%%</span><span class="k">R</span>
<span class="c">#Great we're through. We'll now get back our Train and Test sets from Titanic.</span>
<span class="n">train</span><span class="o">&lt;-</span><span class="n">titanic</span><span class="p">[</span><span class="mi">1</span><span class="p">:</span><span class="n">nrow</span><span class="p">(</span><span class="n">train</span><span class="p">),]</span>
<span class="n">temp</span><span class="o">=</span><span class="n">nrow</span><span class="p">(</span><span class="n">train</span><span class="p">)</span><span class="o">+</span><span class="mi">1</span>
<span class="n">kaggletest</span><span class="o">&lt;-</span><span class="n">titanic</span><span class="p">[</span><span class="n">temp</span><span class="p">:</span><span class="n">nrow</span><span class="p">(</span><span class="n">titanic</span><span class="p">),]</span>

<span class="k">print</span><span class="p">(</span><span class="n">nrow</span><span class="p">(</span><span class="n">train</span><span class="p">))</span>
<span class="k">print</span><span class="p">(</span><span class="n">nrow</span><span class="p">(</span><span class="n">kaggletest</span><span class="p">))</span>
<span class="k">print</span><span class="p">(</span><span class="n">nrow</span><span class="p">(</span><span class="n">titanic</span><span class="p">))</span>
</pre></div>

</div>
</div>

<div class="vbox output_wrapper">
<div class="output vbox">


<div class="hbox output_area">
<div class="prompt"></div>
<div class="box-flex1 output_subarea output_display_data">


<pre>
[1] 891
[1] 418
[1] 1309

</pre>

</div>
</div>

</div>
</div>

</div>
<div class="text_cell_render border-box-sizing rendered_html">
<h4 id="model-fitting-and-evaluation">Model Fitting and Evaluation</h4>
<p>I want to use this opportunity and challenge to try out different models in R and see how they stack up against each other. We'll run through one at a time, fit the parameters and submit to Kaggle. We'll then wrap things up by comparing the different approaches. I think this is a great chance to learn tuning models in R.</p>
<p>First up, before we start training and running cross-validation, I would like to try simple, plain-old logistic regression. We'll not be training but simply fitting a model and checking how the different parameters we've created contribute to the predictions.</p>
<p>Before we get started we need to split the "train.csv" file we're holding in the train dataframe to train/test sets. The reason we do this is so we have a baseline to run our model against before the submission to Kaggle. It enables a good approximation on how well the model can generalize.</p>
<p>We'll be using the <em>caret</em> package for the rest of this approach. The caret package has several functions that attempt to streamline the model building and evaluation process. One of them is the createDataPartition function which can be used to create a stratified random sample of the data into training and test sets.</p>
</div>
<div class="cell border-box-sizing code_cell vbox">
<div class="input hbox">
<div class="prompt input_prompt">
In [23]:
</div>
<div class="input_area box-flex1">
<div class="highlight"><pre><span class="o">%%</span><span class="k">R</span>
<span class="c">#75/25 Train/Test Split</span>
<span class="c">#install.packages('caret')</span>
<span class="c">#Setting a random seed. We will be using this throughout to make sure our results are consistently comparable.</span>
<span class="n">library</span><span class="p">(</span><span class="n">caret</span><span class="p">)</span>
<span class="nb">set</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">35</span><span class="p">)</span> 
<span class="n">trainrows</span><span class="o">&lt;-</span><span class="n">createDataPartition</span><span class="p">(</span><span class="n">train</span><span class="err">$</span><span class="n">Survived</span><span class="p">,</span> <span class="n">p</span> <span class="o">=</span> <span class="mf">0.8</span><span class="p">,</span> <span class="nb">list</span><span class="o">=</span><span class="n">FALSE</span><span class="p">)</span>
<span class="n">train</span><span class="o">.</span><span class="n">set</span><span class="o">&lt;-</span><span class="n">train</span><span class="p">[</span><span class="n">trainrows</span><span class="p">,]</span>
<span class="n">test</span><span class="o">.</span><span class="n">set</span><span class="o">&lt;-</span><span class="n">train</span><span class="p">[</span><span class="o">-</span><span class="n">trainrows</span><span class="p">,]</span>

<span class="k">print</span><span class="p">(</span><span class="n">nrow</span><span class="p">(</span><span class="n">train</span><span class="o">.</span><span class="n">set</span><span class="p">))</span>
<span class="k">print</span><span class="p">(</span><span class="n">nrow</span><span class="p">(</span><span class="n">test</span><span class="o">.</span><span class="n">set</span><span class="p">))</span>
      
<span class="c">#Remember, from this point on Test does NOT refer to the test.csv file. I will call out explicitly when it does and it won't</span>
<span class="c">#until the very end when we submit predictions to Kaggle for each model.</span>
</pre></div>

</div>
</div>

<div class="vbox output_wrapper">
<div class="output vbox">


<div class="hbox output_area">
<div class="prompt"></div>
<div class="box-flex1 output_subarea output_display_data">


<pre>
Loading required package: lattice
Loading required package: ggplot2
[1] 714
[1] 177

</pre>

</div>
</div>

</div>
</div>

</div>
<div class="text_cell_render border-box-sizing rendered_html">
<h5 id="logistic-regression">Logistic Regression</h5>
<p>Before we start training models with caret, I would like to first explore simple logistic regression through the glm() method. glm (Generalized Linear Models) is easy-to-use and lets us several types of linear models, logistic regression being one of them. Let's begin</p>
</div>
<div class="cell border-box-sizing code_cell vbox">
<div class="input hbox">
<div class="prompt input_prompt">
In [24]:
</div>
<div class="input_area box-flex1">
<div class="highlight"><pre><span class="o">%%</span><span class="k">R</span>
<span class="c">#To start with I am not including any of the features we manufactured. Let's see how the raw features perform.</span>

<span class="n">Titan</span><span class="o">.</span><span class="n">logit</span><span class="o">.</span><span class="mi">1</span> <span class="o">&lt;-</span> <span class="n">glm</span><span class="p">(</span><span class="n">Survived</span> <span class="o">~</span> <span class="n">Sex</span> <span class="o">+</span> <span class="n">Pclass</span> <span class="o">+</span> <span class="n">Age</span> <span class="o">+</span> <span class="n">SibSp</span> <span class="o">+</span> <span class="n">Parch</span> <span class="o">+</span> <span class="n">Embarked</span> <span class="o">+</span> <span class="n">Fare</span><span class="p">,</span> 
                       <span class="n">data</span> <span class="o">=</span> <span class="n">train</span><span class="o">.</span><span class="n">set</span><span class="p">,</span> <span class="n">family</span><span class="o">=</span><span class="n">binomial</span><span class="p">(</span><span class="s">"logit"</span><span class="p">))</span>
<span class="k">print</span><span class="p">(</span><span class="n">Titan</span><span class="o">.</span><span class="n">logit</span><span class="o">.</span><span class="mi">1</span><span class="p">)</span>
</pre></div>

</div>
</div>

<div class="vbox output_wrapper">
<div class="output vbox">


<div class="hbox output_area">
<div class="prompt"></div>
<div class="box-flex1 output_subarea output_display_data">


<pre>

Call:  glm(formula = Survived ~ Sex + Pclass + Age + SibSp + Parch + 
    Embarked + Fare, family = binomial("logit"), data = train.set)

Coefficients:
(Intercept)      Sexmale      Pclass2      Pclass3          Age        SibSp  
   4.034633    -2.640662    -1.101916    -2.263913    -0.038039    -0.263821  
      Parch    EmbarkedQ    EmbarkedS         Fare  
  -0.112988    -0.001405    -0.455287     0.002163  

Degrees of Freedom: 713 Total (i.e. Null);  704 Residual
Null Deviance:	    950.9 
Residual Deviance: 633.3 	AIC: 653.3

</pre>

</div>
</div>

</div>
</div>

</div>
<div class="text_cell_render border-box-sizing rendered_html">
<p>Couple of observations on the results above. The factors we're interested in are Deviance and Degrees of Freedom. The null observations are based on how well we can predict survival given a "null" model, which works only based on a constant, mean of means or a "grand mean". The null deviance is expected to be high. While the residual deviance tells us how much the inclusion of features has brought down the null deviance. So for instance, in our first run, the null deviance was <strong>950.9</strong> and the residual deviance was <strong>633.3</strong>. So including the raw features (after the data munging process) brought down the deviance by <strong>~327</strong> points with a 713-704=<strong>9</strong> change in degrees of freedom. If you're interested like I am, google to learn more about these topics. The coefficients are the parameters (theta) for each of the features and the Intercept is the theta0 term.</p>
<p>Let's run the extractor function, anova(), which gives us the result of analysis. I am using the chi-square or "goodness of fit" statistic. Lower the value the better.</p>
</div>
<div class="cell border-box-sizing code_cell vbox">
<div class="input hbox">
<div class="prompt input_prompt">
In [25]:
</div>
<div class="input_area box-flex1">
<div class="highlight"><pre><span class="o">%%</span><span class="k">R</span>
<span class="n">anova</span><span class="p">(</span><span class="n">Titan</span><span class="o">.</span><span class="n">logit</span><span class="o">.</span><span class="mi">1</span><span class="p">,</span> <span class="n">test</span><span class="o">=</span><span class="s">"Chisq"</span><span class="p">)</span>
</pre></div>

</div>
</div>

<div class="vbox output_wrapper">
<div class="output vbox">


<div class="hbox output_area">
<div class="prompt"></div>
<div class="box-flex1 output_subarea output_display_data">


<pre>
Analysis of Deviance Table

Model: binomial, link: logit

Response: Survived

Terms added sequentially (first to last)


         Df Deviance Resid. Df Resid. Dev  Pr(&gt;Chi)    
NULL                       713     950.86              
Sex       1  206.206       712     744.66 &lt; 2.2e-16 ***
Pclass    2   77.642       710     667.02 &lt; 2.2e-16 ***
Age       1   18.755       709     648.26 1.486e-05 ***
SibSp     1    8.977       708     639.29  0.002734 ** 
Parch     1    0.640       707     638.65  0.423776    
Embarked  2    4.625       705     634.02  0.098991 .  
Fare      1    0.723       704     633.30  0.395187    
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

</pre>

</div>
</div>

</div>
</div>

</div>
<div class="text_cell_render border-box-sizing rendered_html">
<p>Looking at the individual deviances, we see that Sex and Pclass accounted for the biggest reductions while Age and SibSp seem to be contributing somewhat. Embarked and Fare are on the lower end while the contribution of Parch is negligible. Let's now make some changes, include our new features and remove Fare and Parch.</p>
</div>
<div class="cell border-box-sizing code_cell vbox">
<div class="input hbox">
<div class="prompt input_prompt">
In [26]:
</div>
<div class="input_area box-flex1">
<div class="highlight"><pre><span class="o">%%</span><span class="k">R</span>
<span class="n">Titan</span><span class="o">.</span><span class="n">logit</span><span class="o">.</span><span class="mi">2</span> <span class="o">&lt;-</span> <span class="n">glm</span><span class="p">(</span><span class="n">Survived</span> <span class="o">~</span> <span class="n">Sex</span> <span class="o">+</span> <span class="n">Pclass</span> <span class="o">+</span> <span class="n">Age</span> <span class="o">+</span> <span class="n">SibSp</span> <span class="o">+</span> <span class="n">Embarked</span> <span class="o">+</span> <span class="n">FareGroup</span> <span class="o">+</span> <span class="n">FamID</span> <span class="o">+</span> <span class="n">Title</span> <span class="o">+</span> <span class="n">FamSize</span><span class="p">,</span> 
                       <span class="n">data</span> <span class="o">=</span> <span class="n">train</span><span class="o">.</span><span class="n">set</span><span class="p">,</span> <span class="n">family</span><span class="o">=</span><span class="n">binomial</span><span class="p">(</span><span class="s">"logit"</span><span class="p">))</span>
<span class="k">print</span><span class="p">(</span><span class="n">Titan</span><span class="o">.</span><span class="n">logit</span><span class="o">.</span><span class="mi">2</span><span class="p">)</span>
</pre></div>

</div>
</div>

<div class="vbox output_wrapper">
<div class="output vbox">


<div class="hbox output_area">
<div class="prompt"></div>
<div class="box-flex1 output_subarea output_display_data">


<pre>

Call:  glm(formula = Survived ~ Sex + Pclass + Age + SibSp + Embarked + 
    FareGroup + FamID + Title + FamSize, family = binomial("logit"), 
    data = train.set)

Coefficients:
              (Intercept)                    Sexmale  
                3.022e+01                 -2.932e+01  
                  Pclass2                    Pclass3  
               -1.165e+00                 -1.093e+00  
                      Age                      SibSp  
               -2.415e-02                  2.153e-01  
                EmbarkedQ                  EmbarkedS  
                2.933e-01                 -2.709e-01  
           FareGroup10-20             FareGroup20-40  
                5.610e-01                  1.247e+00  
             FareGroup40+              FamIDAbelson2  
                1.058e+00                 -1.144e-01  
                FamIDAks2              FamIDAllison4  
                4.504e+15                 -2.955e+01  
    FamIDAndersen-Jensen2            FamIDAndersson7  
                2.559e+01                 -2.594e+00  
            FamIDAndrews2             FamIDAppleton3  
                2.591e+01                  2.754e+01  
     FamIDArnold-Franchi2              FamIDAsplund7  
               -2.780e+01                 -9.996e-01  
          FamIDBackstrom2            FamIDBackstrom4  
               -2.342e+01                  2.432e+01  
            FamIDBaclini4              FamIDBarbara2  
                2.514e+01                 -2.695e+01  
             FamIDBaxter2                FamIDBeane2  
               -6.829e-01                  3.796e+01  
             FamIDBecker4             FamIDBeckwith3  
                4.504e+15                  2.686e+01  
             FamIDBishop2               FamIDBoulos3  
                1.901e+01                 -2.693e+01  
             FamIDBourke3             FamIDBowerman2  
               -2.735e+01                  2.270e+01  
              FamIDBrown3                FamIDBryhl2  
                6.636e-01                 -4.504e+15  
           FamIDCaldwell3                FamIDCaram2  
                2.510e+01                 -3.145e+01  
            FamIDCardeza2               FamIDCarter2  
                2.719e+01                 -2.599e+01  
             FamIDCarter4            FamIDCavendish2  
                1.396e+01                 -2.490e+01  
           FamIDChambers2              FamIDChristy3  
                2.565e+01                  2.697e+01  
       FamIDChronopoulos2               FamIDClarke2  
               -2.292e+01                  2.775e+01  
            FamIDCollyer3              FamIDCompton3  
                1.118e+00                  2.399e+01  
             FamIDCoutts3                FamIDCribb2  
                2.256e+01                 -7.634e+01  
             FamIDCrosby3              FamIDCumings2  
                8.250e-01                  2.315e+01  
             FamIDDanbom3             FamIDDavidson2  
               -2.789e+01                 -4.445e+01  
             FamIDDavies3              FamIDDavison2  
                7.337e-01                  2.443e+01  
               FamIDDean4             FamIDdelCarlo2  
                7.449e-01                 -2.444e+01  
      FamIDdeMessemaeker2                 FamIDDick2  
                2.064e+01                  2.697e+01  
              FamIDDodge3               FamIDDoling2  
                2.502e+01                  4.261e+01  
            FamIDDouglas2           FamIDDuffGordon2  
               -2.482e+01                  2.711e+01  
        FamIDDurany More2                FamIDElias3  
                2.638e+01                 -2.680e+01  
             FamIDEustis2           FamIDFaunthorpe2  
                4.504e+15                  2.679e+01  
               FamIDFord5              FamIDFortune6  
               -1.731e+01                 -6.254e-01  
         FamIDFrauenthal2           FamIDFrauenthal3  
                2.072e+01                  2.958e+01  
          FamIDFrolicher3     FamIDFrolicher-Stehli3  
                2.450e+01                  2.806e+01  
           FamIDFutrelle2                 FamIDGale2  
               -6.513e-01                 -2.397e+01  
              FamIDGiles2           FamIDGoldenberg2  
               -2.348e+01                  2.839e+01  
          FamIDGoldsmith3              FamIDGoodwin8  
                2.487e+01                 -3.330e+01  
             FamIDGraham2           FamIDGreenfield2  
                2.441e+01                  2.620e+01  
         FamIDGustafsson3              FamIDHagland2  
               -4.187e+01                 -1.861e+01  
         FamIDHamalainen3               FamIDHansen2  
                2.591e+01                 -2.340e+01  
             FamIDHansen3               FamIDHarder2  
               -5.239e+01                  2.766e+01  
             FamIDHarper2               FamIDHarris2  
                2.961e+00                 -5.547e-01  
               FamIDHart3                 FamIDHays3  
                1.289e+00                  2.229e+01  
             FamIDHerman4              FamIDHickman3  
                2.614e+01                 -3.538e+01  
            FamIDHippach2             FamIDHirvonen2  
                5.357e+01                  2.910e+01  
            FamIDHocking4                 FamIDHold2  
               -2.375e+01                 -2.059e+01  
          FamIDHolverson2                 FamIDHoyt2  
               -2.258e+01                  1.834e+01  
         FamIDIlmakangas2            FamIDJacobsohn2  
               -2.598e+01                 -1.966e+01  
          FamIDJacobsohn4               FamIDJensen2  
                2.239e+01                 -2.301e+01  
            FamIDJohnson3             FamIDJohnston4  
                2.611e+01                 -2.985e+01  
            FamIDJussila2               FamIDKantor2  
               -2.704e+01                  1.565e-01  
             FamIDKenyon2              FamIDKiernan2  
                2.598e+01                 -1.207e+03  
            FamIDKimball2                 FamIDKink3  
                2.856e+01                 -2.513e+01  
      FamIDKink-Heilmann3               FamIDKlasen3  
                2.618e+01                 -2.429e+01  
           FamIDLahtinen3              FamIDLaroche4  
               -2.831e+01                  8.050e-01  
            FamIDLefebre5               FamIDLennon2  
               -2.767e+01                 -4.504e+15  
            FamIDLindell2            FamIDLindqvist2  
               -2.437e+01                  2.823e+01  
              FamIDLines2                 FamIDLobb2  
                2.471e+01                 -2.340e+01  
              FamIDLouch2               FamIDMadill2  
                2.383e+01                  2.414e+01  
             FamIDMallet3               FamIDMarvin2  
                7.140e-01                 -2.524e+01  
              FamIDMcCoy3              FamIDMcNamee2  
                3.043e+01                 -2.358e+01  
              FamIDMeyer2              FamIDMinahan2  
               -1.188e+00                  2.485e+01  
            FamIDMinahan3                 FamIDMoor2  
               -2.357e+01                  2.595e+01  
              FamIDMoran2             FamIDMoubarek3  
                3.095e-01                  1.393e+01  
             FamIDMurphy2                FamIDNakid3  
                2.723e+01                  2.852e+01  
             FamIDNasser2               FamIDNatsch2  
               -2.532e-01                 -2.146e+01  
           FamIDNavratil3               FamIDNewell2  
                2.643e+01                  2.878e+01  
             FamIDNewell3               FamIDNewsom3  
               -2.082e+01                  2.493e+01  
           FamIDNicholls3        FamIDNicola-Yarred2  
               -1.773e+01                  2.645e+01  
            FamIDO'Brien2                FamIDOlsen2  
                2.950e+01                 -2.216e+01  
            FamIDPalsson5               FamIDPanula6  
               -4.936e+01                 -2.862e+01  
            FamIDParrish2                FamIDPears2  
                3.472e+01                 -9.049e-01  
FamIDPenascoy Castellana2              FamIDPersson2  
               -1.369e+00                  3.023e+01  
              FamIDPeter3            FamIDPetterson2  
                2.598e+01                 -2.278e+01  
             FamIDPotter2                FamIDQuick3  
                2.398e+01                  2.556e+01  
             FamIDRenouf4                 FamIDRice6  
                2.379e+01                 -2.202e+01  
           FamIDRichards3             FamIDRichards6  
                2.988e+01                  2.444e+01  
             FamIDRobert2               FamIDRobins2  
                2.393e+01                 -2.787e+01  
            FamIDRosblom3              FamIDRyerson5  
               -1.694e+01                  2.468e+01  
              FamIDSage11               FamIDSamaan3  
               -2.948e+01                 -2.481e+01  
          FamIDSandstrom3              FamIDShelley2  
                2.597e+01                  2.361e+01  
             FamIDSilven3               FamIDSilvey2  
                2.797e+01                 -4.461e-01  
              FamIDSkoog6                  FamIDSolo  
               -2.788e+01                  1.459e+00  
            FamIDSpencer2           FamIDStephenson2  
                2.281e+01                  2.347e+01  
              FamIDStrom2                FamIDStrom3  
               -2.698e+01                 -2.850e+01  
            FamIDTaussig3               FamIDTaylor2  
                2.470e+01                  2.732e+01  
             FamIDThayer3               FamIDThomas2  
                2.664e+01                  2.664e+01  
       FamIDThorneycroft2               FamIDTurpin2  
                6.012e-01                 -2.782e+01  
        FamIDvanBilliard3         FamIDVanderPlanke2  
               -2.289e+01                 -4.026e+02  
       FamIDVanderPlanke3              FamIDVanImpe3  
               -2.312e+05                 -2.825e+01  
             FamIDWarren2                FamIDWeisz2  
                2.370e+01                  2.415e+01  
              FamIDWells3                 FamIDWest4  
                2.545e+01                  1.068e+00  
              FamIDWhite2                 FamIDWick3  
               -2.411e+01                  2.541e+01  
            FamIDWidener3             FamIDWilliams2  
               -2.544e+01                 -2.437e+01  
             FamIDZabour2                  TitleMiss  
               -2.698e+01                 -2.917e+01  
                  TitleMr                   TitleMrs  
               -2.822e+00                 -2.725e+01  
               TitleNoble                    FamSize  
               -3.994e+00                         NA  

Degrees of Freedom: 713 Total (i.e. Null);  517 Residual
Null Deviance:	    950.9 
Residual Deviance: 373.3 	AIC: 767.3

</pre>

</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell vbox">
<div class="input hbox">
<div class="prompt input_prompt">
In [27]:
</div>
<div class="input_area box-flex1">
<div class="highlight"><pre><span class="o">%%</span><span class="k">R</span>
<span class="n">anova</span><span class="p">(</span><span class="n">Titan</span><span class="o">.</span><span class="n">logit</span><span class="o">.</span><span class="mi">2</span><span class="p">,</span> <span class="n">test</span><span class="o">=</span><span class="s">"Chisq"</span><span class="p">)</span>
</pre></div>

</div>
</div>

<div class="vbox output_wrapper">
<div class="output vbox">


<div class="hbox output_area">
<div class="prompt"></div>
<div class="box-flex1 output_subarea output_display_data">


<pre>
Analysis of Deviance Table

Model: binomial, link: logit

Response: Survived

Terms added sequentially (first to last)


           Df Deviance Resid. Df Resid. Dev  Pr(&gt;Chi)    
NULL                         713     950.86              
Sex         1  206.206       712     744.66 &lt; 2.2e-16 ***
Pclass      2   77.642       710     667.02 &lt; 2.2e-16 ***
Age         1   18.755       709     648.26 1.486e-05 ***
SibSp       1    8.977       708     639.29 0.0027343 ** 
Embarked    2    4.742       706     634.54 0.0933863 .  
FareGroup   3    1.034       703     633.51 0.7930468    
FamID     182  248.620       521     384.89 0.0007554 ***
Title       4   11.591       517     373.30 0.0206677 *  
FamSize     0    0.000       517     373.30              
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

</pre>

</div>
</div>

</div>
</div>

</div>
<div class="text_cell_render border-box-sizing rendered_html">
<p>Looks like FamID and to an extent FareGroup contribute well to the model. Although looking at the extraordinarily high deviance and df for FamID, I am suspicious that this might cause overfitting - meaning we've modeled in extreme based on the training set hence won't generalize very well on new examples. This can be addressed by resampling and hypertuning parameters based on crossvalidation. We essentially split the training set further into train and cv, then hypertune parameters against the cv set. This is repeated multiple times, each with a different sample of train/cv.</p>
<p>OK let's proceed to use the train method of the caret package to train a logistic regression model. We'll use one of the most common crossvalidation methods namely the 3x 10-fold CV. That is 10 folds of data to split train and cv repeated 3 times.</p>
</div>
<div class="cell border-box-sizing code_cell vbox">
<div class="input hbox">
<div class="prompt input_prompt">
In [28]:
</div>
<div class="input_area box-flex1">
<div class="highlight"><pre><span class="o">%%</span><span class="k">R</span>
<span class="c">#Define the 3x 10 fold cv control using the traincontrol method of caret.</span>
<span class="n">tenfoldcv</span><span class="o">&lt;-</span><span class="n">trainControl</span><span class="p">(</span><span class="n">method</span><span class="o">=</span><span class="s">'repeatedcv'</span><span class="p">,</span> <span class="n">number</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">repeats</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
</pre></div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell vbox">
<div class="input hbox">
<div class="prompt input_prompt">
In [283]:
</div>
<div class="input_area box-flex1">
<div class="highlight"><pre><span class="o">%%</span><span class="k">R</span>
<span class="c">#Train a logistic regression classifier using the train method of the caret package. Everything is same as before except</span>
<span class="c">#we use the train function and pass glm as the method.</span>

<span class="c">#Install the doSNOW package to leverage multiple cores - parallelization</span>
<span class="c">#install.packages(doSNOW)</span>
<span class="n">library</span><span class="p">(</span><span class="n">doSNOW</span><span class="p">)</span>

<span class="c">#Set 4 below to the number of cores you'd like to run in parallel. I have 4 and using 3 of them!</span>
<span class="n">cl</span> <span class="o">&lt;-</span> <span class="n">makeCluster</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="s">"SOCK"</span><span class="p">)</span>
<span class="n">registerDoSNOW</span><span class="p">(</span><span class="n">cl</span><span class="p">)</span>

<span class="c">#Note that I've also added options below to normalize the features (Feature Scaling)</span>
<span class="nb">set</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">35</span><span class="p">)</span> 
<span class="n">logit</span><span class="o">.</span><span class="n">tune1</span><span class="o">&lt;-</span><span class="n">train</span><span class="p">(</span><span class="n">Survived</span> <span class="o">~</span> <span class="n">Sex</span> <span class="o">+</span> <span class="n">Pclass</span> <span class="o">+</span> <span class="n">Age</span> <span class="o">+</span> <span class="n">SibSp</span> <span class="o">+</span> <span class="n">Embarked</span> <span class="o">+</span> <span class="n">FareGroup</span> <span class="o">+</span> <span class="n">FamID</span> <span class="o">+</span> <span class="n">Title</span><span class="p">,</span>
                <span class="n">data</span><span class="o">=</span><span class="n">train</span><span class="o">.</span><span class="n">set</span><span class="p">,</span>
                <span class="n">method</span><span class="o">=</span><span class="s">'glm'</span><span class="p">,</span>
                <span class="n">preProcess</span> <span class="o">=</span> <span class="n">c</span><span class="p">(</span><span class="s">"center"</span><span class="p">,</span> <span class="s">"scale"</span><span class="p">),</span>
                <span class="n">trControl</span><span class="o">=</span><span class="n">tenfoldcv</span><span class="p">)</span>

<span class="n">logit</span><span class="o">.</span><span class="n">tune1</span>

<span class="c">#May need to install a dependency for caret train</span>
<span class="c">#install.packages('e1071', dependencies=TRUE)</span>
</pre></div>

</div>
</div>

<div class="vbox output_wrapper">
<div class="output vbox">


<div class="hbox output_area">
<div class="prompt"></div>
<div class="box-flex1 output_subarea output_display_data">


<pre>
Generalized Linear Model 

714 samples
 14 predictors
  2 classes: '0', '1' 

Pre-processing: centered, scaled 
Resampling: Cross-Validated (10 fold, repeated 3 times) 

Summary of sample sizes: 643, 643, 643, 642, 643, 643, ... 

Resampling results

  Accuracy   Kappa      Accuracy SD  Kappa SD 
  0.7829812  0.5332698  0.05484398   0.1230111

 

</pre>

</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell vbox">
<div class="input hbox">
<div class="prompt input_prompt">
In [284]:
</div>
<div class="input_area box-flex1">
<div class="highlight"><pre><span class="o">%%</span><span class="k">R</span>
<span class="n">summary</span><span class="p">(</span><span class="n">logit</span><span class="o">.</span><span class="n">tune1</span><span class="p">)</span>
</pre></div>

</div>
</div>

<div class="vbox output_wrapper">
<div class="output vbox">


<div class="hbox output_area">
<div class="prompt"></div>
<div class="box-flex1 output_subarea output_display_data">


<pre>

Call:
NULL

Deviance Residuals: 
     Min        1Q    Median        3Q       Max  
-2.28940  -0.43374  -0.00008   0.00010   2.42885  

Coefficients: (45 not defined because of singularities)
                              Estimate Std. Error z value Pr(&gt;|z|)  
(Intercept)                 -6.178e-01  2.122e+02  -0.003   0.9977  
Sexmale                     -1.065e+01  3.540e+03  -0.003   0.9976  
Pclass2                     -4.784e-01  2.887e-01  -1.657   0.0975 .
Pclass3                     -5.451e-01  3.414e-01  -1.597   0.1103  
Age                         -3.162e-01  1.743e-01  -1.814   0.0697 .
SibSp                        2.275e-01  6.706e-01   0.339   0.7344  
EmbarkedQ                    8.080e-02  1.658e-01   0.487   0.6259  
EmbarkedS                   -1.214e-01  1.804e-01  -0.673   0.5010  
`FareGroup10-20`             2.253e-01  2.610e-01   0.863   0.3880  
`FareGroup20-40`             5.179e-01  2.891e-01   1.792   0.0732 .
`FareGroup40+`               4.250e-01  2.883e-01   1.474   0.1404  
FamIDAbelson2               -6.050e-03  1.922e-01  -0.031   0.9749  
FamIDAhlin2                         NA         NA      NA       NA  
FamIDAks2                    6.886e-01  4.025e+02   0.002   0.9986  
FamIDAllison4               -1.184e+00  3.883e+02  -0.003   0.9976  
`FamIDAndersen-Jensen2`      7.532e-01  4.025e+02   0.002   0.9985  
FamIDAndersson7             -1.938e-01  2.168e-01  -0.894   0.3714  
FamIDAndrews2                7.125e-01  4.025e+02   0.002   0.9986  
FamIDAngle2                         NA         NA      NA       NA  
FamIDAppleton3               6.236e-01  4.025e+02   0.002   0.9988  
`FamIDArnold-Franchi2`      -1.073e+00  3.092e+02  -0.003   0.9972  
FamIDAsplund7               -6.470e-02  1.963e-01  -0.330   0.7417  
FamIDAstor2                         NA         NA      NA       NA  
FamIDBackstrom2             -6.092e-01  4.025e+02  -0.002   0.9988  
FamIDBackstrom4              6.570e-01  4.025e+02   0.002   0.9987  
FamIDBaclini4                9.648e-01  3.949e+02   0.002   0.9981  
FamIDBarbara2               -1.079e+00  3.893e+02  -0.003   0.9978  
FamIDBaxter2                -3.612e-02  1.847e-01  -0.195   0.8450  
FamIDBeane2                  8.323e-01  4.025e+02   0.002   0.9983  
FamIDBecker4                 6.907e-01  4.025e+02   0.002   0.9986  
FamIDBeckwith3               1.070e+00  3.166e+02   0.003   0.9973  
FamIDBishop2                 5.908e-01  4.025e+02   0.001   0.9988  
FamIDBoulos3                -7.514e-01  4.025e+02  -0.002   0.9985  
FamIDBourke3                -1.310e+00  3.150e+02  -0.004   0.9967  
FamIDBowerman2               6.835e-01  4.025e+02   0.002   0.9986  
FamIDBraund2                        NA         NA      NA       NA  
FamIDBrown3                  3.510e-02  2.015e-01   0.174   0.8617  
FamIDBryhl2                 -6.385e-01  4.025e+02  -0.002   0.9987  
FamIDCaldwell3               9.659e-01  3.860e+02   0.003   0.9980  
FamIDCaram2                 -8.114e-01  4.025e+02  -0.002   0.9984  
FamIDCardeza2                7.973e-01  4.025e+02   0.002   0.9984  
FamIDCarter2                -1.066e+00  2.916e+02  -0.004   0.9971  
FamIDCarter4                 1.284e+00  3.196e+02   0.004   0.9968  
FamIDCavendish2             -6.651e-01  4.025e+02  -0.002   0.9987  
FamIDChaffee2                       NA         NA      NA       NA  
FamIDChambers2               1.056e+00  3.148e+02   0.003   0.9973  
FamIDChapman2                       NA         NA      NA       NA  
FamIDChibnall2                      NA         NA      NA       NA  
FamIDChristy3                7.147e-01  4.025e+02   0.002   0.9986  
FamIDChronopoulos2          -6.247e-01  4.025e+02  -0.002   0.9988  
FamIDClark2                         NA         NA      NA       NA  
FamIDClarke2                 6.457e-01  4.025e+02   0.002   0.9987  
FamIDCollyer3                7.236e-02  2.007e-01   0.361   0.7184  
FamIDCompton3                6.806e-01  4.025e+02   0.002   0.9987  
FamIDCornell3                       NA         NA      NA       NA  
FamIDCoutts3                 7.235e-01  4.025e+02   0.002   0.9986  
FamIDCribb2                 -5.903e-01  4.025e+02  -0.001   0.9988  
FamIDCrosby3                 4.363e-02  1.757e-01   0.248   0.8038  
FamIDCumings2                6.080e-01  4.025e+02   0.002   0.9988  
FamIDDanbom3                -1.061e+00  3.096e+02  -0.003   0.9973  
FamIDDavidson2              -6.696e-01  4.025e+02  -0.002   0.9987  
FamIDDavidson4                      NA         NA      NA       NA  
FamIDDavies3                 3.880e-02  1.637e-01   0.237   0.8126  
FamIDDavison2                6.632e-01  4.025e+02   0.002   0.9987  
FamIDDean4                   3.940e-02  1.691e-01   0.233   0.8157  
FamIDdelCarlo2              -6.450e-01  4.025e+02  -0.002   0.9987  
FamIDdeMessemaeker2          6.759e-01  4.025e+02   0.002   0.9987  
FamIDDick2                   1.058e+00  3.063e+02   0.003   0.9972  
FamIDDodge3                  6.729e-01  4.025e+02   0.002   0.9987  
FamIDDoling2                 7.164e-01  4.025e+02   0.002   0.9986  
FamIDDouglas2               -6.626e-01  4.025e+02  -0.002   0.9987  
FamIDDouglas3                       NA         NA      NA       NA  
FamIDDrew3                          NA         NA      NA       NA  
FamIDDuffGordon2             1.068e+00  3.094e+02   0.003   0.9972  
`FamIDDurany More2`          7.320e-01  4.025e+02   0.002   0.9985  
FamIDDyker2                         NA         NA      NA       NA  
FamIDEarnshaw2                      NA         NA      NA       NA  
FamIDElias3                 -6.119e-01  4.025e+02  -0.002   0.9988  
FamIDEustis2                 6.942e-01  4.025e+02   0.002   0.9986  
FamIDFaunthorpe2             6.466e-01  4.025e+02   0.002   0.9987  
FamIDFord5                  -1.315e+00  3.334e+02  -0.004   0.9969  
FamIDFortune6               -4.048e-02  2.085e-01  -0.194   0.8460  
FamIDFrauenthal2             6.037e-01  4.025e+02   0.001   0.9988  
FamIDFrauenthal3             8.479e-01  4.025e+02   0.002   0.9983  
FamIDFrolicher3              6.733e-01  4.025e+02   0.002   0.9987  
`FamIDFrolicher-Stehli3`     8.109e-01  4.025e+02   0.002   0.9984  
FamIDFutrelle2              -3.445e-02  1.937e-01  -0.178   0.8588  
FamIDGale2                  -6.303e-01  4.025e+02  -0.002   0.9988  
FamIDGibson2                        NA         NA      NA       NA  
FamIDGiles2                 -6.164e-01  4.025e+02  -0.002   0.9988  
FamIDGoldenberg2             1.065e+00  3.013e+02   0.004   0.9972  
FamIDGoldsmith3              6.457e-01  4.025e+02   0.002   0.9987  
FamIDGoodwin8               -1.580e+00  3.994e+02  -0.004   0.9968  
FamIDGraham2                 6.443e-01  4.025e+02   0.002   0.9987  
FamIDGreenfield2             7.856e-01  4.025e+02   0.002   0.9984  
FamIDGustafsson3            -8.422e-01  4.018e+02  -0.002   0.9983  
FamIDHagland2               -6.182e-01  4.025e+02  -0.002   0.9988  
FamIDHakkarainen2                   NA         NA      NA       NA  
FamIDHamalainen3             9.970e-01  3.930e+02   0.003   0.9980  
FamIDHansen2                -5.936e-01  4.025e+02  -0.001   0.9988  
FamIDHansen3                -6.091e-01  4.025e+02  -0.002   0.9988  
FamIDHarder2                 7.793e-01  4.025e+02   0.002   0.9985  
FamIDHarper2                 2.212e-01  2.270e-01   0.974   0.3300  
FamIDHarris2                -2.934e-02  1.980e-01  -0.148   0.8822  
FamIDHart3                   8.346e-02  2.031e-01   0.411   0.6811  
FamIDHays3                   6.308e-01  4.025e+02   0.002   0.9987  
FamIDHerman4                 7.208e-01  4.025e+02   0.002   0.9986  
FamIDHickman3               -9.069e-01  4.021e+02  -0.002   0.9982  
FamIDHiltunen3                      NA         NA      NA       NA  
FamIDHippach2                9.173e-01  3.896e+02   0.002   0.9981  
FamIDHirvonen2               7.249e-01  4.025e+02   0.002   0.9986  
FamIDHirvonen3                      NA         NA      NA       NA  
FamIDHocking4               -6.227e-01  4.025e+02  -0.002   0.9988  
FamIDHocking5                       NA         NA      NA       NA  
FamIDHogeboom2                      NA         NA      NA       NA  
FamIDHold2                  -6.213e-01  4.025e+02  -0.002   0.9988  
FamIDHolverson2             -6.597e-01  4.025e+02  -0.002   0.9987  
FamIDHoward2                        NA         NA      NA       NA  
FamIDHoyt2                   6.154e-01  4.025e+02   0.002   0.9988  
FamIDIlmakangas2            -7.058e-01  4.025e+02  -0.002   0.9986  
FamIDJacobsohn2             -6.231e-01  4.025e+02  -0.002   0.9988  
FamIDJacobsohn4              6.340e-01  4.025e+02   0.002   0.9987  
FamIDJefferys3                      NA         NA      NA       NA  
FamIDJensen2                -6.017e-01  4.025e+02  -0.001   0.9988  
FamIDJohnson3                1.017e+00  3.989e+02   0.003   0.9980  
FamIDJohnston4              -7.552e-01  4.025e+02  -0.002   0.9985  
FamIDJussila2               -1.003e+00  4.022e+02  -0.002   0.9980  
FamIDKantor2                 8.279e-03  1.951e-01   0.042   0.9661  
FamIDKarun2                         NA         NA      NA       NA  
FamIDKenyon2                 6.037e-01  4.025e+02   0.001   0.9988  
FamIDKhalil2                        NA         NA      NA       NA  
FamIDKiernan2               -6.183e-01  4.025e+02  -0.002   0.9988  
FamIDKimball2                8.048e-01  4.025e+02   0.002   0.9984  
FamIDKink3                  -6.017e-01  4.025e+02  -0.001   0.9988  
`FamIDKink-Heilmann3`        7.011e-01  4.025e+02   0.002   0.9986  
`FamIDKink-Heilmann5`               NA         NA      NA       NA  
FamIDKlasen3                -6.008e-01  4.025e+02  -0.001   0.9988  
FamIDLahtinen3              -8.206e-01  4.025e+02  -0.002   0.9984  
FamIDLaroche4                5.211e-02  2.064e-01   0.252   0.8007  
FamIDLefebre5               -1.330e+00  3.994e+02  -0.003   0.9973  
FamIDLennon2                -6.393e-01  4.025e+02  -0.002   0.9987  
FamIDLindell2               -6.056e-01  4.025e+02  -0.002   0.9988  
FamIDLindqvist2              8.655e-01  4.025e+02   0.002   0.9983  
FamIDLines2                  6.710e-01  4.025e+02   0.002   0.9987  
FamIDLobb2                  -6.110e-01  4.025e+02  -0.002   0.9988  
FamIDLouch2                  6.583e-01  4.025e+02   0.002   0.9987  
FamIDMadill2                 6.771e-01  4.025e+02   0.002   0.9987  
FamIDMallet3                 3.776e-02  1.753e-01   0.215   0.8294  
FamIDMarvin2                -6.804e-01  4.025e+02  -0.002   0.9987  
FamIDMcCoy3                  1.063e+00  3.296e+02   0.003   0.9974  
FamIDMcNamee2               -6.164e-01  4.025e+02  -0.002   0.9988  
FamIDMellinger2                     NA         NA      NA       NA  
FamIDMeyer2                 -6.282e-02  1.958e-01  -0.321   0.7484  
FamIDMinahan2                6.642e-01  4.025e+02   0.002   0.9987  
FamIDMinahan3               -6.432e-01  4.025e+02  -0.002   0.9987  
FamIDMock2                          NA         NA      NA       NA  
FamIDMoor2                   1.008e+00  3.892e+02   0.003   0.9979  
FamIDMoran2                  1.637e-02  1.617e-01   0.101   0.9193  
FamIDMoubarek3               1.032e+00  4.022e+02   0.003   0.9980  
FamIDMurphy2                 7.138e-01  4.025e+02   0.002   0.9986  
FamIDNakid3                  1.121e+00  3.216e+02   0.003   0.9972  
FamIDNasser2                -1.339e-02  2.015e-01  -0.066   0.9470  
FamIDNatsch2                -6.733e-01  4.025e+02  -0.002   0.9987  
FamIDNavratil3               7.005e-01  4.025e+02   0.002   0.9986  
FamIDNewell2                 9.467e-01  4.019e+02   0.002   0.9981  
FamIDNewell3                -6.473e-01  4.025e+02  -0.002   0.9987  
FamIDNewsom3                 6.737e-01  4.025e+02   0.002   0.9987  
FamIDNicholls3              -6.439e-01  4.025e+02  -0.002   0.9987  
`FamIDNicola-Yarred2`        1.016e+00  3.995e+02   0.003   0.9980  
`FamIDO'Brien2`              6.421e-01  4.025e+02   0.002   0.9987  
FamIDOlsen2                 -5.711e-01  4.025e+02  -0.001   0.9989  
FamIDOstby2                         NA         NA      NA       NA  
FamIDPalsson5               -1.583e+00  3.966e+02  -0.004   0.9968  
FamIDPanula6                -1.702e+00  3.394e+02  -0.005   0.9960  
FamIDParrish2                6.736e-01  4.025e+02   0.002   0.9987  
FamIDPeacock3                       NA         NA      NA       NA  
FamIDPears2                 -4.786e-02  1.964e-01  -0.244   0.8074  
`FamIDPenascoy Castellana2` -7.240e-02  1.934e-01  -0.374   0.7082  
FamIDPersson2                8.700e-01  4.025e+02   0.002   0.9983  
FamIDPeter3                  9.555e-01  3.847e+02   0.002   0.9980  
FamIDPetterson2             -5.945e-01  4.025e+02  -0.001   0.9988  
FamIDPhillips2                      NA         NA      NA       NA  
FamIDPotter2                 6.323e-01  4.025e+02   0.002   0.9987  
FamIDQuick3                  6.939e-01  4.025e+02   0.002   0.9986  
FamIDRenouf2                        NA         NA      NA       NA  
FamIDRenouf4                 6.314e-01  4.025e+02   0.002   0.9987  
FamIDRice6                  -1.813e+00  4.006e+02  -0.005   0.9964  
FamIDRichards3               7.262e-01  4.025e+02   0.002   0.9986  
FamIDRichards6               6.597e-01  4.025e+02   0.002   0.9987  
FamIDRobert2                 6.307e-01  4.025e+02   0.002   0.9987  
FamIDRobins2                -7.787e-01  4.025e+02  -0.002   0.9985  
FamIDRosblom3               -1.074e+00  3.243e+02  -0.003   0.9974  
FamIDRothschild2                    NA         NA      NA       NA  
FamIDRyerson5                6.536e-01  4.025e+02   0.002   0.9987  
FamIDSage11                 -1.755e+00  3.590e+02  -0.005   0.9961  
FamIDSamaan3                -6.621e-01  4.025e+02  -0.002   0.9987  
FamIDSandstrom3              9.897e-01  3.910e+02   0.003   0.9980  
FamIDSchabert2                      NA         NA      NA       NA  
FamIDShelley2                6.510e-01  4.025e+02   0.002   0.9987  
FamIDSilven3                 7.421e-01  4.025e+02   0.002   0.9985  
FamIDSilvey2                -2.359e-02  1.986e-01  -0.119   0.9055  
FamIDSkoog6                 -1.722e+00  3.458e+02  -0.005   0.9960  
FamIDSmith2                         NA         NA      NA       NA  
FamIDSnyder2                        NA         NA      NA       NA  
FamIDSolo                    7.131e-01  1.282e+00   0.556   0.5781  
FamIDSpedden3                       NA         NA      NA       NA  
FamIDSpencer2                5.935e-01  4.025e+02   0.001   0.9988  
FamIDStengel2                       NA         NA      NA       NA  
FamIDStephenson2             6.207e-01  4.025e+02   0.002   0.9988  
FamIDStraus2                        NA         NA      NA       NA  
FamIDStrom2                 -7.396e-01  4.025e+02  -0.002   0.9985  
FamIDStrom3                 -7.949e-01  4.025e+02  -0.002   0.9984  
FamIDTaussig3                9.287e-01  3.840e+02   0.002   0.9981  
FamIDTaylor2                 1.078e+00  3.017e+02   0.004   0.9971  
FamIDThayer3                 1.042e+00  3.205e+02   0.003   0.9974  
FamIDThomas2                 7.401e-01  4.025e+02   0.002   0.9985  
FamIDThomas3                        NA         NA      NA       NA  
FamIDThorneycroft2           3.180e-02  1.904e-01   0.167   0.8674  
FamIDTouma3                         NA         NA      NA       NA  
FamIDTurpin2                -1.095e+00  3.113e+02  -0.004   0.9972  
FamIDvanBilliard3           -5.934e-01  4.025e+02  -0.001   0.9988  
FamIDVanderPlanke2          -7.931e-01  4.025e+02  -0.002   0.9984  
FamIDVanderPlanke3          -9.929e-01  3.306e+02  -0.003   0.9976  
FamIDVanderPlanke4                  NA         NA      NA       NA  
FamIDVanImpe3               -1.126e+00  3.838e+02  -0.003   0.9977  
FamIDWare2                          NA         NA      NA       NA  
FamIDWarren2                 6.279e-01  4.025e+02   0.002   0.9988  
FamIDWeisz2                  6.466e-01  4.025e+02   0.002   0.9987  
FamIDWells3                  6.957e-01  4.025e+02   0.002   0.9986  
FamIDWest4                   6.913e-02  2.036e-01   0.340   0.7341  
FamIDWhite2                 -6.408e-01  4.025e+02  -0.002   0.9987  
FamIDWick3                   6.916e-01  4.025e+02   0.002   0.9986  
FamIDWidener3               -6.753e-01  4.025e+02  -0.002   0.9987  
FamIDWiklund2                       NA         NA      NA       NA  
FamIDWilkes2                        NA         NA      NA       NA  
FamIDWilliams2              -6.536e-01  4.025e+02  -0.002   0.9987  
FamIDYasbeck2                       NA         NA      NA       NA  
FamIDZabour2                -7.397e-01  4.025e+02  -0.002   0.9985  
TitleMiss                   -8.997e+00  3.011e+03  -0.003   0.9976  
TitleMr                     -1.393e+00  7.860e-01  -1.772   0.0764 .
TitleMrs                    -7.105e+00  2.603e+03  -0.003   0.9978  
TitleNoble                  -5.542e-01  2.803e-01  -1.977   0.0480 *
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

(Dispersion parameter for binomial family taken to be 1)

    Null deviance: 950.86  on 713  degrees of freedom
Residual deviance: 373.30  on 517  degrees of freedom
AIC: 767.3

Number of Fisher Scoring iterations: 18


</pre>

</div>
</div>

</div>
</div>

</div>
<div class="text_cell_render border-box-sizing rendered_html">
<p>Okay looks like we're doing (un)reasonably well. Let's try a couple of interesting ideas. <strong>Class Compression</strong> refers to collapsing some levels on a categorical variable. In layman terms, making a factor two-level. So for instance, we have Embarked, most of which has the value 'S' as we saw earlier. We can use the I() function when training to shrink this to S or otherwise. Let's do that.</p>
</div>
<div class="cell border-box-sizing code_cell vbox">
<div class="input hbox">
<div class="prompt input_prompt">
In [285]:
</div>
<div class="input_area box-flex1">
<div class="highlight"><pre><span class="o">%%</span><span class="k">R</span>
<span class="c">#Let's set class compression on Embarked to 'S' or otherwise.</span>
<span class="nb">set</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">35</span><span class="p">)</span> 

<span class="n">logit</span><span class="o">.</span><span class="n">tune2</span><span class="o">&lt;-</span><span class="n">train</span><span class="p">(</span><span class="n">Survived</span> <span class="o">~</span> <span class="n">Sex</span> <span class="o">+</span> <span class="n">Pclass</span> <span class="o">+</span> <span class="n">Age</span> <span class="o">+</span> <span class="n">SibSp</span> <span class="o">+</span> <span class="n">I</span><span class="p">(</span><span class="n">Embarked</span><span class="o">==</span><span class="s">'S'</span><span class="p">)</span> <span class="o">+</span> <span class="n">FareGroup</span> <span class="o">+</span> <span class="n">FamID</span> <span class="o">+</span> <span class="n">Title</span><span class="p">,</span>
                <span class="n">data</span><span class="o">=</span><span class="n">train</span><span class="o">.</span><span class="n">set</span><span class="p">,</span>
                <span class="n">method</span><span class="o">=</span><span class="s">'glm'</span><span class="p">,</span>
                <span class="n">preProcess</span> <span class="o">=</span> <span class="n">c</span><span class="p">(</span><span class="s">"center"</span><span class="p">,</span> <span class="s">"scale"</span><span class="p">),</span>
                <span class="n">trControl</span><span class="o">=</span><span class="n">tenfoldcv</span><span class="p">)</span>

<span class="n">logit</span><span class="o">.</span><span class="n">tune2</span>
</pre></div>

</div>
</div>

<div class="vbox output_wrapper">
<div class="output vbox">


<div class="hbox output_area">
<div class="prompt"></div>
<div class="box-flex1 output_subarea output_display_data">


<pre>
Generalized Linear Model 

714 samples
 14 predictors
  2 classes: '0', '1' 

Pre-processing: centered, scaled 
Resampling: Cross-Validated (10 fold, repeated 3 times) 

Summary of sample sizes: 643, 643, 643, 642, 643, 643, ... 

Resampling results

  Accuracy   Kappa    Accuracy SD  Kappa SD 
  0.7820488  0.53063  0.05507752   0.1240941

 

</pre>

</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell vbox">
<div class="input hbox">
<div class="prompt input_prompt">
In [286]:
</div>
<div class="input_area box-flex1">
<div class="highlight"><pre><span class="o">%%</span><span class="k">R</span>
<span class="n">summary</span><span class="p">(</span><span class="n">logit</span><span class="o">.</span><span class="n">tune2</span><span class="p">)</span>
</pre></div>

</div>
</div>

<div class="vbox output_wrapper">
<div class="output vbox">


<div class="hbox output_area">
<div class="prompt"></div>
<div class="box-flex1 output_subarea output_display_data">


<pre>

Call:
NULL

Deviance Residuals: 
     Min        1Q    Median        3Q       Max  
-2.34231  -0.43582  -0.00008   0.00010   2.42395  

Coefficients: (45 not defined because of singularities)
                              Estimate Std. Error z value Pr(&gt;|z|)  
(Intercept)                 -6.156e-01  2.122e+02  -0.003   0.9977  
Sexmale                     -1.065e+01  3.548e+03  -0.003   0.9976  
Pclass2                     -4.596e-01  2.869e-01  -1.602   0.1092  
Pclass3                     -5.264e-01  3.407e-01  -1.545   0.1223  
Age                         -3.148e-01  1.749e-01  -1.800   0.0718 .
SibSp                        2.230e-01  6.716e-01   0.332   0.7398  
`I(Embarked == "S")TRUE`    -1.728e-01  1.444e-01  -1.197   0.2315  
`FareGroup10-20`             2.101e-01  2.593e-01   0.810   0.4177  
`FareGroup20-40`             5.142e-01  2.900e-01   1.773   0.0762 .
`FareGroup40+`               4.068e-01  2.876e-01   1.415   0.1572  
FamIDAbelson2               -1.258e-02  1.918e-01  -0.066   0.9477  
FamIDAhlin2                         NA         NA      NA       NA  
FamIDAks2                    6.882e-01  4.025e+02   0.002   0.9986  
FamIDAllison4               -1.181e+00  3.885e+02  -0.003   0.9976  
`FamIDAndersen-Jensen2`      7.511e-01  4.025e+02   0.002   0.9985  
FamIDAndersson7             -1.949e-01  2.170e-01  -0.898   0.3690  
FamIDAndrews2                7.132e-01  4.025e+02   0.002   0.9986  
FamIDAngle2                         NA         NA      NA       NA  
FamIDAppleton3               6.264e-01  4.025e+02   0.002   0.9988  
`FamIDArnold-Franchi2`      -1.072e+00  3.092e+02  -0.003   0.9972  
FamIDAsplund7               -6.467e-02  1.965e-01  -0.329   0.7421  
FamIDAstor2                         NA         NA      NA       NA  
FamIDBackstrom2             -6.081e-01  4.025e+02  -0.002   0.9988  
FamIDBackstrom4              6.584e-01  4.025e+02   0.002   0.9987  
FamIDBaclini4                9.586e-01  3.950e+02   0.002   0.9981  
FamIDBarbara2               -1.085e+00  3.895e+02  -0.003   0.9978  
FamIDBaxter2                -3.857e-02  1.849e-01  -0.209   0.8347  
FamIDBeane2                  8.320e-01  4.025e+02   0.002   0.9984  
FamIDBecker4                 6.901e-01  4.025e+02   0.002   0.9986  
FamIDBeckwith3               1.073e+00  3.164e+02   0.003   0.9973  
FamIDBishop2                 5.893e-01  4.025e+02   0.001   0.9988  
FamIDBoulos3                -7.564e-01  4.025e+02  -0.002   0.9985  
FamIDBourke3                -1.297e+00  3.146e+02  -0.004   0.9967  
FamIDBowerman2               6.842e-01  4.025e+02   0.002   0.9986  
FamIDBraund2                        NA         NA      NA       NA  
FamIDBrown3                  3.452e-02  2.015e-01   0.171   0.8640  
FamIDBryhl2                 -6.388e-01  4.025e+02  -0.002   0.9987  
FamIDCaldwell3               9.648e-01  3.862e+02   0.002   0.9980  
FamIDCaram2                 -8.146e-01  4.025e+02  -0.002   0.9984  
FamIDCardeza2                7.956e-01  4.025e+02   0.002   0.9984  
FamIDCarter2                -1.067e+00  2.919e+02  -0.004   0.9971  
FamIDCarter4                 1.289e+00  3.194e+02   0.004   0.9968  
FamIDCavendish2             -6.623e-01  4.025e+02  -0.002   0.9987  
FamIDChaffee2                       NA         NA      NA       NA  
FamIDChambers2               1.060e+00  3.146e+02   0.003   0.9973  
FamIDChapman2                       NA         NA      NA       NA  
FamIDChibnall2                      NA         NA      NA       NA  
FamIDChristy3                7.125e-01  4.025e+02   0.002   0.9986  
FamIDChronopoulos2          -6.279e-01  4.025e+02  -0.002   0.9988  
FamIDClark2                         NA         NA      NA       NA  
FamIDClarke2                 6.453e-01  4.025e+02   0.002   0.9987  
FamIDCollyer3                7.044e-02  2.012e-01   0.350   0.7262  
FamIDCompton3                6.772e-01  4.025e+02   0.002   0.9987  
FamIDCornell3                       NA         NA      NA       NA  
FamIDCoutts3                 7.242e-01  4.025e+02   0.002   0.9986  
FamIDCribb2                 -5.894e-01  4.025e+02  -0.001   0.9988  
FamIDCrosby3                 4.598e-02  1.763e-01   0.261   0.7943  
FamIDCumings2                6.064e-01  4.025e+02   0.002   0.9988  
FamIDDanbom3                -1.059e+00  3.096e+02  -0.003   0.9973  
FamIDDavidson2              -6.668e-01  4.025e+02  -0.002   0.9987  
FamIDDavidson4                      NA         NA      NA       NA  
FamIDDavies3                 3.841e-02  1.639e-01   0.234   0.8148  
FamIDDavison2                6.643e-01  4.025e+02   0.002   0.9987  
FamIDDean4                   3.913e-02  1.693e-01   0.231   0.8172  
FamIDdelCarlo2              -6.496e-01  4.025e+02  -0.002   0.9987  
FamIDdeMessemaeker2          6.769e-01  4.025e+02   0.002   0.9987  
FamIDDick2                   1.062e+00  3.064e+02   0.003   0.9972  
FamIDDodge3                  6.751e-01  4.025e+02   0.002   0.9987  
FamIDDoling2                 7.141e-01  4.025e+02   0.002   0.9986  
FamIDDouglas2               -6.642e-01  4.025e+02  -0.002   0.9987  
FamIDDouglas3                       NA         NA      NA       NA  
FamIDDrew3                          NA         NA      NA       NA  
FamIDDuffGordon2             1.065e+00  3.082e+02   0.003   0.9972  
`FamIDDurany More2`          7.266e-01  4.025e+02   0.002   0.9986  
FamIDDyker2                         NA         NA      NA       NA  
FamIDEarnshaw2                      NA         NA      NA       NA  
FamIDElias3                 -6.165e-01  4.025e+02  -0.002   0.9988  
FamIDEustis2                 6.907e-01  4.025e+02   0.002   0.9986  
FamIDFaunthorpe2             6.462e-01  4.025e+02   0.002   0.9987  
FamIDFord5                  -1.315e+00  3.326e+02  -0.004   0.9968  
FamIDFortune6               -3.674e-02  2.089e-01  -0.176   0.8604  
FamIDFrauenthal2             6.064e-01  4.025e+02   0.002   0.9988  
FamIDFrauenthal3             8.513e-01  4.025e+02   0.002   0.9983  
FamIDFrolicher3              6.698e-01  4.025e+02   0.002   0.9987  
`FamIDFrolicher-Stehli3`     8.093e-01  4.025e+02   0.002   0.9984  
FamIDFutrelle2              -3.060e-02  1.936e-01  -0.158   0.8744  
FamIDGale2                  -6.307e-01  4.025e+02  -0.002   0.9987  
FamIDGibson2                        NA         NA      NA       NA  
FamIDGiles2                 -6.156e-01  4.025e+02  -0.002   0.9988  
FamIDGoldenberg2             1.063e+00  3.015e+02   0.004   0.9972  
FamIDGoldsmith3              6.456e-01  4.025e+02   0.002   0.9987  
FamIDGoodwin8               -1.578e+00  3.993e+02  -0.004   0.9968  
FamIDGraham2                 6.467e-01  4.025e+02   0.002   0.9987  
FamIDGreenfield2             7.839e-01  4.025e+02   0.002   0.9984  
FamIDGustafsson3            -8.424e-01  4.018e+02  -0.002   0.9983  
FamIDHagland2               -6.171e-01  4.025e+02  -0.002   0.9988  
FamIDHakkarainen2                   NA         NA      NA       NA  
FamIDHamalainen3             9.976e-01  3.930e+02   0.003   0.9980  
FamIDHansen2                -5.939e-01  4.025e+02  -0.001   0.9988  
FamIDHansen3                -6.079e-01  4.025e+02  -0.002   0.9988  
FamIDHarder2                 7.778e-01  4.025e+02   0.002   0.9985  
FamIDHarper2                 2.196e-01  2.276e-01   0.965   0.3347  
FamIDHarris2                -2.551e-02  1.979e-01  -0.129   0.8974  
FamIDHart3                   8.158e-02  2.036e-01   0.401   0.6886  
FamIDHays3                   6.334e-01  4.025e+02   0.002   0.9987  
FamIDHerman4                 7.200e-01  4.025e+02   0.002   0.9986  
FamIDHickman3               -9.052e-01  4.021e+02  -0.002   0.9982  
FamIDHiltunen3                      NA         NA      NA       NA  
FamIDHippach2                9.129e-01  3.897e+02   0.002   0.9981  
FamIDHirvonen2               7.241e-01  4.025e+02   0.002   0.9986  
FamIDHirvonen3                      NA         NA      NA       NA  
FamIDHocking4               -6.217e-01  4.025e+02  -0.002   0.9988  
FamIDHocking5                       NA         NA      NA       NA  
FamIDHogeboom2                      NA         NA      NA       NA  
FamIDHold2                  -6.217e-01  4.025e+02  -0.002   0.9988  
FamIDHolverson2             -6.569e-01  4.025e+02  -0.002   0.9987  
FamIDHoward2                        NA         NA      NA       NA  
FamIDHoyt2                   6.181e-01  4.025e+02   0.002   0.9988  
FamIDIlmakangas2            -7.080e-01  4.025e+02  -0.002   0.9986  
FamIDJacobsohn2             -6.235e-01  4.025e+02  -0.002   0.9988  
FamIDJacobsohn4              6.338e-01  4.025e+02   0.002   0.9987  
FamIDJefferys3                      NA         NA      NA       NA  
FamIDJensen2                -6.020e-01  4.025e+02  -0.001   0.9988  
FamIDJohnson3                1.017e+00  3.987e+02   0.003   0.9980  
FamIDJohnston4              -7.571e-01  4.025e+02  -0.002   0.9985  
FamIDJussila2               -1.006e+00  4.022e+02  -0.003   0.9980  
FamIDKantor2                 7.818e-03  1.951e-01   0.040   0.9680  
FamIDKarun2                         NA         NA      NA       NA  
FamIDKenyon2                 6.064e-01  4.025e+02   0.002   0.9988  
FamIDKhalil2                        NA         NA      NA       NA  
FamIDKiernan2               -6.120e-01  4.025e+02  -0.002   0.9988  
FamIDKimball2                8.075e-01  4.025e+02   0.002   0.9984  
FamIDKink3                  -6.018e-01  4.025e+02  -0.001   0.9988  
`FamIDKink-Heilmann3`        6.991e-01  4.025e+02   0.002   0.9986  
`FamIDKink-Heilmann5`               NA         NA      NA       NA  
FamIDKlasen3                -6.011e-01  4.025e+02  -0.001   0.9988  
FamIDLahtinen3              -8.210e-01  4.025e+02  -0.002   0.9984  
FamIDLaroche4                4.529e-02  2.065e-01   0.219   0.8264  
FamIDLefebre5               -1.332e+00  3.992e+02  -0.003   0.9973  
FamIDLennon2                -6.315e-01  4.025e+02  -0.002   0.9987  
FamIDLindell2               -6.045e-01  4.025e+02  -0.002   0.9988  
FamIDLindqvist2              8.652e-01  4.025e+02   0.002   0.9983  
FamIDLines2                  6.704e-01  4.025e+02   0.002   0.9987  
FamIDLobb2                  -6.099e-01  4.025e+02  -0.002   0.9988  
FamIDLouch2                  6.579e-01  4.025e+02   0.002   0.9987  
FamIDMadill2                 6.779e-01  4.025e+02   0.002   0.9987  
FamIDMallet3                 3.085e-02  1.749e-01   0.176   0.8600  
FamIDMarvin2                -6.776e-01  4.025e+02  -0.002   0.9987  
FamIDMcCoy3                  1.072e+00  3.278e+02   0.003   0.9974  
FamIDMcNamee2               -6.153e-01  4.025e+02  -0.002   0.9988  
FamIDMellinger2                     NA         NA      NA       NA  
FamIDMeyer2                 -6.498e-02  1.959e-01  -0.332   0.7401  
FamIDMinahan2                6.718e-01  4.025e+02   0.002   0.9987  
FamIDMinahan3               -6.330e-01  4.025e+02  -0.002   0.9987  
FamIDMock2                          NA         NA      NA       NA  
FamIDMoor2                   1.008e+00  3.893e+02   0.003   0.9979  
FamIDMoran2                  2.453e-02  1.613e-01   0.152   0.8791  
FamIDMoubarek3               1.027e+00  4.022e+02   0.003   0.9980  
FamIDMurphy2                 7.197e-01  4.025e+02   0.002   0.9986  
FamIDNakid3                  1.116e+00  3.201e+02   0.003   0.9972  
FamIDNasser2                -1.989e-02  2.010e-01  -0.099   0.9212  
FamIDNatsch2                -6.764e-01  4.025e+02  -0.002   0.9987  
FamIDNavratil3               6.998e-01  4.025e+02   0.002   0.9986  
FamIDNewell2                 9.419e-01  4.019e+02   0.002   0.9981  
FamIDNewell3                -6.491e-01  4.025e+02  -0.002   0.9987  
FamIDNewsom3                 6.731e-01  4.025e+02   0.002   0.9987  
FamIDNicholls3              -6.442e-01  4.025e+02  -0.002   0.9987  
`FamIDNicola-Yarred2`        1.010e+00  3.993e+02   0.003   0.9980  
`FamIDO'Brien2`              6.498e-01  4.025e+02   0.002   0.9987  
FamIDOlsen2                 -5.716e-01  4.025e+02  -0.001   0.9989  
FamIDOstby2                         NA         NA      NA       NA  
FamIDPalsson5               -1.585e+00  3.966e+02  -0.004   0.9968  
FamIDPanula6                -1.702e+00  3.386e+02  -0.005   0.9960  
FamIDParrish2                6.730e-01  4.025e+02   0.002   0.9987  
FamIDPeacock3                       NA         NA      NA       NA  
FamIDPears2                 -4.395e-02  1.963e-01  -0.224   0.8228  
`FamIDPenascoy Castellana2` -7.452e-02  1.935e-01  -0.385   0.7001  
FamIDPersson2                8.697e-01  4.025e+02   0.002   0.9983  
FamIDPeter3                  9.473e-01  3.850e+02   0.002   0.9980  
FamIDPetterson2             -5.948e-01  4.025e+02  -0.001   0.9988  
FamIDPhillips2                      NA         NA      NA       NA  
FamIDPotter2                 6.305e-01  4.025e+02   0.002   0.9988  
FamIDQuick3                  6.918e-01  4.025e+02   0.002   0.9986  
FamIDRenouf2                        NA         NA      NA       NA  
FamIDRenouf4                 6.313e-01  4.025e+02   0.002   0.9987  
FamIDRice6                  -1.799e+00  4.005e+02  -0.004   0.9964  
FamIDRichards3               7.265e-01  4.025e+02   0.002   0.9986  
FamIDRichards6               6.606e-01  4.025e+02   0.002   0.9987  
FamIDRobert2                 6.332e-01  4.025e+02   0.002   0.9987  
FamIDRobins2                -7.777e-01  4.025e+02  -0.002   0.9985  
FamIDRosblom3               -1.075e+00  3.238e+02  -0.003   0.9974  
FamIDRothschild2                    NA         NA      NA       NA  
FamIDRyerson5                6.504e-01  4.025e+02   0.002   0.9987  
FamIDSage11                 -1.752e+00  3.578e+02  -0.005   0.9961  
FamIDSamaan3                -6.662e-01  4.025e+02  -0.002   0.9987  
FamIDSandstrom3              9.893e-01  3.912e+02   0.003   0.9980  
FamIDSchabert2                      NA         NA      NA       NA  
FamIDShelley2                6.505e-01  4.025e+02   0.002   0.9987  
FamIDSilven3                 7.408e-01  4.025e+02   0.002   0.9985  
FamIDSilvey2                -1.979e-02  1.986e-01  -0.100   0.9206  
FamIDSkoog6                 -1.723e+00  3.454e+02  -0.005   0.9960  
FamIDSmith2                         NA         NA      NA       NA  
FamIDSnyder2                        NA         NA      NA       NA  
FamIDSolo                    7.121e-01  1.284e+00   0.555   0.5791  
FamIDSpedden3                       NA         NA      NA       NA  
FamIDSpencer2                5.920e-01  4.025e+02   0.001   0.9988  
FamIDStengel2                       NA         NA      NA       NA  
FamIDStephenson2             6.190e-01  4.025e+02   0.002   0.9988  
FamIDStraus2                        NA         NA      NA       NA  
FamIDStrom2                 -7.404e-01  4.025e+02  -0.002   0.9985  
FamIDStrom3                 -7.939e-01  4.025e+02  -0.002   0.9984  
FamIDTaussig3                9.304e-01  3.843e+02   0.002   0.9981  
FamIDTaylor2                 1.082e+00  3.019e+02   0.004   0.9971  
FamIDThayer3                 1.040e+00  3.203e+02   0.003   0.9974  
FamIDThomas2                 7.349e-01  4.025e+02   0.002   0.9985  
FamIDThomas3                        NA         NA      NA       NA  
FamIDThorneycroft2           3.334e-02  1.905e-01   0.175   0.8611  
FamIDTouma3                         NA         NA      NA       NA  
FamIDTurpin2                -1.096e+00  3.112e+02  -0.004   0.9972  
FamIDvanBilliard3           -5.926e-01  4.025e+02  -0.001   0.9988  
FamIDVanderPlanke2          -7.921e-01  4.025e+02  -0.002   0.9984  
FamIDVanderPlanke3          -9.930e-01  3.288e+02  -0.003   0.9976  
FamIDVanderPlanke4                  NA         NA      NA       NA  
FamIDVanImpe3               -1.127e+00  3.840e+02  -0.003   0.9977  
FamIDWare2                          NA         NA      NA       NA  
FamIDWarren2                 6.262e-01  4.025e+02   0.002   0.9988  
FamIDWeisz2                  6.462e-01  4.025e+02   0.002   0.9987  
FamIDWells3                  6.936e-01  4.025e+02   0.002   0.9986  
FamIDWest4                   6.739e-02  2.041e-01   0.330   0.7412  
FamIDWhite2                 -6.383e-01  4.025e+02  -0.002   0.9987  
FamIDWick3                   6.923e-01  4.025e+02   0.002   0.9986  
FamIDWidener3               -6.770e-01  4.025e+02  -0.002   0.9987  
FamIDWiklund2                       NA         NA      NA       NA  
FamIDWilkes2                        NA         NA      NA       NA  
FamIDWilliams2              -6.554e-01  4.025e+02  -0.002   0.9987  
FamIDYasbeck2                       NA         NA      NA       NA  
FamIDZabour2                -7.448e-01  4.025e+02  -0.002   0.9985  
TitleMiss                   -8.980e+00  3.017e+03  -0.003   0.9976  
TitleMr                     -1.399e+00  7.872e-01  -1.778   0.0755 .
TitleMrs                    -7.107e+00  2.608e+03  -0.003   0.9978  
TitleNoble                  -5.585e-01  2.807e-01  -1.989   0.0467 *
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

(Dispersion parameter for binomial family taken to be 1)

    Null deviance: 950.86  on 713  degrees of freedom
Residual deviance: 373.54  on 518  degrees of freedom
AIC: 765.54

Number of Fisher Scoring iterations: 18


</pre>

</div>
</div>

</div>
</div>

</div>
<div class="text_cell_render border-box-sizing rendered_html">
<p>So that didn't really help. Let's try one last trick, <strong>Interaction</strong>. Let's work in an interaction effect between passenger class and sex, as passenger class showed a much bigger difference in survival rate amongst the women compared to the men (i.e. Higher class women were much more likely to survive than lower class women, whereas first class Men were more likely to survive than 2nd or 3rd class men, but not by the same margin as amongst the women). We saw this during our initial visualizations. Besides Pclass and Sex have been the biggest determining factors so far.</p>
</div>
<div class="cell border-box-sizing code_cell vbox">
<div class="input hbox">
<div class="prompt input_prompt">
In [287]:
</div>
<div class="input_area box-flex1">
<div class="highlight"><pre><span class="o">%%</span><span class="k">R</span>
<span class="c">#Let's work in an interaction between Pclass and Sex.</span>
<span class="nb">set</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">35</span><span class="p">)</span> 

<span class="n">logit</span><span class="o">.</span><span class="n">tune3</span><span class="o">&lt;-</span><span class="n">train</span><span class="p">(</span><span class="n">Survived</span> <span class="o">~</span> <span class="n">Sex</span> <span class="o">+</span> <span class="n">Pclass</span> <span class="o">+</span> <span class="n">Sex</span><span class="p">:</span><span class="n">Pclass</span> <span class="o">+</span> <span class="n">Age</span> <span class="o">+</span> <span class="n">SibSp</span> <span class="o">+</span> <span class="n">Embarked</span> <span class="o">+</span> <span class="n">FareGroup</span> <span class="o">+</span> <span class="n">FamID</span> <span class="o">+</span> <span class="n">Title</span><span class="p">,</span>
                <span class="n">data</span><span class="o">=</span><span class="n">train</span><span class="o">.</span><span class="n">set</span><span class="p">,</span>
                <span class="n">method</span><span class="o">=</span><span class="s">'glm'</span><span class="p">,</span>
                <span class="n">preProcess</span> <span class="o">=</span> <span class="n">c</span><span class="p">(</span><span class="s">"center"</span><span class="p">,</span> <span class="s">"scale"</span><span class="p">),</span>
                <span class="n">trControl</span><span class="o">=</span><span class="n">tenfoldcv</span><span class="p">)</span>

<span class="n">logit</span><span class="o">.</span><span class="n">tune3</span>
</pre></div>

</div>
</div>

<div class="vbox output_wrapper">
<div class="output vbox">


<div class="hbox output_area">
<div class="prompt"></div>
<div class="box-flex1 output_subarea output_display_data">


<pre>
Generalized Linear Model 

714 samples
 14 predictors
  2 classes: '0', '1' 

Pre-processing: centered, scaled 
Resampling: Cross-Validated (10 fold, repeated 3 times) 

Summary of sample sizes: 643, 643, 643, 642, 643, 643, ... 

Resampling results

  Accuracy   Kappa      Accuracy SD  Kappa SD 
  0.7904864  0.5472096  0.05401862   0.1249195

 

</pre>

</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell vbox">
<div class="input hbox">
<div class="prompt input_prompt">
In [288]:
</div>
<div class="input_area box-flex1">
<div class="highlight"><pre><span class="o">%%</span><span class="k">R</span>
<span class="n">summary</span><span class="p">(</span><span class="n">logit</span><span class="o">.</span><span class="n">tune3</span><span class="p">)</span>
</pre></div>

</div>
</div>

<div class="vbox output_wrapper">
<div class="output vbox">


<div class="hbox output_area">
<div class="prompt"></div>
<div class="box-flex1 output_subarea output_display_data">


<pre>

Call:
NULL

Deviance Residuals: 
     Min        1Q    Median        3Q       Max  
-2.85112  -0.46296  -0.00009   0.00009   2.54282  

Coefficients: (45 not defined because of singularities)
                              Estimate Std. Error z value Pr(&gt;|z|)  
(Intercept)                 -5.350e-01  2.135e+02  -0.003   0.9980  
Sexmale                     -1.099e+01  3.407e+03  -0.003   0.9974  
Pclass2                     -7.112e-01  6.345e-01  -1.121   0.2623  
Pclass3                     -1.487e+00  7.122e-01  -2.088   0.0368 *
Age                         -3.107e-01  1.799e-01  -1.727   0.0842 .
SibSp                        2.551e-02  6.888e-01   0.037   0.9705  
EmbarkedQ                    1.342e-01  1.615e-01   0.831   0.4058  
EmbarkedS                   -1.049e-01  1.818e-01  -0.577   0.5640  
`FareGroup10-20`             1.840e-01  2.615e-01   0.704   0.4816  
`FareGroup20-40`             5.310e-01  2.953e-01   1.798   0.0721 .
`FareGroup40+`               3.425e-01  3.013e-01   1.137   0.2556  
FamIDAbelson2               -2.723e-02  1.935e-01  -0.141   0.8881  
FamIDAhlin2                         NA         NA      NA       NA  
FamIDAks2                    7.047e-01  4.025e+02   0.002   0.9986  
FamIDAllison4               -1.250e+00  3.928e+02  -0.003   0.9975  
`FamIDAndersen-Jensen2`      7.543e-01  4.025e+02   0.002   0.9985  
FamIDAndersson7             -1.563e-01  1.910e-01  -0.818   0.4132  
FamIDAndrews2                6.498e-01  4.025e+02   0.002   0.9987  
FamIDAngle2                         NA         NA      NA       NA  
FamIDAppleton3               5.904e-01  4.025e+02   0.001   0.9988  
`FamIDArnold-Franchi2`      -1.044e+00  3.351e+02  -0.003   0.9975  
FamIDAsplund7               -3.992e-02  1.723e-01  -0.232   0.8168  
FamIDAstor2                         NA         NA      NA       NA  
FamIDBackstrom2             -6.261e-01  4.025e+02  -0.002   0.9988  
FamIDBackstrom4              6.981e-01  4.025e+02   0.002   0.9986  
FamIDBaclini4                9.878e-01  3.963e+02   0.002   0.9980  
FamIDBarbara2               -1.059e+00  3.933e+02  -0.003   0.9979  
FamIDBaxter2                -7.557e-02  1.924e-01  -0.393   0.6945  
FamIDBeane2                  8.272e-01  4.025e+02   0.002   0.9984  
FamIDBecker4                 7.046e-01  4.025e+02   0.002   0.9986  
FamIDBeckwith3               1.064e+00  3.177e+02   0.003   0.9973  
FamIDBishop2                 5.524e-01  4.025e+02   0.001   0.9989  
FamIDBoulos3                -7.450e-01  4.025e+02  -0.002   0.9985  
FamIDBourke3                -1.292e+00  3.411e+02  -0.004   0.9970  
FamIDBowerman2               6.143e-01  4.025e+02   0.002   0.9988  
FamIDBraund2                        NA         NA      NA       NA  
FamIDBrown3                  1.151e-02  2.058e-01   0.056   0.9554  
FamIDBryhl2                 -6.435e-01  4.025e+02  -0.002   0.9987  
FamIDCaldwell3               9.558e-01  3.665e+02   0.003   0.9979  
FamIDCaram2                 -7.831e-01  4.025e+02  -0.002   0.9984  
FamIDCardeza2                7.874e-01  4.025e+02   0.002   0.9984  
FamIDCarter2                -1.102e+00  2.822e+02  -0.004   0.9969  
FamIDCarter4                 1.278e+00  3.216e+02   0.004   0.9968  
FamIDCavendish2             -6.692e-01  4.025e+02  -0.002   0.9987  
FamIDChaffee2                       NA         NA      NA       NA  
FamIDChambers2               1.051e+00  3.161e+02   0.003   0.9973  
FamIDChapman2                       NA         NA      NA       NA  
FamIDChibnall2                      NA         NA      NA       NA  
FamIDChristy3                6.650e-01  4.025e+02   0.002   0.9987  
FamIDChronopoulos2          -6.402e-01  4.025e+02  -0.002   0.9987  
FamIDClark2                         NA         NA      NA       NA  
FamIDClarke2                 6.180e-01  4.025e+02   0.002   0.9988  
FamIDCollyer3                2.449e-02  2.003e-01   0.122   0.9027  
FamIDCompton3                6.197e-01  4.025e+02   0.002   0.9988  
FamIDCornell3                       NA         NA      NA       NA  
FamIDCoutts3                 7.184e-01  4.025e+02   0.002   0.9986  
FamIDCribb2                 -6.146e-01  4.025e+02  -0.002   0.9988  
FamIDCrosby3                -8.693e-03  1.950e-01  -0.045   0.9644  
FamIDCumings2                5.693e-01  4.025e+02   0.001   0.9989  
FamIDDanbom3                -1.032e+00  3.356e+02  -0.003   0.9975  
FamIDDavidson2              -6.737e-01  4.025e+02  -0.002   0.9987  
FamIDDavidson4                      NA         NA      NA       NA  
FamIDDavies3                 3.311e-02  1.406e-01   0.235   0.8138  
FamIDDavison2                6.902e-01  4.025e+02   0.002   0.9986  
FamIDDean4                   1.679e-02  1.481e-01   0.113   0.9097  
FamIDdelCarlo2              -6.487e-01  4.025e+02  -0.002   0.9987  
FamIDdeMessemaeker2          7.026e-01  4.025e+02   0.002   0.9986  
FamIDDick2                   1.053e+00  3.083e+02   0.003   0.9973  
FamIDDodge3                  6.735e-01  4.025e+02   0.002   0.9987  
FamIDDoling2                 6.597e-01  4.025e+02   0.002   0.9987  
FamIDDouglas2               -6.656e-01  4.025e+02  -0.002   0.9987  
FamIDDouglas3                       NA         NA      NA       NA  
FamIDDrew3                          NA         NA      NA       NA  
FamIDDuffGordon2             1.063e+00  3.093e+02   0.003   0.9973  
`FamIDDurany More2`          6.887e-01  4.025e+02   0.002   0.9986  
FamIDDyker2                         NA         NA      NA       NA  
FamIDEarnshaw2                      NA         NA      NA       NA  
FamIDElias3                 -6.311e-01  4.025e+02  -0.002   0.9987  
FamIDEustis2                 6.331e-01  4.025e+02   0.002   0.9987  
FamIDFaunthorpe2             6.189e-01  4.025e+02   0.002   0.9988  
FamIDFord5                  -1.295e+00  3.571e+02  -0.004   0.9971  
FamIDFortune6               -7.440e-02  2.115e-01  -0.352   0.7250  
FamIDFrauenthal2             5.638e-01  4.025e+02   0.001   0.9989  
FamIDFrauenthal3             8.475e-01  4.025e+02   0.002   0.9983  
FamIDFrolicher3              6.055e-01  4.025e+02   0.002   0.9988  
`FamIDFrolicher-Stehli3`     8.078e-01  4.025e+02   0.002   0.9984  
FamIDFutrelle2              -6.571e-02  2.075e-01  -0.317   0.7515  
FamIDGale2                  -6.355e-01  4.025e+02  -0.002   0.9987  
FamIDGibson2                        NA         NA      NA       NA  
FamIDGiles2                 -6.164e-01  4.025e+02  -0.002   0.9988  
FamIDGoldenberg2             1.061e+00  3.036e+02   0.003   0.9972  
FamIDGoldsmith3              6.675e-01  4.025e+02   0.002   0.9987  
FamIDGoodwin8               -1.520e+00  3.999e+02  -0.004   0.9970  
FamIDGraham2                 5.967e-01  4.025e+02   0.001   0.9988  
FamIDGreenfield2             7.758e-01  4.025e+02   0.002   0.9985  
FamIDGustafsson3            -8.615e-01  4.018e+02  -0.002   0.9983  
FamIDHagland2               -6.350e-01  4.025e+02  -0.002   0.9987  
FamIDHakkarainen2                   NA         NA      NA       NA  
FamIDHamalainen3             9.973e-01  3.640e+02   0.003   0.9978  
FamIDHansen2                -6.143e-01  4.025e+02  -0.002   0.9988  
FamIDHansen3                -6.191e-01  4.025e+02  -0.002   0.9988  
FamIDHarder2                 7.767e-01  4.025e+02   0.002   0.9985  
FamIDHarper2                 1.991e-01  2.017e-01   0.987   0.3236  
FamIDHarris2                -6.069e-02  2.139e-01  -0.284   0.7766  
FamIDHart3                   3.698e-02  2.039e-01   0.181   0.8561  
FamIDHays3                   5.905e-01  4.025e+02   0.001   0.9988  
FamIDHerman4                 6.800e-01  4.025e+02   0.002   0.9987  
FamIDHickman3               -8.913e-01  4.021e+02  -0.002   0.9982  
FamIDHiltunen3                      NA         NA      NA       NA  
FamIDHippach2                8.313e-01  3.934e+02   0.002   0.9983  
FamIDHirvonen2               7.229e-01  4.025e+02   0.002   0.9986  
FamIDHirvonen3                      NA         NA      NA       NA  
FamIDHocking4               -6.155e-01  4.025e+02  -0.002   0.9988  
FamIDHocking5                       NA         NA      NA       NA  
FamIDHogeboom2                      NA         NA      NA       NA  
FamIDHold2                  -6.266e-01  4.025e+02  -0.002   0.9988  
FamIDHolverson2             -6.639e-01  4.025e+02  -0.002   0.9987  
FamIDHoward2                        NA         NA      NA       NA  
FamIDHoyt2                   5.754e-01  4.025e+02   0.001   0.9989  
FamIDIlmakangas2            -7.049e-01  4.025e+02  -0.002   0.9986  
FamIDJacobsohn2             -6.284e-01  4.025e+02  -0.002   0.9988  
FamIDJacobsohn4              6.136e-01  4.025e+02   0.002   0.9988  
FamIDJefferys3                      NA         NA      NA       NA  
FamIDJensen2                -6.223e-01  4.025e+02  -0.002   0.9988  
FamIDJohnson3                1.018e+00  4.013e+02   0.003   0.9980  
FamIDJohnston4              -7.554e-01  4.025e+02  -0.002   0.9985  
FamIDJussila2               -1.002e+00  4.022e+02  -0.002   0.9980  
FamIDKantor2                -1.484e-02  1.977e-01  -0.075   0.9401  
FamIDKarun2                         NA         NA      NA       NA  
FamIDKenyon2                 5.638e-01  4.025e+02   0.001   0.9989  
FamIDKhalil2                        NA         NA      NA       NA  
FamIDKiernan2               -6.449e-01  4.025e+02  -0.002   0.9987  
FamIDKimball2                8.006e-01  4.025e+02   0.002   0.9984  
FamIDKink3                  -6.152e-01  4.025e+02  -0.002   0.9988  
`FamIDKink-Heilmann3`        6.940e-01  4.025e+02   0.002   0.9986  
`FamIDKink-Heilmann5`               NA         NA      NA       NA  
FamIDKlasen3                -6.214e-01  4.025e+02  -0.002   0.9988  
FamIDLahtinen3              -8.482e-01  4.025e+02  -0.002   0.9983  
FamIDLaroche4                2.688e-02  2.057e-01   0.131   0.8960  
FamIDLefebre5               -1.312e+00  4.011e+02  -0.003   0.9974  
FamIDLennon2                -6.620e-01  4.025e+02  -0.002   0.9987  
FamIDLindell2               -6.226e-01  4.025e+02  -0.002   0.9988  
FamIDLindqvist2              8.448e-01  4.025e+02   0.002   0.9983  
FamIDLines2                  5.931e-01  4.025e+02   0.001   0.9988  
FamIDLobb2                  -6.279e-01  4.025e+02  -0.002   0.9988  
FamIDLouch2                  6.305e-01  4.025e+02   0.002   0.9988  
FamIDMadill2                 6.081e-01  4.025e+02   0.002   0.9988  
FamIDMallet3                 3.582e-02  1.574e-01   0.228   0.8200  
FamIDMarvin2                -6.843e-01  4.025e+02  -0.002   0.9986  
FamIDMcCoy3                  1.042e+00  3.470e+02   0.003   0.9976  
FamIDMcNamee2               -6.332e-01  4.025e+02  -0.002   0.9987  
FamIDMellinger2                     NA         NA      NA       NA  
FamIDMeyer2                 -9.190e-02  2.106e-01  -0.436   0.6625  
FamIDMinahan2                5.962e-01  4.025e+02   0.001   0.9988  
FamIDMinahan3               -6.493e-01  4.025e+02  -0.002   0.9987  
FamIDMock2                          NA         NA      NA       NA  
FamIDMoor2                   1.003e+00  3.969e+02   0.003   0.9980  
FamIDMoran2                 -7.498e-03  1.385e-01  -0.054   0.9568  
FamIDMoubarek3               1.027e+00  4.022e+02   0.003   0.9980  
FamIDMurphy2                 7.128e-01  4.025e+02   0.002   0.9986  
FamIDNakid3                  1.104e+00  3.350e+02   0.003   0.9974  
FamIDNasser2                -3.445e-02  2.056e-01  -0.168   0.8669  
FamIDNatsch2                -6.921e-01  4.025e+02  -0.002   0.9986  
FamIDNavratil3               7.073e-01  4.025e+02   0.002   0.9986  
FamIDNewell2                 8.609e-01  4.019e+02   0.002   0.9983  
FamIDNewell3                -6.576e-01  4.025e+02  -0.002   0.9987  
FamIDNewsom3                 5.957e-01  4.025e+02   0.001   0.9988  
FamIDNicholls3              -6.488e-01  4.025e+02  -0.002   0.9987  
`FamIDNicola-Yarred2`        1.019e+00  4.013e+02   0.003   0.9980  
`FamIDO'Brien2`              6.632e-01  4.025e+02   0.002   0.9987  
FamIDOlsen2                 -5.992e-01  4.025e+02  -0.001   0.9988  
FamIDOstby2                         NA         NA      NA       NA  
FamIDPalsson5               -1.559e+00  3.981e+02  -0.004   0.9969  
FamIDPanula6                -1.680e+00  3.489e+02  -0.005   0.9962  
FamIDParrish2                6.385e-01  4.025e+02   0.002   0.9987  
FamIDPeacock3                       NA         NA      NA       NA  
FamIDPears2                 -7.889e-02  2.114e-01  -0.373   0.7090  
`FamIDPenascoy Castellana2` -1.013e-01  2.069e-01  -0.490   0.6243  
FamIDPersson2                8.493e-01  4.025e+02   0.002   0.9983  
FamIDPeter3                  9.624e-01  3.894e+02   0.002   0.9980  
FamIDPetterson2             -6.152e-01  4.025e+02  -0.002   0.9988  
FamIDPhillips2                      NA         NA      NA       NA  
FamIDPotter2                 5.861e-01  4.025e+02   0.001   0.9988  
FamIDQuick3                  6.446e-01  4.025e+02   0.002   0.9987  
FamIDRenouf2                        NA         NA      NA       NA  
FamIDRenouf4                 6.180e-01  4.025e+02   0.002   0.9988  
FamIDRice6                  -1.800e+00  4.008e+02  -0.004   0.9964  
FamIDRichards3               7.379e-01  4.025e+02   0.002   0.9985  
FamIDRichards6               6.443e-01  4.025e+02   0.002   0.9987  
FamIDRobert2                 5.834e-01  4.025e+02   0.001   0.9988  
FamIDRobins2                -7.521e-01  4.025e+02  -0.002   0.9985  
FamIDRosblom3               -1.063e+00  3.483e+02  -0.003   0.9976  
FamIDRothschild2                    NA         NA      NA       NA  
FamIDRyerson5                6.002e-01  4.025e+02   0.001   0.9988  
FamIDSage11                 -1.635e+00  3.694e+02  -0.004   0.9965  
FamIDSamaan3                -6.754e-01  4.025e+02  -0.002   0.9987  
FamIDSandstrom3              1.003e+00  3.942e+02   0.003   0.9980  
FamIDSchabert2                      NA         NA      NA       NA  
FamIDShelley2                6.163e-01  4.025e+02   0.002   0.9988  
FamIDSilven3                 6.904e-01  4.025e+02   0.002   0.9986  
FamIDSilvey2                -5.504e-02  2.148e-01  -0.256   0.7977  
FamIDSkoog6                 -1.697e+00  3.623e+02  -0.005   0.9963  
FamIDSmith2                         NA         NA      NA       NA  
FamIDSnyder2                        NA         NA      NA       NA  
FamIDSolo                    4.404e-01  1.094e+00   0.403   0.6872  
FamIDSpedden3                       NA         NA      NA       NA  
FamIDSpencer2                5.550e-01  4.025e+02   0.001   0.9989  
FamIDStengel2                       NA         NA      NA       NA  
FamIDStephenson2             5.817e-01  4.025e+02   0.001   0.9988  
FamIDStraus2                        NA         NA      NA       NA  
FamIDStrom2                 -7.416e-01  4.025e+02  -0.002   0.9985  
FamIDStrom3                 -7.681e-01  4.025e+02  -0.002   0.9985  
FamIDTaussig3                8.421e-01  3.904e+02   0.002   0.9983  
FamIDTaylor2                 1.073e+00  3.040e+02   0.004   0.9972  
FamIDThayer3                 1.030e+00  3.244e+02   0.003   0.9975  
FamIDThomas2                 7.254e-01  4.025e+02   0.002   0.9986  
FamIDThomas3                        NA         NA      NA       NA  
FamIDThorneycroft2           3.898e-02  1.546e-01   0.252   0.8010  
FamIDTouma3                         NA         NA      NA       NA  
FamIDTurpin2                -1.127e+00  2.917e+02  -0.004   0.9969  
FamIDvanBilliard3           -6.177e-01  4.025e+02  -0.002   0.9988  
FamIDVanderPlanke2          -7.663e-01  4.025e+02  -0.002   0.9985  
FamIDVanderPlanke3          -9.833e-01  3.480e+02  -0.003   0.9977  
FamIDVanderPlanke4                  NA         NA      NA       NA  
FamIDVanImpe3               -1.106e+00  3.902e+02  -0.003   0.9977  
FamIDWare2                          NA         NA      NA       NA  
FamIDWarren2                 5.888e-01  4.025e+02   0.001   0.9988  
FamIDWeisz2                  6.189e-01  4.025e+02   0.002   0.9988  
FamIDWells3                  6.463e-01  4.025e+02   0.002   0.9987  
FamIDWest4                   2.669e-02  2.030e-01   0.132   0.8954  
FamIDWhite2                 -6.523e-01  4.025e+02  -0.002   0.9987  
FamIDWick3                   6.223e-01  4.025e+02   0.002   0.9988  
FamIDWidener3               -6.851e-01  4.025e+02  -0.002   0.9986  
FamIDWiklund2                       NA         NA      NA       NA  
FamIDWilkes2                        NA         NA      NA       NA  
FamIDWilliams2              -6.638e-01  4.025e+02  -0.002   0.9987  
FamIDYasbeck2                       NA         NA      NA       NA  
FamIDZabour2                -7.335e-01  4.025e+02  -0.002   0.9985  
TitleMiss                   -8.526e+00  2.897e+03  -0.003   0.9977  
TitleMr                     -1.242e+00  7.618e-01  -1.630   0.1030  
TitleMrs                    -6.906e+00  2.505e+03  -0.003   0.9978  
TitleNoble                  -5.001e-01  2.775e-01  -1.802   0.0716 .
`Sexmale:Pclass2`            1.211e-01  4.900e-01   0.247   0.8048  
`Sexmale:Pclass3`            1.035e+00  6.352e-01   1.630   0.1031  
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

(Dispersion parameter for binomial family taken to be 1)

    Null deviance: 950.86  on 713  degrees of freedom
Residual deviance: 366.58  on 515  degrees of freedom
AIC: 764.58

Number of Fisher Scoring iterations: 18


</pre>

</div>
</div>

</div>
</div>

</div>
<div class="text_cell_render border-box-sizing rendered_html">
<p>So we did a little bit better. I would just like to test a theory. We manufactured the FamilyID and have been doing well so far. What happens if we take it out? Will we do worse or better? Let's check it out.</p>
</div>
<div class="cell border-box-sizing code_cell vbox">
<div class="input hbox">
<div class="prompt input_prompt">
In [289]:
</div>
<div class="input_area box-flex1">
<div class="highlight"><pre><span class="o">%%</span><span class="k">R</span>
<span class="c">#Let's work in an interaction between Pclass and Sex.</span>
<span class="nb">set</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">35</span><span class="p">)</span> 

<span class="n">logit</span><span class="o">.</span><span class="n">tune4</span><span class="o">&lt;-</span><span class="n">train</span><span class="p">(</span><span class="n">Survived</span> <span class="o">~</span> <span class="n">Sex</span> <span class="o">+</span> <span class="n">Pclass</span> <span class="o">+</span> <span class="n">Sex</span><span class="p">:</span><span class="n">Pclass</span> <span class="o">+</span> <span class="n">Age</span> <span class="o">+</span> <span class="n">SibSp</span> <span class="o">+</span> <span class="n">Embarked</span> <span class="o">+</span> <span class="n">FareGroup</span> <span class="o">+</span> <span class="n">Title</span><span class="p">,</span>
                <span class="n">data</span><span class="o">=</span><span class="n">train</span><span class="o">.</span><span class="n">set</span><span class="p">,</span>
                <span class="n">method</span><span class="o">=</span><span class="s">'glm'</span><span class="p">,</span>
                <span class="n">preProcess</span> <span class="o">=</span> <span class="n">c</span><span class="p">(</span><span class="s">"center"</span><span class="p">,</span> <span class="s">"scale"</span><span class="p">),</span>
                <span class="n">trControl</span><span class="o">=</span><span class="n">tenfoldcv</span><span class="p">)</span>

<span class="n">logit</span><span class="o">.</span><span class="n">tune4</span>
</pre></div>

</div>
</div>

<div class="vbox output_wrapper">
<div class="output vbox">


<div class="hbox output_area">
<div class="prompt"></div>
<div class="box-flex1 output_subarea output_display_data">


<pre>
Generalized Linear Model 

714 samples
 14 predictors
  2 classes: '0', '1' 

Pre-processing: centered, scaled 
Resampling: Cross-Validated (10 fold, repeated 3 times) 

Summary of sample sizes: 643, 643, 643, 642, 643, 643, ... 

Resampling results

  Accuracy   Kappa      Accuracy SD  Kappa SD  
  0.8123305  0.5934912  0.04130739   0.09243173

 

</pre>

</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell vbox">
<div class="input hbox">
<div class="prompt input_prompt">
In [290]:
</div>
<div class="input_area box-flex1">
<div class="highlight"><pre><span class="o">%%</span><span class="k">R</span>
<span class="n">summary</span><span class="p">(</span><span class="n">logit</span><span class="o">.</span><span class="n">tune4</span><span class="p">)</span>
</pre></div>

</div>
</div>

<div class="vbox output_wrapper">
<div class="output vbox">


<div class="hbox output_area">
<div class="prompt"></div>
<div class="box-flex1 output_subarea output_display_data">


<pre>

Call:
NULL

Deviance Residuals: 
    Min       1Q   Median       3Q      Max  
-2.6591  -0.5397  -0.4099   0.3937   2.4194  

Coefficients:
                   Estimate Std. Error z value Pr(&gt;|z|)    
(Intercept)        -0.56336    0.12309  -4.577 4.72e-06 ***
Sexmale            -8.13159  278.33333  -0.029 0.976693    
Pclass2            -0.36485    0.33842  -1.078 0.280987    
Pclass3            -1.62269    0.37865  -4.285 1.82e-05 ***
Age                -0.30128    0.13506  -2.231 0.025693 *  
SibSp              -0.62972    0.17467  -3.605 0.000312 ***
EmbarkedQ           0.04973    0.11805   0.421 0.673568    
EmbarkedS          -0.17619    0.12541  -1.405 0.160047    
`FareGroup10-20`    0.07364    0.14908   0.494 0.621326    
`FareGroup20-40`   -0.01342    0.17629  -0.076 0.939314    
`FareGroup40+`      0.11277    0.22144   0.509 0.610572    
TitleMiss          -6.75940  236.67998  -0.029 0.977216    
TitleMr            -1.55762    0.29962  -5.199 2.01e-07 ***
TitleMrs           -5.78595  204.63657  -0.028 0.977443    
TitleNoble         -0.46573    0.14315  -3.253 0.001140 ** 
`Sexmale:Pclass2`  -0.32045    0.29394  -1.090 0.275630    
`Sexmale:Pclass3`   0.65008    0.35598   1.826 0.067823 .  
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

(Dispersion parameter for binomial family taken to be 1)

    Null deviance: 950.86  on 713  degrees of freedom
Residual deviance: 576.85  on 697  degrees of freedom
AIC: 610.85

Number of Fisher Scoring iterations: 13


</pre>

</div>
</div>

</div>
</div>

</div>
<div class="text_cell_render border-box-sizing rendered_html">
<p>So we actually did <strong>much</strong> better. So lesson learnt, engineering new features is a great idea but may or may not positively impact your model. In fact, if we don't get it right, it could have an adverse impact. Let's see if we can make anymore tiny improvements with the Title. We have 4 possible values and I am going to class compress each.</p>
</div>
<div class="cell border-box-sizing code_cell vbox">
<div class="input hbox">
<div class="prompt input_prompt">
In [291]:
</div>
<div class="input_area box-flex1">
<div class="highlight"><pre><span class="o">%%</span><span class="k">R</span>
<span class="c">#Let's work in an interaction between Pclass and Sex.</span>
<span class="nb">set</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">35</span><span class="p">)</span> 

<span class="n">logit</span><span class="o">.</span><span class="n">tune5</span><span class="o">&lt;-</span><span class="n">train</span><span class="p">(</span><span class="n">Survived</span> <span class="o">~</span> <span class="n">Sex</span> <span class="o">+</span> <span class="n">Pclass</span> <span class="o">+</span> <span class="n">Sex</span><span class="p">:</span><span class="n">Pclass</span> <span class="o">+</span> <span class="n">Age</span> <span class="o">+</span> <span class="n">SibSp</span> <span class="o">+</span> <span class="n">Embarked</span> <span class="o">+</span> <span class="n">FareGroup</span> <span class="o">+</span> <span class="n">I</span><span class="p">(</span><span class="n">Title</span><span class="o">==</span><span class="s">'Mr'</span><span class="p">)</span> <span class="o">+</span>
                   <span class="n">I</span><span class="p">(</span><span class="n">Title</span><span class="o">==</span><span class="s">'Mrs'</span><span class="p">)</span> <span class="o">+</span> <span class="n">I</span><span class="p">(</span><span class="n">Title</span><span class="o">==</span><span class="s">'Miss'</span><span class="p">)</span> <span class="o">+</span> <span class="n">I</span><span class="p">(</span><span class="n">Title</span><span class="o">==</span><span class="s">'Noble'</span><span class="p">),</span>
                <span class="n">data</span><span class="o">=</span><span class="n">train</span><span class="o">.</span><span class="n">set</span><span class="p">,</span>
                <span class="n">method</span><span class="o">=</span><span class="s">'glm'</span><span class="p">,</span>
                <span class="n">preProcess</span> <span class="o">=</span> <span class="n">c</span><span class="p">(</span><span class="s">"center"</span><span class="p">,</span> <span class="s">"scale"</span><span class="p">),</span>
                <span class="n">trControl</span><span class="o">=</span><span class="n">tenfoldcv</span><span class="p">)</span>

<span class="n">logit</span><span class="o">.</span><span class="n">tune5</span>
</pre></div>

</div>
</div>

<div class="vbox output_wrapper">
<div class="output vbox">


<div class="hbox output_area">
<div class="prompt"></div>
<div class="box-flex1 output_subarea output_display_data">


<pre>
Generalized Linear Model 

714 samples
 14 predictors
  2 classes: '0', '1' 

Pre-processing: centered, scaled 
Resampling: Cross-Validated (10 fold, repeated 3 times) 

Summary of sample sizes: 643, 643, 643, 642, 643, 643, ... 

Resampling results

  Accuracy   Kappa      Accuracy SD  Kappa SD  
  0.8123305  0.5934912  0.04130739   0.09243173

 

</pre>

</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell vbox">
<div class="input hbox">
<div class="prompt input_prompt">
In [292]:
</div>
<div class="input_area box-flex1">
<div class="highlight"><pre><span class="o">%%</span><span class="k">R</span>
<span class="n">summary</span><span class="p">(</span><span class="n">logit</span><span class="o">.</span><span class="n">tune5</span><span class="p">)</span>
</pre></div>

</div>
</div>

<div class="vbox output_wrapper">
<div class="output vbox">


<div class="hbox output_area">
<div class="prompt"></div>
<div class="box-flex1 output_subarea output_display_data">


<pre>

Call:
NULL

Deviance Residuals: 
    Min       1Q   Median       3Q      Max  
-2.6591  -0.5397  -0.4099   0.3937   2.4194  

Coefficients:
                           Estimate Std. Error z value Pr(&gt;|z|)    
(Intercept)                -0.56336    0.12309  -4.577 4.72e-06 ***
Sexmale                    -8.13159  278.33333  -0.029 0.976693    
Pclass2                    -0.36485    0.33842  -1.078 0.280987    
Pclass3                    -1.62269    0.37865  -4.285 1.82e-05 ***
Age                        -0.30128    0.13506  -2.231 0.025693 *  
SibSp                      -0.62972    0.17467  -3.605 0.000312 ***
EmbarkedQ                   0.04973    0.11805   0.421 0.673568    
EmbarkedS                  -0.17619    0.12541  -1.405 0.160047    
`FareGroup10-20`            0.07364    0.14908   0.494 0.621326    
`FareGroup20-40`           -0.01342    0.17629  -0.076 0.939314    
`FareGroup40+`              0.11277    0.22144   0.509 0.610572    
`I(Title == "Mr")TRUE`     -1.55762    0.29962  -5.199 2.01e-07 ***
`I(Title == "Mrs")TRUE`    -5.78595  204.63657  -0.028 0.977443    
`I(Title == "Miss")TRUE`   -6.75940  236.67998  -0.029 0.977216    
`I(Title == "Noble")TRUE`  -0.46573    0.14315  -3.253 0.001140 ** 
`Sexmale:Pclass2`          -0.32045    0.29394  -1.090 0.275630    
`Sexmale:Pclass3`           0.65008    0.35598   1.826 0.067823 .  
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

(Dispersion parameter for binomial family taken to be 1)

    Null deviance: 950.86  on 713  degrees of freedom
Residual deviance: 576.85  on 697  degrees of freedom
AIC: 610.85

Number of Fisher Scoring iterations: 13


</pre>

</div>
</div>

</div>
</div>

</div>
<div class="text_cell_render border-box-sizing rendered_html">
<p>Hmm, didn't really make a difference. Let's try one last thing, adding Child, which we derived during the feature engineering exercise.</p>
</div>
<div class="cell border-box-sizing code_cell vbox">
<div class="input hbox">
<div class="prompt input_prompt">
In [120]:
</div>
<div class="input_area box-flex1">
<div class="highlight"><pre><span class="o">%%</span><span class="k">R</span>
<span class="c">#Let's add Child to the mix.</span>
<span class="nb">set</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">35</span><span class="p">)</span> 

<span class="n">logit</span><span class="o">.</span><span class="n">tune6</span><span class="o">&lt;-</span><span class="n">train</span><span class="p">(</span><span class="n">Survived</span> <span class="o">~</span> <span class="n">Sex</span> <span class="o">+</span> <span class="n">Pclass</span> <span class="o">+</span> <span class="n">Sex</span><span class="p">:</span><span class="n">Pclass</span> <span class="o">+</span> <span class="n">Age</span> <span class="o">+</span> <span class="n">SibSp</span> <span class="o">+</span> <span class="n">Embarked</span> <span class="o">+</span> <span class="n">FareGroup</span> <span class="o">+</span> <span class="n">Title</span> <span class="o">+</span> <span class="n">Child</span><span class="p">,</span>
                <span class="n">data</span><span class="o">=</span><span class="n">train</span><span class="o">.</span><span class="n">set</span><span class="p">,</span>
                <span class="n">method</span><span class="o">=</span><span class="s">'glm'</span><span class="p">,</span>
                <span class="n">preProcess</span> <span class="o">=</span> <span class="n">c</span><span class="p">(</span><span class="s">"center"</span><span class="p">,</span> <span class="s">"scale"</span><span class="p">),</span>
                <span class="n">trControl</span><span class="o">=</span><span class="n">tenfoldcv</span><span class="p">)</span>

<span class="n">logit</span><span class="o">.</span><span class="n">tune6</span>
</pre></div>

</div>
</div>

<div class="vbox output_wrapper">
<div class="output vbox">


<div class="hbox output_area">
<div class="prompt"></div>
<div class="box-flex1 output_subarea output_display_data">


<pre>
Generalized Linear Model 

714 samples
 14 predictors
  2 classes: '0', '1' 

Pre-processing: centered, scaled 
Resampling: Cross-Validated (10 fold, repeated 3 times) 

Summary of sample sizes: 643, 643, 643, 642, 643, 643, ... 

Resampling results

  Accuracy   Kappa      Accuracy SD  Kappa SD
  0.8144806  0.5969237  0.04436537   0.101153

 

</pre>

</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell vbox">
<div class="input hbox">
<div class="prompt input_prompt">
In [294]:
</div>
<div class="input_area box-flex1">
<div class="highlight"><pre><span class="o">%%</span><span class="k">R</span>
<span class="n">summary</span><span class="p">(</span><span class="n">logit</span><span class="o">.</span><span class="n">tune6</span><span class="p">)</span>
</pre></div>

</div>
</div>

<div class="vbox output_wrapper">
<div class="output vbox">


<div class="hbox output_area">
<div class="prompt"></div>
<div class="box-flex1 output_subarea output_display_data">


<pre>

Call:
NULL

Deviance Residuals: 
    Min       1Q   Median       3Q      Max  
-2.7285  -0.5465  -0.4164   0.4031   2.4338  

Coefficients:
                   Estimate Std. Error z value Pr(&gt;|z|)    
(Intercept)        -0.56186    0.12306  -4.566 4.98e-06 ***
Sexmale            -8.16008  276.99294  -0.029 0.976498    
Pclass2            -0.36500    0.33876  -1.077 0.281271    
Pclass3            -1.62927    0.37881  -4.301 1.70e-05 ***
Age                -0.25715    0.14521  -1.771 0.076581 .  
SibSp              -0.64181    0.17585  -3.650 0.000262 ***
EmbarkedQ           0.05690    0.11859   0.480 0.631327    
EmbarkedS          -0.17477    0.12575  -1.390 0.164569    
`FareGroup10-20`    0.05529    0.15150   0.365 0.715165    
`FareGroup20-40`   -0.03809    0.17965  -0.212 0.832083    
`FareGroup40+`      0.09460    0.22321   0.424 0.671714    
TitleMiss          -6.73181  235.54018  -0.029 0.977199    
TitleMr            -1.47297    0.31722  -4.643 3.43e-06 ***
TitleMrs           -5.73725  203.65108  -0.028 0.977525    
TitleNoble         -0.44396    0.14534  -3.055 0.002254 ** 
Child               0.11549    0.14579   0.792 0.428237    
`Sexmale:Pclass2`  -0.31971    0.29422  -1.087 0.277200    
`Sexmale:Pclass3`   0.64601    0.35560   1.817 0.069267 .  
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

(Dispersion parameter for binomial family taken to be 1)

    Null deviance: 950.86  on 713  degrees of freedom
Residual deviance: 576.23  on 696  degrees of freedom
AIC: 612.23

Number of Fisher Scoring iterations: 13


</pre>

</div>
</div>

</div>
</div>

</div>
<div class="text_cell_render border-box-sizing rendered_html">
<p>So we got that tiny push we were looking for. Let's now go ahead and try this model on our test set as well as submit to Kaggle.</p>
<p><strong>Model Evaluation - Logistic Regression</strong><br>We can now begin to evaluate model performance by putting together some cross-tabulations of the observed and predicted Survival for the passengers in the test.set data. caret makes this easy with the confusionMatrix function.</p>
</div>
<div class="cell border-box-sizing code_cell vbox">
<div class="input hbox">
<div class="prompt input_prompt">
In [295]:
</div>
<div class="input_area box-flex1">
<div class="highlight"><pre><span class="o">%%</span><span class="k">R</span>
<span class="c">#Derive predictions using our final LR model on the test set (this is NOT the test.csv file from Kaggle)</span>
<span class="n">logit</span><span class="o">.</span><span class="n">pred</span><span class="o">&lt;-</span><span class="n">predict</span><span class="p">(</span><span class="n">logit</span><span class="o">.</span><span class="n">tune6</span><span class="p">,</span> <span class="n">test</span><span class="o">.</span><span class="n">set</span><span class="p">)</span>

<span class="c">#Generate the confusion matrix</span>
<span class="n">confusionMatrix</span><span class="p">(</span><span class="n">logit</span><span class="o">.</span><span class="n">pred</span><span class="p">,</span> <span class="n">test</span><span class="o">.</span><span class="n">set</span><span class="err">$</span><span class="n">Survived</span><span class="p">)</span>
</pre></div>

</div>
</div>

<div class="vbox output_wrapper">
<div class="output vbox">


<div class="hbox output_area">
<div class="prompt"></div>
<div class="box-flex1 output_subarea output_display_data">


<pre>
Confusion Matrix and Statistics

          Reference
Prediction  0  1
         0 99 18
         1 10 50
                                          
               Accuracy : 0.8418          
                 95% CI : (0.7795, 0.8922)
    No Information Rate : 0.6158          
    P-Value [Acc &gt; NIR] : 4.229e-11       
                                          
                  Kappa : 0.6581          
 Mcnemar's Test P-Value : 0.1859          
                                          
            Sensitivity : 0.9083          
            Specificity : 0.7353          
         Pos Pred Value : 0.8462          
         Neg Pred Value : 0.8333          
             Prevalence : 0.6158          
         Detection Rate : 0.5593          
   Detection Prevalence : 0.6610          
      Balanced Accuracy : 0.8218          
                                          
       'Positive' Class : 0               
                                          

</pre>

</div>
</div>

</div>
</div>

</div>
<div class="text_cell_render border-box-sizing rendered_html">
<p>The metric we're looking for here is called Specificity. It basically is, out of all that actually survived how many we predicted will survive. So, it's 50/68 = 73.53%. Not too shabby though I'd like to do better. Let's anyway try to make a submission and find out for real.</p>
<p><strong>Submit Results to Kaggle</strong><br>Let's now submit the results from the LR model to Kaggle to see how we fare.</p>
</div>
<div class="cell border-box-sizing code_cell vbox">
<div class="input hbox">
<div class="prompt input_prompt">
In [356]:
</div>
<div class="input_area box-flex1">
<div class="highlight"><pre><span class="o">%%</span><span class="k">R</span>
<span class="c">#Generate predictions and write as a dataframe, then include PassengerID</span>
<span class="n">Survived</span><span class="o">&lt;-</span><span class="n">predict</span><span class="p">(</span><span class="n">logit</span><span class="o">.</span><span class="n">tune6</span><span class="p">,</span> <span class="n">kaggletest</span><span class="p">)</span>
<span class="n">lr</span><span class="o">.</span><span class="n">predictions</span><span class="o">&lt;-</span><span class="k">as</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">frame</span><span class="p">(</span><span class="n">Survived</span><span class="p">)</span>
<span class="n">lr</span><span class="o">.</span><span class="n">predictions</span><span class="err">$</span><span class="n">PassengerId</span><span class="o">&lt;-</span><span class="n">kaggletest</span><span class="err">$</span><span class="n">PassengerId</span>

<span class="c">#Write results as a CSV file</span>
<span class="n">write</span><span class="o">.</span><span class="n">csv</span><span class="p">(</span><span class="n">lr</span><span class="o">.</span><span class="n">predictions</span><span class="p">[,</span><span class="n">c</span><span class="p">(</span><span class="s">'PassengerId'</span><span class="p">,</span><span class="s">'Survived'</span><span class="p">)],</span> <span class="nb">file</span><span class="o">=</span><span class="s">"LR_Titanic_Predictions.csv"</span><span class="p">,</span> <span class="n">row</span><span class="o">.</span><span class="n">names</span><span class="o">=</span><span class="n">FALSE</span><span class="p">,</span> <span class="n">quote</span><span class="o">=</span><span class="n">FALSE</span><span class="p">)</span>
</pre></div>

</div>
</div>

</div>
<div class="text_cell_render border-box-sizing rendered_html">
<p>The model scored <strong>0.76555</strong> which put us ahead of only about 1/4th of the teams on the leaderboard. Let us keep trying to improve.</p>
</div>
<div class="text_cell_render border-box-sizing rendered_html">
<p><strong>Support Vector Machines</strong><br>Support Vector Machines (SVMs) are a powerful supervised learning algorithm used for classification or for regression. SVMs are a discriminative classifier: that is, they draw a boundary between clusters of data. The process of fitting an SVM based model to our dataset is very similar to what we just did with glm but involves an additional step to hypertune parameters. The key parameter for SVM is C, which can be considered as 1/lambda where lambda is the regularization term. We talked about overfitting previously, regularization is the process of offsetting it. If there is overfitting, we would increase lambda, so conversely decrease C.</p>
<p>The caret package automatically selects the best C value by hypertuning it during crossvalidation. But we need to supply a range of C values for the train method to try. For SVMs, this could be handled by updating the parameter, tunelength (or tunegrid). By default, the length is 3 and the values tried are 0.25, 0.5 and 1. Setting it to 6 would try 0.25 - 8. Let's get started.</p>
</div>
<div class="cell border-box-sizing code_cell vbox">
<div class="input hbox">
<div class="prompt input_prompt">
In [124]:
</div>
<div class="input_area box-flex1">
<div class="highlight"><pre><span class="o">%%</span><span class="k">R</span>
<span class="nb">set</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">35</span><span class="p">)</span> 

<span class="c">#Training an SVM model with the RBF kernel - Radial Basis Function</span>
<span class="n">svm</span><span class="o">.</span><span class="n">tune1</span><span class="o">&lt;-</span><span class="n">train</span><span class="p">(</span><span class="n">Survived</span> <span class="o">~</span> <span class="n">Sex</span> <span class="o">+</span> <span class="n">Pclass</span> <span class="o">+</span>  <span class="n">Sex</span><span class="p">:</span><span class="n">Pclass</span> <span class="o">+</span> <span class="n">Age</span> <span class="o">+</span> <span class="n">SibSp</span> <span class="o">+</span> <span class="n">Embarked</span> <span class="o">+</span> <span class="n">FareGroup</span> <span class="o">+</span> <span class="n">Title</span> <span class="o">+</span> <span class="n">Child</span><span class="p">,</span>
                <span class="n">data</span><span class="o">=</span><span class="n">train</span><span class="o">.</span><span class="n">set</span><span class="p">,</span>
                <span class="n">method</span><span class="o">=</span><span class="s">'svmRadial'</span><span class="p">,</span>
                <span class="n">tuneLength</span><span class="o">=</span><span class="mi">9</span><span class="p">,</span>
                <span class="n">preProcess</span> <span class="o">=</span> <span class="n">c</span><span class="p">(</span><span class="s">"center"</span><span class="p">,</span> <span class="s">"scale"</span><span class="p">),</span>
                <span class="n">trControl</span><span class="o">=</span><span class="n">tenfoldcv</span><span class="p">)</span>

<span class="n">svm</span><span class="o">.</span><span class="n">tune1</span>
</pre></div>

</div>
</div>

<div class="vbox output_wrapper">
<div class="output vbox">


<div class="hbox output_area">
<div class="prompt"></div>
<div class="box-flex1 output_subarea output_display_data">


<pre>
Support Vector Machines with Radial Basis Function Kernel 

714 samples
 14 predictors
  2 classes: '0', '1' 

Pre-processing: centered, scaled 
Resampling: Cross-Validated (10 fold, repeated 3 times) 

Summary of sample sizes: 643, 643, 643, 642, 643, 643, ... 

Resampling results across tuning parameters:

  C      Accuracy   Kappa      Accuracy SD  Kappa SD 
   0.25  0.8049426  0.5722555  0.05162691   0.1132959
   0.50  0.8117884  0.5843046  0.05585971   0.1259916
   1.00  0.8226591  0.6100882  0.05152085   0.1165301
   2.00  0.8249804  0.6164518  0.05146277   0.1156968
   4.00  0.8160650  0.5986011  0.05477380   0.1213830
   8.00  0.8131307  0.5934170  0.04906936   0.1095503
  16.00  0.8131172  0.5940660  0.05068143   0.1116418
  32.00  0.8150599  0.5995714  0.05261309   0.1151817
  64.00  0.8092588  0.5876340  0.05748809   0.1249829

Tuning parameter 'sigma' was held constant at a value of 0.07616343
Accuracy was used to select the optimal model using  the largest value.
The final values used for the model were sigma = 0.07616343 and C = 2. 

</pre>

</div>
</div>

</div>
</div>

</div>
<div class="text_cell_render border-box-sizing rendered_html">
<p>Great, so SVM automatically tried 9 different values of C while holding the other parameter Sigma constant and picked the values that gave the best results. We really didn't have to do much there. Let's go ahead and evaluate the model as well as submit to Kaggle.</p>
<p><strong>Model Evaluation - SVM</strong></p>
</div>
<div class="cell border-box-sizing code_cell vbox">
<div class="input hbox">
<div class="prompt input_prompt">
In [312]:
</div>
<div class="input_area box-flex1">
<div class="highlight"><pre><span class="o">%%</span><span class="k">R</span>
<span class="c">#Derive predictions using our final LR model on the test set (this is NOT the test.csv file from Kaggle)</span>
<span class="n">svm</span><span class="o">.</span><span class="n">pred</span><span class="o">&lt;-</span><span class="n">predict</span><span class="p">(</span><span class="n">svm</span><span class="o">.</span><span class="n">tune1</span><span class="p">,</span> <span class="n">test</span><span class="o">.</span><span class="n">set</span><span class="p">)</span>

<span class="c">#Generate the confusion matrix</span>
<span class="n">confusionMatrix</span><span class="p">(</span><span class="n">svm</span><span class="o">.</span><span class="n">pred</span><span class="p">,</span> <span class="n">test</span><span class="o">.</span><span class="n">set</span><span class="err">$</span><span class="n">Survived</span><span class="p">)</span>
</pre></div>

</div>
</div>

<div class="vbox output_wrapper">
<div class="output vbox">


<div class="hbox output_area">
<div class="prompt"></div>
<div class="box-flex1 output_subarea output_display_data">


<pre>
Confusion Matrix and Statistics

          Reference
Prediction   0   1
         0 100  20
         1   9  48
                                          
               Accuracy : 0.8362          
                 95% CI : (0.7732, 0.8874)
    No Information Rate : 0.6158          
    P-Value [Acc &gt; NIR] : 1.38e-10        
                                          
                  Kappa : 0.6429          
 Mcnemar's Test P-Value : 0.06332         
                                          
            Sensitivity : 0.9174          
            Specificity : 0.7059          
         Pos Pred Value : 0.8333          
         Neg Pred Value : 0.8421          
             Prevalence : 0.6158          
         Detection Rate : 0.5650          
   Detection Prevalence : 0.6780          
      Balanced Accuracy : 0.8117          
                                          
       'Positive' Class : 0               
                                          

</pre>

</div>
</div>

</div>
</div>

</div>
<div class="text_cell_render border-box-sizing rendered_html">
<p>The specificity is actually a bit down from the LR model, we're at 70%. Other than that eveyrthing looks pretty similar. I also just discovered that a Support Vector Machine automatically captures interaction between variables. So the Pclass:Sex interaction we put in has no importance to this model. We'll remove it going forward since Random Forests also automatically identifies interactions.</p>
<p><strong>Submit to Kaggle</strong></p>
</div>
<div class="cell border-box-sizing code_cell vbox">
<div class="input hbox">
<div class="prompt input_prompt">
In [355]:
</div>
<div class="input_area box-flex1">
<div class="highlight"><pre><span class="o">%%</span><span class="k">R</span>
<span class="c">#Generate predictions and write as a dataframe, then include PassengerID</span>
<span class="n">Survived</span><span class="o">&lt;-</span><span class="n">predict</span><span class="p">(</span><span class="n">svm</span><span class="o">.</span><span class="n">tune1</span><span class="p">,</span> <span class="n">kaggletest</span><span class="p">)</span>
<span class="n">svm</span><span class="o">.</span><span class="n">predictions</span><span class="o">&lt;-</span><span class="k">as</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">frame</span><span class="p">(</span><span class="n">Survived</span><span class="p">)</span>
<span class="n">svm</span><span class="o">.</span><span class="n">predictions</span><span class="err">$</span><span class="n">PassengerId</span><span class="o">&lt;-</span><span class="n">kaggletest</span><span class="err">$</span><span class="n">PassengerId</span>

<span class="c">#Write results as a CSV file</span>
<span class="n">write</span><span class="o">.</span><span class="n">csv</span><span class="p">(</span><span class="n">svm</span><span class="o">.</span><span class="n">predictions</span><span class="p">[,</span><span class="n">c</span><span class="p">(</span><span class="s">'PassengerId'</span><span class="p">,</span><span class="s">'Survived'</span><span class="p">)],</span> <span class="nb">file</span><span class="o">=</span><span class="s">"SVM_Titanic_Predictions.csv"</span><span class="p">,</span> <span class="n">row</span><span class="o">.</span><span class="n">names</span><span class="o">=</span><span class="n">FALSE</span><span class="p">,</span> <span class="n">quote</span><span class="o">=</span><span class="n">FALSE</span><span class="p">)</span>
</pre></div>

</div>
</div>

</div>
<div class="text_cell_render border-box-sizing rendered_html">
<p>We scored <strong>0.77512</strong>, an improvement over the Logistic Regression model that took us up the leaderboard a few notches. We're not going to let this go!</p>
</div>
<div class="text_cell_render border-box-sizing rendered_html">
<p><strong>Random Forests</strong><br>Next up, a very popular and easy to use model, Random Forests. RF builds on the concept of decision trees and expands it by growing multiple trees and averaging out the results to find the best fit. The parameter we need to tune is mtry, that number of features to try at each node. The best recommended value for this parameter is typically the square root of the number of features. Let's give this a shot.</p>
</div>
<div class="cell border-box-sizing code_cell vbox">
<div class="input hbox">
<div class="prompt input_prompt">
In [365]:
</div>
<div class="input_area box-flex1">
<div class="highlight"><pre><span class="o">%%</span><span class="k">R</span>
<span class="nb">set</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">35</span><span class="p">)</span> 

<span class="n">rfgrid</span><span class="o">&lt;-</span><span class="n">data</span><span class="o">.</span><span class="n">frame</span><span class="p">(</span><span class="o">.</span><span class="n">mtry</span><span class="o">=</span><span class="n">c</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">4</span><span class="p">))</span>

<span class="c">#Training a Random Forest model</span>
<span class="n">rf</span><span class="o">.</span><span class="n">tune1</span><span class="o">&lt;-</span><span class="n">train</span><span class="p">(</span><span class="n">Survived</span> <span class="o">~</span> <span class="n">Sex</span> <span class="o">+</span> <span class="n">Pclass</span> <span class="o">+</span> <span class="n">Age</span> <span class="o">+</span> <span class="n">SibSp</span> <span class="o">+</span> <span class="n">Embarked</span> <span class="o">+</span> <span class="n">FareGroup</span> <span class="o">+</span> <span class="n">Title</span> <span class="o">+</span> <span class="n">Child</span><span class="p">,</span>
                <span class="n">data</span><span class="o">=</span><span class="n">train</span><span class="o">.</span><span class="n">set</span><span class="p">,</span>
                <span class="n">method</span><span class="o">=</span><span class="s">'rf'</span><span class="p">,</span>
                <span class="n">tuneGrid</span><span class="o">=</span><span class="n">rfgrid</span><span class="p">,</span>
                <span class="n">trControl</span><span class="o">=</span><span class="n">tenfoldcv</span><span class="p">)</span>

<span class="n">rf</span><span class="o">.</span><span class="n">tune1</span>
</pre></div>

</div>
</div>

<div class="vbox output_wrapper">
<div class="output vbox">


<div class="hbox output_area">
<div class="prompt"></div>
<div class="box-flex1 output_subarea output_display_data">


<pre>
Random Forest 

714 samples
 14 predictors
  2 classes: '0', '1' 

No pre-processing
Resampling: Cross-Validated (10 fold, repeated 3 times) 

Summary of sample sizes: 643, 643, 643, 642, 643, 643, ... 

Resampling results across tuning parameters:

  mtry  Accuracy   Kappa      Accuracy SD  Kappa SD 
  2     0.8096114  0.5868040  0.05614486   0.1231515
  3     0.8120599  0.5869056  0.05485173   0.1228654
  4     0.8151139  0.5951016  0.05099510   0.1145908

Accuracy was used to select the optimal model using  the largest value.
The final value used for the model was mtry = 4. 

</pre>

</div>
</div>

</div>
</div>

</div>
<div class="text_cell_render border-box-sizing rendered_html">
<p>Looks like the best mtry value found was 4. Let's complete the formalities.</p>
<p><strong>Model Evaluation - Random Forests</strong></p>
</div>
<div class="cell border-box-sizing code_cell vbox">
<div class="input hbox">
<div class="prompt input_prompt">
In [353]:
</div>
<div class="input_area box-flex1">
<div class="highlight"><pre><span class="o">%%</span><span class="k">R</span>
<span class="c">#Derive predictions using our final LR model on the test set (this is NOT the test.csv file from Kaggle)</span>
<span class="n">rf</span><span class="o">.</span><span class="n">pred</span><span class="o">&lt;-</span><span class="n">predict</span><span class="p">(</span><span class="n">rf</span><span class="o">.</span><span class="n">tune1</span><span class="p">,</span> <span class="n">test</span><span class="o">.</span><span class="n">set</span><span class="p">)</span>

<span class="c">#Generate the confusion matrix</span>
<span class="n">confusionMatrix</span><span class="p">(</span><span class="n">rf</span><span class="o">.</span><span class="n">pred</span><span class="p">,</span> <span class="n">test</span><span class="o">.</span><span class="n">set</span><span class="err">$</span><span class="n">Survived</span><span class="p">)</span>
</pre></div>

</div>
</div>

<div class="vbox output_wrapper">
<div class="output vbox">


<div class="hbox output_area">
<div class="prompt"></div>
<div class="box-flex1 output_subarea output_display_data">


<pre>
Confusion Matrix and Statistics

          Reference
Prediction   0   1
         0 101  20
         1   8  48
                                          
               Accuracy : 0.8418          
                 95% CI : (0.7795, 0.8922)
    No Information Rate : 0.6158          
    P-Value [Acc &gt; NIR] : 4.229e-11       
                                          
                  Kappa : 0.6542          
 Mcnemar's Test P-Value : 0.03764         
                                          
            Sensitivity : 0.9266          
            Specificity : 0.7059          
         Pos Pred Value : 0.8347          
         Neg Pred Value : 0.8571          
             Prevalence : 0.6158          
         Detection Rate : 0.5706          
   Detection Prevalence : 0.6836          
      Balanced Accuracy : 0.8162          
                                          
       'Positive' Class : 0               
                                          

</pre>

</div>
</div>

</div>
</div>

</div>
<div class="text_cell_render border-box-sizing rendered_html">
<p>Well, the specificity is exactly the same, at 70%. I doubt this is going to give us a different result with Kaggle but let's try anyway.</p>
<p><strong>Submit to Kaggle</strong></p>
</div>
<div class="cell border-box-sizing code_cell vbox">
<div class="input hbox">
<div class="prompt input_prompt">
In [357]:
</div>
<div class="input_area box-flex1">
<div class="highlight"><pre><span class="o">%%</span><span class="k">R</span>
<span class="c">#Generate predictions and write as a dataframe, then include PassengerID</span>
<span class="n">Survived</span><span class="o">&lt;-</span><span class="n">predict</span><span class="p">(</span><span class="n">rf</span><span class="o">.</span><span class="n">tune1</span><span class="p">,</span> <span class="n">kaggletest</span><span class="p">)</span>
<span class="n">rf</span><span class="o">.</span><span class="n">predictions</span><span class="o">&lt;-</span><span class="k">as</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">frame</span><span class="p">(</span><span class="n">Survived</span><span class="p">)</span>
<span class="n">rf</span><span class="o">.</span><span class="n">predictions</span><span class="err">$</span><span class="n">PassengerId</span><span class="o">&lt;-</span><span class="n">kaggletest</span><span class="err">$</span><span class="n">PassengerId</span>

<span class="c">#Write results as a CSV file</span>
<span class="n">write</span><span class="o">.</span><span class="n">csv</span><span class="p">(</span><span class="n">rf</span><span class="o">.</span><span class="n">predictions</span><span class="p">[,</span><span class="n">c</span><span class="p">(</span><span class="s">'PassengerId'</span><span class="p">,</span><span class="s">'Survived'</span><span class="p">)],</span> <span class="nb">file</span><span class="o">=</span><span class="s">"RF_Titanic_Predictions.csv"</span><span class="p">,</span> <span class="n">row</span><span class="o">.</span><span class="n">names</span><span class="o">=</span><span class="n">FALSE</span><span class="p">,</span> <span class="n">quote</span><span class="o">=</span><span class="n">FALSE</span><span class="p">)</span>
</pre></div>

</div>
</div>

</div>
<div class="text_cell_render border-box-sizing rendered_html">
<p>Surprise, we scored <strong>0.78469</strong> bringing us midway on the leaderboard. So we're definitely making headway!</p>
<p><strong>Feature Importances</strong><br>Before we move ahead let's look at a key statistic that comes from running a tree based model. It's called feature importances, which tells us how much of an impact each of the features we're feeding to the model has to the final outcome.</p>
</div>
<div class="cell border-box-sizing code_cell vbox">
<div class="input hbox">
<div class="prompt input_prompt">
In [370]:
</div>
<div class="input_area box-flex1">
<div class="highlight"><pre><span class="o">%%</span><span class="k">R</span>
<span class="c">#Print variable importan</span>
<span class="n">varImp</span><span class="p">(</span><span class="n">rf</span><span class="o">.</span><span class="n">tune1</span><span class="err">$</span><span class="n">finalModel</span><span class="p">)</span>
</pre></div>

</div>
</div>

<div class="vbox output_wrapper">
<div class="output vbox">


<div class="hbox output_area">
<div class="prompt"></div>
<div class="box-flex1 output_subarea output_display_data">


<pre>
                 Overall
Sexmale        41.576129
Pclass2         6.801074
Pclass3        21.558667
Age            36.931313
SibSp          15.046491
EmbarkedQ       2.972848
EmbarkedS       6.683872
FareGroup10-20  3.980921
FareGroup20-40  6.418674
FareGroup40+   10.203688
TitleMiss      11.145308
TitleMr        36.630889
TitleMrs       10.509372
TitleNoble      2.862573
Child           4.153887

</pre>

</div>
</div>

</div>
</div>

</div>
<div class="text_cell_render border-box-sizing rendered_html">
<p>That's very interesting. We always knew that Gender was the most important variable. Sexmale by the way shows up there because it's the class that suffered the most. We see here that Age and "Mr." Title take the second spot. That is a revelation of sorts. SibSp also seems quite important compared to say Embarked.</p>
<p>Before we move ahead with other models, I am really curious to try a few more things out with RF. I would like to measure the impact of adding a couple of features we've left out, Family Size and Parch and see how they pan out in terms of importance. Offline I tried adding FamID and it again created a negative impact so I am leaving it out for good</p>
</div>
<div class="cell border-box-sizing code_cell vbox">
<div class="input hbox">
<div class="prompt input_prompt">
In [41]:
</div>
<div class="input_area box-flex1">
<div class="highlight"><pre><span class="o">%%</span><span class="k">R</span>
<span class="nb">set</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">35</span><span class="p">)</span> 

<span class="c">#Notice how we're trying out 2-5 features at each node now since we're adding a couple of features to train.</span>
<span class="n">rfgrid</span><span class="o">&lt;-</span><span class="n">data</span><span class="o">.</span><span class="n">frame</span><span class="p">(</span><span class="o">.</span><span class="n">mtry</span><span class="o">=</span><span class="n">c</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">4</span><span class="p">,</span><span class="mi">5</span><span class="p">))</span>

<span class="c">#Training a Random Forest model</span>
<span class="n">rf</span><span class="o">.</span><span class="n">tune2</span><span class="o">&lt;-</span><span class="n">train</span><span class="p">(</span><span class="n">Survived</span> <span class="o">~</span> <span class="n">Sex</span> <span class="o">+</span> <span class="n">Pclass</span> <span class="o">+</span> <span class="n">Age</span> <span class="o">+</span> <span class="n">SibSp</span> <span class="o">+</span> <span class="n">Embarked</span> <span class="o">+</span> <span class="n">FareGroup</span> <span class="o">+</span> <span class="n">Title</span> <span class="o">+</span> <span class="n">Child</span> <span class="o">+</span> <span class="n">FamSize</span> <span class="o">+</span> <span class="n">Parch</span><span class="p">,</span>
                <span class="n">data</span><span class="o">=</span><span class="n">train</span><span class="o">.</span><span class="n">set</span><span class="p">,</span>
                <span class="n">method</span><span class="o">=</span><span class="s">'rf'</span><span class="p">,</span>
                <span class="n">tuneGrid</span><span class="o">=</span><span class="n">rfgrid</span><span class="p">,</span>
                <span class="n">trControl</span><span class="o">=</span><span class="n">tenfoldcv</span><span class="p">)</span>

<span class="n">rf</span><span class="o">.</span><span class="n">tune2</span>
</pre></div>

</div>
</div>

<div class="vbox output_wrapper">
<div class="output vbox">


<div class="hbox output_area">
<div class="prompt"></div>
<div class="box-flex1 output_subarea output_display_data">


<pre>
Random Forest 

714 samples
 14 predictors
  2 classes: '0', '1' 

No pre-processing
Resampling: Cross-Validated (10 fold, repeated 3 times) 

Summary of sample sizes: 643, 643, 643, 642, 643, 643, ... 

Resampling results across tuning parameters:

  mtry  Accuracy   Kappa      Accuracy SD  Kappa SD  
  2     0.8161450  0.6018844  0.05130416   0.11229173
  3     0.8114502  0.5872835  0.05293296   0.11855522
  4     0.8133020  0.5920896  0.04751211   0.10699385
  5     0.8221049  0.6147302  0.04405445   0.09805046

Accuracy was used to select the optimal model using  the largest value.
The final value used for the model was mtry = 5. 

</pre>

</div>
</div>

</div>
</div>

</div>
<div class="text_cell_render border-box-sizing rendered_html">
<p>As expected, the best mtry value this time was 5. Let's look at the feature importances.</p>
</div>
<div class="cell border-box-sizing code_cell vbox">
<div class="input hbox">
<div class="prompt input_prompt">
In [73]:
</div>
<div class="input_area box-flex1">
<div class="highlight"><pre><span class="o">%%</span><span class="k">R</span>
<span class="n">varImp</span><span class="p">(</span><span class="n">rf</span><span class="o">.</span><span class="n">tune2</span><span class="err">$</span><span class="n">finalModel</span><span class="p">)</span>
</pre></div>

</div>
</div>

<div class="vbox output_wrapper">
<div class="output vbox">


<div class="hbox output_area">
<div class="prompt"></div>
<div class="box-flex1 output_subarea output_display_data">


<pre>
                 Overall
Sexmale        43.453469
Pclass2         6.453174
Pclass3        19.967399
Age            42.531124
SibSp          10.604394
EmbarkedQ       2.998889
EmbarkedS       6.815784
FareGroup10-20  4.111547
FareGroup20-40  6.365776
FareGroup40+    9.403774
TitleMiss      10.173660
TitleMr        38.239391
TitleMrs        8.937783
TitleNoble      2.831949
Child           3.719191
FamSize        19.145703
Parch           7.960594

</pre>

</div>
</div>

</div>
</div>

</div>
<div class="text_cell_render border-box-sizing rendered_html">
<p>So it worked out well. Parch and especially FamSize seem to be reasonably important. I believe feature selection plays a very important role in Tree based on models (not that they don't in others but perhaps even more important in this case). OK let's run predictions then re-submit to Kaggle to see if we can improve the score.</p>
</div>
<div class="cell border-box-sizing code_cell vbox">
<div class="input hbox">
<div class="prompt input_prompt">
In [43]:
</div>
<div class="input_area box-flex1">
<div class="highlight"><pre><span class="o">%%</span><span class="k">R</span>
<span class="c">#Derive predictions using our final LR model on the test set (this is NOT the test.csv file from Kaggle)</span>
<span class="n">rf</span><span class="o">.</span><span class="n">pred</span><span class="o">&lt;-</span><span class="n">predict</span><span class="p">(</span><span class="n">rf</span><span class="o">.</span><span class="n">tune2</span><span class="p">,</span> <span class="n">test</span><span class="o">.</span><span class="n">set</span><span class="p">)</span>

<span class="c">#Generate the confusion matrix</span>
<span class="n">confusionMatrix</span><span class="p">(</span><span class="n">rf</span><span class="o">.</span><span class="n">pred</span><span class="p">,</span> <span class="n">test</span><span class="o">.</span><span class="n">set</span><span class="err">$</span><span class="n">Survived</span><span class="p">)</span>
</pre></div>

</div>
</div>

<div class="vbox output_wrapper">
<div class="output vbox">


<div class="hbox output_area">
<div class="prompt"></div>
<div class="box-flex1 output_subarea output_display_data">


<pre>
Confusion Matrix and Statistics

          Reference
Prediction  0  1
         0 98 20
         1 11 48
                                          
               Accuracy : 0.8249          
                 95% CI : (0.7607, 0.8778)
    No Information Rate : 0.6158          
    P-Value [Acc &gt; NIR] : 1.304e-09       
                                          
                  Kappa : 0.6204          
 Mcnemar's Test P-Value : 0.1508          
                                          
            Sensitivity : 0.8991          
            Specificity : 0.7059          
         Pos Pred Value : 0.8305          
         Neg Pred Value : 0.8136          
             Prevalence : 0.6158          
         Detection Rate : 0.5537          
   Detection Prevalence : 0.6667          
      Balanced Accuracy : 0.8025          
                                          
       'Positive' Class : 0               
                                          

</pre>

</div>
</div>

</div>
</div>

</div>
<div class="text_cell_render border-box-sizing rendered_html">
<p>No difference on predictions in our Test set. The sensitivity is the same. But let's try submitting to Kaggle anyway.</p>
</div>
<div class="cell border-box-sizing code_cell vbox">
<div class="input hbox">
<div class="prompt input_prompt">
In [44]:
</div>
<div class="input_area box-flex1">
<div class="highlight"><pre><span class="o">%%</span><span class="k">R</span>
<span class="c">#Generate predictions and write as a dataframe, then include PassengerID</span>
<span class="n">Survived</span><span class="o">&lt;-</span><span class="n">predict</span><span class="p">(</span><span class="n">rf</span><span class="o">.</span><span class="n">tune2</span><span class="p">,</span> <span class="n">kaggletest</span><span class="p">)</span>
<span class="n">rf</span><span class="o">.</span><span class="n">predictions</span><span class="o">&lt;-</span><span class="k">as</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">frame</span><span class="p">(</span><span class="n">Survived</span><span class="p">)</span>
<span class="n">rf</span><span class="o">.</span><span class="n">predictions</span><span class="err">$</span><span class="n">PassengerId</span><span class="o">&lt;-</span><span class="n">kaggletest</span><span class="err">$</span><span class="n">PassengerId</span>

<span class="c">#Write results as a CSV file</span>
<span class="n">write</span><span class="o">.</span><span class="n">csv</span><span class="p">(</span><span class="n">rf</span><span class="o">.</span><span class="n">predictions</span><span class="p">[,</span><span class="n">c</span><span class="p">(</span><span class="s">'PassengerId'</span><span class="p">,</span><span class="s">'Survived'</span><span class="p">)],</span> <span class="nb">file</span><span class="o">=</span><span class="s">"RF_Titanic_Predictions.csv"</span><span class="p">,</span> <span class="n">row</span><span class="o">.</span><span class="n">names</span><span class="o">=</span><span class="n">FALSE</span><span class="p">,</span> <span class="n">quote</span><span class="o">=</span><span class="n">FALSE</span><span class="p">)</span>
</pre></div>

</div>
</div>

</div>
<div class="text_cell_render border-box-sizing rendered_html">
<p>Guess what, we did make an improvement to the Kaggle score. This model scored <strong>0.78947</strong> bringing us to the top 1/3rd of the leaderboard. Since tree based models are giving us great results let's try one more, a very interesting model called <em>Conditional Trees</em>.</p>
<p><strong>Conditional Trees</strong><br>Conditional Tree based models supposedly tend to select variables that have many possible splits or many missing values. So instead of Random Forests which tries to find out which variables are important, using an information measure, these models perform sort of a significance test to see which features will yield the best results at each split. Let's give this a whirl.</p>
<p>Note that there are two Conditional Tree packages in caret (ctree, ctree2). We will be using ctree2 which allows us to tune the Max Depth, how deep the trees can grow.</p>
</div>
<div class="cell border-box-sizing code_cell vbox">
<div class="input hbox">
<div class="prompt input_prompt">
In [75]:
</div>
<div class="input_area box-flex1">
<div class="highlight"><pre><span class="o">%%</span><span class="k">R</span>
<span class="nb">set</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">35</span><span class="p">)</span> 

<span class="n">ctrgrid</span><span class="o">&lt;-</span><span class="n">data</span><span class="o">.</span><span class="n">frame</span><span class="p">(</span><span class="o">.</span><span class="n">maxdepth</span><span class="o">=</span><span class="n">c</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">4</span><span class="p">,</span><span class="mi">5</span><span class="p">,</span><span class="mi">6</span><span class="p">))</span>

<span class="c">#Training a Conditional Tree model</span>
<span class="n">ctr</span><span class="o">.</span><span class="n">tune1</span><span class="o">&lt;-</span><span class="n">train</span><span class="p">(</span><span class="n">Survived</span> <span class="o">~</span> <span class="n">Sex</span> <span class="o">+</span> <span class="n">Pclass</span> <span class="o">+</span> <span class="n">Age</span> <span class="o">+</span> <span class="n">SibSp</span> <span class="o">+</span> <span class="n">Embarked</span> <span class="o">+</span> <span class="n">FareGroup</span> <span class="o">+</span> <span class="n">Title</span> <span class="o">+</span> <span class="n">Child</span> <span class="o">+</span> <span class="n">FamSize</span> <span class="o">+</span> <span class="n">Parch</span><span class="p">,</span>
                <span class="n">data</span><span class="o">=</span><span class="n">train</span><span class="o">.</span><span class="n">set</span><span class="p">,</span>
                <span class="n">method</span><span class="o">=</span><span class="s">'ctree2'</span><span class="p">,</span>
                <span class="n">tuneGrid</span><span class="o">=</span><span class="n">ctrgrid</span><span class="p">,</span>
                <span class="n">trControl</span><span class="o">=</span><span class="n">tenfoldcv</span><span class="p">)</span>

<span class="n">ctr</span><span class="o">.</span><span class="n">tune1</span>
</pre></div>

</div>
</div>

<div class="vbox output_wrapper">
<div class="output vbox">


<div class="hbox output_area">
<div class="prompt"></div>
<div class="box-flex1 output_subarea output_display_data">


<pre>
Conditional Inference Tree 

714 samples
 14 predictors
  2 classes: '0', '1' 

No pre-processing
Resampling: Cross-Validated (10 fold, repeated 3 times) 

Summary of sample sizes: 643, 643, 643, 642, 643, 643, ... 

Resampling results across tuning parameters:

  maxdepth  Accuracy   Kappa      Accuracy SD  Kappa SD 
  2         0.7707812  0.4755401  0.04604332   0.1104954
  3         0.8077726  0.5855616  0.05702946   0.1237835
  4         0.8236502  0.6130369  0.05491988   0.1236674
  5         0.8194444  0.6055659  0.04897090   0.1102774
  6         0.8152061  0.5960590  0.05126715   0.1141253

Accuracy was used to select the optimal model using  the largest value.
The final value used for the model was maxdepth = 4. 

</pre>

</div>
</div>

</div>
</div>

</div>
<div class="text_cell_render border-box-sizing rendered_html">
<p>OK that did give us a better accuracy at Max Depth 4. Before we run predictions, let's visualize the tree that was built for the final model.</p>
</div>
<div class="cell border-box-sizing code_cell vbox">
<div class="input hbox">
<div class="prompt input_prompt">
In [115]:
</div>
<div class="input_area box-flex1">
<div class="highlight"><pre><span class="o">%%</span><span class="k">R</span>
<span class="n">plot</span><span class="p">(</span><span class="n">ctr</span><span class="o">.</span><span class="n">tune1</span><span class="err">$</span><span class="n">finalModel</span><span class="p">)</span>
</pre></div>

</div>
</div>

<div class="vbox output_wrapper">
<div class="output vbox">


<div class="hbox output_area">
<div class="prompt"></div>
<div class="box-flex1 output_subarea output_display_data">


<img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAeAAAAHgCAMAAABKCk6nAAADAFBMVEUAAAABAQECAgIDAwMEBAQF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">

</div>
</div>

</div>
</div>

</div>
<div class="text_cell_render border-box-sizing rendered_html">
<p>We can observe here that Sexmale as expected was the starting node. From then on, Pclass and TitleMr took the honors for level 2 leading further then to the other variables. We're now ready to evaluate the model and run the predictions.</p>
<p><strong>Model Evaluation - Conditional Trees</strong></p>
</div>
<div class="cell border-box-sizing code_cell vbox">
<div class="input hbox">
<div class="prompt input_prompt">
In [76]:
</div>
<div class="input_area box-flex1">
<div class="highlight"><pre><span class="o">%%</span><span class="k">R</span>
<span class="c">#Derive predictions using our final LR model on the test set (this is NOT the test.csv file from Kaggle)</span>
<span class="n">ctr</span><span class="o">.</span><span class="n">pred</span><span class="o">&lt;-</span><span class="n">predict</span><span class="p">(</span><span class="n">ctr</span><span class="o">.</span><span class="n">tune1</span><span class="p">,</span> <span class="n">test</span><span class="o">.</span><span class="n">set</span><span class="p">)</span>

<span class="c">#Generate the confusion matrix</span>
<span class="n">confusionMatrix</span><span class="p">(</span><span class="n">ctr</span><span class="o">.</span><span class="n">pred</span><span class="p">,</span> <span class="n">test</span><span class="o">.</span><span class="n">set</span><span class="err">$</span><span class="n">Survived</span><span class="p">)</span>
</pre></div>

</div>
</div>

<div class="vbox output_wrapper">
<div class="output vbox">


<div class="hbox output_area">
<div class="prompt"></div>
<div class="box-flex1 output_subarea output_display_data">


<pre>
Confusion Matrix and Statistics

          Reference
Prediction   0   1
         0 102  19
         1   7  49
                                          
               Accuracy : 0.8531          
                 95% CI : (0.7922, 0.9017)
    No Information Rate : 0.6158          
    P-Value [Acc &gt; NIR] : 3.506e-12       
                                          
                  Kappa : 0.6789          
 Mcnemar's Test P-Value : 0.03098         
                                          
            Sensitivity : 0.9358          
            Specificity : 0.7206          
         Pos Pred Value : 0.8430          
         Neg Pred Value : 0.8750          
             Prevalence : 0.6158          
         Detection Rate : 0.5763          
   Detection Prevalence : 0.6836          
      Balanced Accuracy : 0.8282          
                                          
       'Positive' Class : 0               
                                          

</pre>

</div>
</div>

</div>
</div>

</div>
<div class="text_cell_render border-box-sizing rendered_html">
<p>So that gave us a better Specificity on the Test set at 72.06%. I am interested to see how this tests out at Kaggle.</p>
<p><strong>Submit to Kaggle</strong></p>
</div>
<div class="cell border-box-sizing code_cell vbox">
<div class="input hbox">
<div class="prompt input_prompt">
In [91]:
</div>
<div class="input_area box-flex1">
<div class="highlight"><pre><span class="o">%%</span><span class="k">R</span>
<span class="c">#Generate predictions and write as a dataframe, then include PassengerID</span>
<span class="n">Survived</span><span class="o">&lt;-</span><span class="n">predict</span><span class="p">(</span><span class="n">ctr</span><span class="o">.</span><span class="n">tune1</span><span class="p">,</span> <span class="n">kaggletest</span><span class="p">)</span>
<span class="n">ctr</span><span class="o">.</span><span class="n">predictions</span><span class="o">&lt;-</span><span class="k">as</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">frame</span><span class="p">(</span><span class="n">Survived</span><span class="p">)</span>
<span class="n">ctr</span><span class="o">.</span><span class="n">predictions</span><span class="err">$</span><span class="n">PassengerId</span><span class="o">&lt;-</span><span class="n">kaggletest</span><span class="err">$</span><span class="n">PassengerId</span>

<span class="c">#Write results as a CSV file</span>
<span class="n">write</span><span class="o">.</span><span class="n">csv</span><span class="p">(</span><span class="n">ctr</span><span class="o">.</span><span class="n">predictions</span><span class="p">[,</span><span class="n">c</span><span class="p">(</span><span class="s">'PassengerId'</span><span class="p">,</span><span class="s">'Survived'</span><span class="p">)],</span> <span class="nb">file</span><span class="o">=</span><span class="s">"CTR_Titanic_Predictions.csv"</span><span class="p">,</span> <span class="n">row</span><span class="o">.</span><span class="n">names</span><span class="o">=</span><span class="n">FALSE</span><span class="p">,</span> <span class="n">quote</span><span class="o">=</span><span class="n">FALSE</span><span class="p">)</span>
</pre></div>

</div>
</div>

</div>
<div class="text_cell_render border-box-sizing rendered_html">
<p>The model scored <strong>0.77512</strong> which is actually slightly worse than how Random Forests did. So the best model in terms of the Kaggle leaderboard has been Random Forests. But let's run a formal comparison of all the models we've built so far.</p>
</div>
<div class="text_cell_render border-box-sizing rendered_html">
<p><strong>Model Comparison</strong><br>The resamples method in the caret package makes it easy to compare results between different models.</p>
</div>
<div class="cell border-box-sizing code_cell vbox">
<div class="input hbox">
<div class="prompt input_prompt">
In [126]:
</div>
<div class="input_area box-flex1">
<div class="highlight"><pre><span class="o">%%</span><span class="k">R</span>
<span class="n">modelcompare</span><span class="o">&lt;-</span><span class="n">resamples</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">Logit</span> <span class="o">=</span> <span class="n">logit</span><span class="o">.</span><span class="n">tune6</span><span class="p">,</span> <span class="n">SVM</span> <span class="o">=</span> <span class="n">svm</span><span class="o">.</span><span class="n">tune1</span><span class="p">,</span> <span class="n">RF</span> <span class="o">=</span> <span class="n">rf</span><span class="o">.</span><span class="n">tune2</span><span class="p">,</span> <span class="n">CTREE</span> <span class="o">=</span> <span class="n">ctr</span><span class="o">.</span><span class="n">tune1</span> <span class="p">))</span>
<span class="n">summary</span><span class="p">(</span><span class="n">modelcompare</span><span class="p">)</span>
</pre></div>

</div>
</div>

<div class="vbox output_wrapper">
<div class="output vbox">


<div class="hbox output_area">
<div class="prompt"></div>
<div class="box-flex1 output_subarea output_display_data">


<pre>

Call:
summary.resamples(object = modelcompare)

Models: Logit, SVM, RF, CTREE 
Number of resamples: 24 

Accuracy 
        Min. 1st Qu. Median   Mean 3rd Qu.   Max. NA's
Logit 0.7465  0.7887 0.8042 0.8145  0.8333 0.9437    0
SVM   0.7606  0.7778 0.8042 0.8244  0.8677 0.9296    0
RF    0.7606  0.7917 0.8182 0.8250  0.8592 0.9155    0
CTREE 0.7361  0.7770 0.8099 0.8216  0.8502 0.9577    0

Kappa 
        Min. 1st Qu. Median   Mean 3rd Qu.   Max. NA's
Logit 0.4295  0.5334 0.5747 0.5969  0.6505 0.8787    0
SVM   0.4570  0.5146 0.5612 0.6149  0.7173 0.8495    0
RF    0.4652  0.5392 0.6140 0.6195  0.7012 0.8232    0
CTREE 0.4338  0.5003 0.5771 0.6083  0.6847 0.9097    0


</pre>

</div>
</div>

</div>
</div>

</div>
<div class="text_cell_render border-box-sizing rendered_html">
<p>We can see that for the metric we chose (Accuracy), Random Forests outperformed the other models. Note here that we could've chosen ROC (Receiver Operating Characteristic) as the metric in which case, we'd have needed to generate class probabilties - that is, probability for survived/not survived for every data item rather than letting crossvalidation generate predictions automatically. I intend to learn and demonstrate these concepts in a seperate session. For now, let's plot the results in a couple of different ways.</p>
<p><strong>Box Plot of Model Comparison Results</strong></p>
</div>
<div class="cell border-box-sizing code_cell vbox">
<div class="input hbox">
<div class="prompt input_prompt">
In [128]:
</div>
<div class="input_area box-flex1">
<div class="highlight"><pre><span class="o">%%</span><span class="k">R</span>
<span class="n">bwplot</span><span class="p">(</span><span class="n">modelcompare</span><span class="p">)</span>
</pre></div>

</div>
</div>

<div class="vbox output_wrapper">
<div class="output vbox">


<div class="hbox output_area">
<div class="prompt"></div>
<div class="box-flex1 output_subarea output_display_data">


<img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAeAAAAHgCAIAAADytinCAAAgAElEQVR4nO3deUBVdf7/8feFK4oI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%0AAElFTkSuQmCC">

</div>
</div>

</div>
</div>

</div>
<div class="text_cell_render border-box-sizing rendered_html">
<p><strong>Dot Plot of Model Comparison Results</strong></p>
</div>
<div class="cell border-box-sizing code_cell vbox">
<div class="input hbox">
<div class="prompt input_prompt">
In [129]:
</div>
<div class="input_area box-flex1">
<div class="highlight"><pre><span class="o">%%</span><span class="k">R</span>
<span class="n">dotplot</span><span class="p">(</span><span class="n">modelcompare</span><span class="p">)</span>
</pre></div>

</div>
</div>

<div class="vbox output_wrapper">
<div class="output vbox">


<div class="hbox output_area">
<div class="prompt"></div>
<div class="box-flex1 output_subarea output_display_data">


<img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAeAAAAHgCAIAAADytinCAAAgAElEQVR4nO3deVyVdfr/8YvDAWRX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%0AiiKgAUBRBDQAKIqABgBF/X8doFqqqGI6RwAAAABJRU5ErkJggg==">

</div>
</div>

</div>
</div>

</div>
<div class="text_cell_render border-box-sizing rendered_html">
<p>So there you have it. We took the Titanic dataset presented by Kaggle, imported and visualized the data in a series of plots, munged the data to address gaps and fitted 4 different models with varying results, all in R, special thanks to the caret package. We only managed to get up to 0.7894 on the Kaggle leaderboard but the point of this exercise was to learn and demonstrate machine learning concepts in R. Hope we've achieved that objective.</p>
<p>I will be happy to receive your feedback positive or negative but try to be nice, I am just learning :-)</p>
</div>
</div>
    </div>
    <aside class="postpromonav">
    <nav>
    
            <ul class="pager">
            <li class="previous">
                <a href="svm-sklearn.html" rel="prev" title="Recognizing Hand Written Digits (UCI ML Repo) with Support Vector Machines (SVM)">Previous post</a>
            </li>
        </ul>

    </nav>
    </aside>
        <section class="comments">
        <h2>Comments</h2>
                        <div id="disqus_thread"></div>
        <script>
        var disqus_shortname ="shankarmsy",
            disqus_url="https://shankarmsy.github.io/posts/saving-titanic-r.html",
        disqus_title="Saving the Titanic with R",
        disqus_identifier="cache/posts/saving-titanic-r.html",
        disqus_config = function () {
            this.language = "en";
        };
        (function() {
            var dsq = document.createElement('script'); dsq.async = true;
            dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
            (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
        })();
    </script>
    <noscript>Please enable JavaScript to view the <a href="//disqus.com/?ref_noscript" rel="nofollow">comments powered by Disqus.</a>
</noscript>
    <a href="//disqus.com" class="dsq-brlink" rel="nofollow">Comments powered by <span class="logo-disqus">Disqus</span></a>


        </section>
</article>
               <script>var disqus_shortname="shankarmsy";(function(){var a=document.createElement("script");a.async=true;a.src="//"+disqus_shortname+".disqus.com/count.js";(document.getElementsByTagName("head")[0]||document.getElementsByTagName("body")[0]).appendChild(a)}());</script>


        </div>
        <!--End of body content-->

        <footer>
            Contents © 2014         <a href="mailto:Shankar.Muthuswamy@gmail.com">Shankar Muthuswamy</a> - Powered by         <a href="http://getnikola.com" rel="nofollow">Nikola</a>         
            
        </footer>
    </div>
</div>

            <script src="../assets/js/all-nocdn.js"></script>
    

    <script>jQuery("a.image-reference").colorbox({rel:"gal",maxWidth:"100%",maxHeight:"100%",scalePhotos:true});</script>
    <!-- fancy dates -->
    <script>
    moment.locale("");
    fancydates(0, "YYYY-MM-DD HH:mm");
    </script>
    <!-- end fancy dates -->


</body>
</html>
