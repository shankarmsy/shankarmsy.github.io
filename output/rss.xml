<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet type="text/xsl" href="assets/xml/rss.xsl" media="all"?><rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>It's all in the data</title><link>https://shankarmsy.github.io/</link><description>musings and ramblings on Data Science &amp; more</description><atom:link href="https://shankarmsy.github.io/rss.xml" type="application/rss+xml" rel="self"></atom:link><language>en</language><lastBuildDate>Tue, 24 Feb 2015 15:47:24 GMT</lastBuildDate><generator>http://getnikola.com/</generator><docs>http://blogs.law.harvard.edu/tech/rss</docs><item><title>Exploratory Visualizations part-3 - Styling matplotlib</title><link>https://shankarmsy.github.io/posts/exploringviz3.html</link><dc:creator>Shankar Muthuswamy</dc:creator><description>&lt;div tabindex="-1" id="notebook" class="border-box-sizing"&gt;
    &lt;div class="container" id="notebook-container"&gt;

&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;In the first two posts of this series I did a compare and contrast of out-of-the-box look and feel of Matplotlib and compared it with base R graphics and the ever so awesome ggplot2. In this post, I'll explore some options to make matplotlib plots prettier, or in other words look more like ggplot2.&lt;/p&gt;
&lt;p&gt;Let's get right to it by importing the required packages.&lt;/p&gt;&lt;p&gt;&lt;a href="https://shankarmsy.github.io/posts/exploringviz3.html"&gt;Read more…&lt;/a&gt; (3 min remaining to read)&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description><category>R</category><category>base R graphics</category><category>brewer2mpl</category><category>colorbrewer</category><category>ggplot2</category><category>matplotlib</category><category>pandas</category><category>python</category><category>seaborn</category><category>style</category><category>visualization</category><guid>https://shankarmsy.github.io/posts/exploringviz3.html</guid><pubDate>Fri, 02 Jan 2015 19:25:01 GMT</pubDate></item><item><title>Exploratory Visualizations part-2 - Decoding ggplot2</title><link>https://shankarmsy.github.io/posts/exploringviz2.html</link><dc:creator>Shankar Muthuswamy</dc:creator><description>&lt;div tabindex="-1" id="notebook" class="border-box-sizing"&gt;
    &lt;div class="container" id="notebook-container"&gt;

&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;In the first post of this series we looked at the out-of-the-box visualizations possible with matplotlib (&lt;a href="https://shankarmsy.github.io/posts/exploringviz1.html"&gt;here&lt;/a&gt;) and the base R graphics package and drew a comparison. In this post, let's take a look at the ever-so-awesome ggplot2.&lt;/p&gt;
&lt;p&gt;ggplot2 is invaluable for its sophistication and the way it enables you to write complex plots in just a few lines of code.&lt;/p&gt;
&lt;p&gt;Let's get right to it by importing the required packages.&lt;/p&gt;&lt;p&gt;&lt;a href="https://shankarmsy.github.io/posts/exploringviz2.html"&gt;Read more…&lt;/a&gt; (5 min remaining to read)&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description><category>R</category><category>exploratory</category><category>ggplot2</category><category>matplotlib</category><category>pandas</category><category>python</category><category>visualization</category><guid>https://shankarmsy.github.io/posts/exploringviz2.html</guid><pubDate>Wed, 31 Dec 2014 12:30:01 GMT</pubDate></item><item><title>Exploratory Visualizations part-1 - matplotlib vs base R</title><link>https://shankarmsy.github.io/posts/exploringviz1.html</link><dc:creator>Shankar Muthuswamy</dc:creator><description>&lt;div tabindex="-1" id="notebook" class="border-box-sizing"&gt;
    &lt;div class="container" id="notebook-container"&gt;

&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;In these series of posts, I will try to visually compare and contrast visualization tools focusing specifically on Python and R. We will look at a wide array of tools such as matplotlib, base graphics in R, lattice, ggplot2 and visually pit them against each other by creating some simple visualizations. Later we will turn our attention to matplotlib and implement some ideas to make its visualizations more impressive. This isn't meant to be a tutorial (there's plenty out there) but hopefully there's a trick or two along the way that's helpful.&lt;/p&gt;
&lt;p&gt;In this first post, we will begin by comparing matplotlib with the base graphics package in R.&lt;/p&gt;
&lt;p&gt;To start with we will use a simple dataset that provides specifications for 428 new vehicles for the year 2004. This dataset has been used for a number of statistics courses since the results are easier for everyone to relate to. We however will use the data to focus on the tools rather than focus on the data itself.&lt;/p&gt;
&lt;p&gt;Let's go!&lt;/p&gt;&lt;p&gt;&lt;a href="https://shankarmsy.github.io/posts/exploringviz1.html"&gt;Read more…&lt;/a&gt; (7 min remaining to read)&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description><category>R</category><category>base R graphics</category><category>ggplot2</category><category>matplotlib</category><category>pandas</category><category>python</category><category>visualization</category><guid>https://shankarmsy.github.io/posts/exploringviz1.html</guid><pubDate>Tue, 16 Dec 2014 12:30:01 GMT</pubDate></item><item><title>Visually differentiating PCA and Linear Regression</title><link>https://shankarmsy.github.io/posts/pca-vs-lr.html</link><dc:creator>Shankar Muthuswamy</dc:creator><description>&lt;div tabindex="-1" id="notebook" class="border-box-sizing"&gt;
    &lt;div class="container" id="notebook-container"&gt;

&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;I've always been fascinated by the concept of PCA. Considering its wide range of applications and how inherently mathematical the idea is, I feel PCA is one of the pillars of the intersection between Pure Mathematics and Real-world analytics. Besides, the fact that you could think about real data as just raw numbers and then transform it down to something you can visualize and relate to, is extremely powerful and essential in any learning process.&lt;/p&gt;
&lt;p&gt;Just in case you're wondering, Principle Component Analysis (PCA) simply put is a dimensionality reduction technique that can find the combinations of variables that explain the most variance. So you can transform a 1000-feature dataset into 2D so you can visualize it in a plot or you could bring it down to x features where x&amp;lt;&amp;lt;1000 while preserving most of the variance in the data. I've previously explored &lt;a href="https://shankarmsy.github.io/posts/pca-sklearn.html"&gt;Facial image compression and reconstruction using PCA&lt;/a&gt; using scikit-learn.&lt;/p&gt;
&lt;p&gt;In this post I would like to delve into the concept of linearity in Principal Component Analysis.&lt;/p&gt;&lt;p&gt;&lt;a href="https://shankarmsy.github.io/posts/pca-vs-lr.html"&gt;Read more…&lt;/a&gt; (6 min remaining to read)&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description><category>dimensionality reduction</category><category>image compression</category><category>linear regression</category><category>pca</category><category>scikit-learn</category><category>unsupervised learning</category><guid>https://shankarmsy.github.io/posts/pca-vs-lr.html</guid><pubDate>Fri, 12 Dec 2014 17:01:00 GMT</pubDate></item><item><title>Predicting Forest Cover Types with Ensemble Learning</title><link>https://shankarmsy.github.io/posts/forest-cover-types.html</link><dc:creator>Shankar Muthuswamy</dc:creator><description>&lt;div tabindex="-1" id="notebook" class="border-box-sizing"&gt;
    &lt;div class="container" id="notebook-container"&gt;

&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;This is a documentation of one of my approaches to solving the forest cover type prediction challenge hosted by Kaggle. Feel free to use for your own reference and let me know if you have any suggestions on how I can improve the model :-)&lt;/p&gt;
&lt;p&gt;I found this topic very engaging being a nature lover. Also the features are very friendly and don't require much domain knowledge to explore (and hopefully engineer new features).&lt;/p&gt;
&lt;p&gt;OK let's get started.&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="https://shankarmsy.github.io/posts/forest-cover-types.html"&gt;Read more…&lt;/a&gt; (30 min remaining to read)&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description><category>blending</category><category>ensemble</category><category>extra trees</category><category>random forests</category><category>scikit-learn</category><category>supervised learning</category><guid>https://shankarmsy.github.io/posts/forest-cover-types.html</guid><pubDate>Tue, 02 Dec 2014 12:15:33 GMT</pubDate></item><item><title>Saving the Titanic with R &amp; IPython</title><link>https://shankarmsy.github.io/posts/saving-titanic-r.html</link><dc:creator>Shankar Muthuswamy</dc:creator><description>&lt;div tabindex="-1" id="notebook" class="border-box-sizing"&gt;
    &lt;div class="container" id="notebook-container"&gt;

&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;The following is an illustration of one of my approaches to solving the Titanic Survival prediction challenge hosted by Kaggle. Below is an excerpt from the competition page.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;The sinking of the RMS Titanic is one of the most infamous shipwrecks in history. On April 15, 1912, during her maiden voyage, the Titanic sank after colliding with an iceberg, killing 1502 out of 2224 passengers and crew. This sensational tragedy shocked the international community and led to better safety regulations for ships.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;a href="https://shankarmsy.github.io/posts/saving-titanic-r.html"&gt;Read more…&lt;/a&gt; (55 min remaining to read)&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description><category>R</category><category>conditional trees</category><category>kaggle</category><category>logistic regression</category><category>random forests</category><category>scikit-learn</category><category>supervised learning</category><category>svm</category><category>titanic</category><guid>https://shankarmsy.github.io/posts/saving-titanic-r.html</guid><pubDate>Sun, 23 Nov 2014 10:11:09 GMT</pubDate></item><item><title>Recognizing Hand Written Digits (UCI ML Repo) with Support Vector Machines (SVM)</title><link>https://shankarmsy.github.io/posts/svm-sklearn.html</link><dc:creator>Shankar Muthuswamy</dc:creator><description>&lt;div tabindex="-1" id="notebook" class="border-box-sizing"&gt;
    &lt;div class="container" id="notebook-container"&gt;

&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;Support Vector Machines (SVMs) are a powerful supervised learning algorithm used for &lt;strong&gt;classification&lt;/strong&gt; or for &lt;strong&gt;regression&lt;/strong&gt;. SVMs are a &lt;strong&gt;discriminative&lt;/strong&gt; classifier: that is, they draw a boundary between clusters of data. In this post I will demonstrate hand-written digit recognition using the SVC classifier in scikit-learn. We'll make use of the online dataset available in the UCI machine learning repository.&lt;/p&gt;
&lt;p&gt;&lt;a href="https://shankarmsy.github.io/posts/svm-sklearn.html"&gt;Read more…&lt;/a&gt; (10 min remaining to read)&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description><category>digit recognition</category><category>scikit-learn</category><category>supervised learning</category><category>svm</category><guid>https://shankarmsy.github.io/posts/svm-sklearn.html</guid><pubDate>Wed, 19 Nov 2014 09:00:03 GMT</pubDate></item><item><title>Data Munging with Pandas (Advanced)</title><link>https://shankarmsy.github.io/posts/munging-pandas.html</link><dc:creator>Shankar Muthuswamy</dc:creator><description>&lt;div tabindex="-1" id="notebook" class="border-box-sizing"&gt;
    &lt;div class="container" id="notebook-container"&gt;

&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;Pandas is a Python library for doing data analysis. It's really fast and lets you do exploratory work incredibly quickly.&lt;/p&gt;
&lt;p&gt;In this post I will demonstrate some advanced data munging/wrangling concepts with the awesome Pandas. I intend to code more and write less but will add help text as much as possible. Check out the pandas help documentation to learn more.&lt;/p&gt;
&lt;p&gt;OK, let's get started. &lt;/p&gt;&lt;p&gt;&lt;a href="https://shankarmsy.github.io/posts/munging-pandas.html"&gt;Read more…&lt;/a&gt; (17 min remaining to read)&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description><category>data munging</category><category>pandas</category><category>python</category><category>scikit-learn</category><guid>https://shankarmsy.github.io/posts/munging-pandas.html</guid><pubDate>Mon, 17 Nov 2014 10:03:44 GMT</pubDate></item><item><title>Facial Image Compression and Reconstruction with PCA</title><link>https://shankarmsy.github.io/posts/pca-sklearn.html</link><dc:creator>Shankar Muthuswamy</dc:creator><description>&lt;div tabindex="-1" id="notebook" class="border-box-sizing"&gt;
    &lt;div class="container" id="notebook-container"&gt;

&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;Principle Component Analysis (PCA) is a dimension reduction technique that can find the combinations of variables that explain the most variance. In this post I will demonstrate dimensionality reduction concepts including facial image compression and reconstruction using PCA.&lt;/p&gt;
&lt;p&gt;Let's get started. &lt;/p&gt;&lt;p&gt;&lt;a href="https://shankarmsy.github.io/posts/pca-sklearn.html"&gt;Read more…&lt;/a&gt; (7 min remaining to read)&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description><category>dimensionality reduction</category><category>image compression</category><category>pca</category><category>scikit-learn</category><category>unsupervised learning</category><guid>https://shankarmsy.github.io/posts/pca-sklearn.html</guid><pubDate>Wed, 12 Nov 2014 18:04:24 GMT</pubDate></item><item><title>Dive-in to Pandas (Basic)</title><link>https://shankarmsy.github.io/posts/dive-in-pandas.html</link><dc:creator>Shankar Muthuswamy</dc:creator><description>&lt;div tabindex="-1" id="notebook" class="border-box-sizing"&gt;
    &lt;div class="container" id="notebook-container"&gt;

&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;Pandas is a Python library for doing data analysis. It's really fast and lets you do exploratory work incredibly quickly.&lt;/p&gt;
&lt;p&gt;It provides an R-like DataFrame, produces high quality plots with matplotlib, and integrates nicely with other libraries that expect NumPy arrays. In this post, I'll go through the basics of pandas. Check out the (very readable) pandas docs or the pandas cookbook if you want to learn more.&lt;/p&gt;
&lt;p&gt;OK, let's get started.&lt;/p&gt;
&lt;p&gt;&lt;a href="https://shankarmsy.github.io/posts/dive-in-pandas.html"&gt;Read more…&lt;/a&gt; (11 min remaining to read)&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description><category>data munging</category><category>pandas</category><category>python</category><category>scikit-learn</category><guid>https://shankarmsy.github.io/posts/dive-in-pandas.html</guid><pubDate>Wed, 05 Nov 2014 09:36:11 GMT</pubDate></item></channel></rss>