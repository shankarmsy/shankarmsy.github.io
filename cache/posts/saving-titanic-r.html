
<div class="text_cell_render border-box-sizing rendered_html">
<p>The following is an illustration of one of my approaches to solving the Titanic Survival prediction challenge hosted by Kaggle. Below is an excerpt from the competition page.</p>
<blockquote>
<p>The sinking of the RMS Titanic is one of the most infamous shipwrecks in history. On April 15, 1912, during her maiden voyage, the Titanic sank after colliding with an iceberg, killing 1502 out of 2224 passengers and crew. This sensational tragedy shocked the international community and led to better safety regulations for ships.</p>
</blockquote>
<!-- TEASER_END -->  
<blockquote>
<p>One of the reasons that the shipwreck led to such loss of life was that there were not enough lifeboats for the passengers and crew. Although there was some element of luck involved in surviving the sinking, some groups of people were more likely to survive than others, such as women, children, and the upper-class.</p>
<p>In this challenge, we ask you to complete the analysis of what sorts of people were likely to survive. In particular, we ask you to apply the tools of machine learning to predict which passengers survived the tragedy.</p>
</blockquote>
<p><em>Disclaimer</em><br />This pursuit infuses my own ideas with others I've had the privilege to learn from. I write to further my learning.</p>
<p>To get started, download the data files from Kaggle's website <a href="http://www.kaggle.com/c/titanic-gettingStarted/data">here</a>. You will see two CSV files, train and test. Download them to your working directory.</p>
</div>
<div class="text_cell_render border-box-sizing rendered_html">
<p>OK let's now take a look at the column descriptions provided for the dataset.</p>
<pre><code>VARIABLE DESCRIPTIONS:
survival        Survival
                (0 = No; 1 = Yes)
pclass          Passenger Class
                (1 = 1st; 2 = 2nd; 3 = 3rd)
name            Name
sex             Sex
age             Age
sibsp           Number of Siblings/Spouses Aboard
parch           Number of Parents/Children Aboard
ticket          Ticket Number
fare            Passenger Fare
cabin           Cabin
embarked        Port of Embarkation
                (C = Cherbourg; Q = Queenstown; S = Southampton)

SPECIAL NOTES:
Pclass is a proxy for socio-economic status (SES)
 1st ~ Upper; 2nd ~ Middle; 3rd ~ Lower

Age is in Years; Fractional if Age less than One (1)
 If the Age is Estimated, it is in the form xx.5

With respect to the family relation variables (i.e. sibsp and parch)
some relations were ignored.  The following are the definitions used
for sibsp and parch.

Sibling:  Brother, Sister, Stepbrother, or Stepsister of Passenger Aboard Titanic
Spouse:   Husband or Wife of Passenger Aboard Titanic (Mistresses and Fiances Ignored)
Parent:   Mother or Father of Passenger Aboard Titanic
Child:    Son, Daughter, Stepson, or Stepdaughter of Passenger Aboard Titanic

Other family relatives excluded from this study include cousins,
nephews/nieces, aunts/uncles, and in-laws.  Some children travelled
only with a nanny, therefore parch=0 for them.  As well, some
travelled with very close friends or neighbors in a village, however,
the definitions do not support such relations.</code></pre>
<p>Bottomline, we have some information about passengers traveling aboard the Titanic and we need to predict if train a model that can predict if one survived or not based on data similar to that provided in the dataset. Without further ado, let's get started.</p>
</div>
<div class="cell border-box-sizing code_cell vbox">
<div class="input hbox">
<div class="prompt input_prompt">
In&nbsp;[1]:
</div>
<div class="input_area box-flex1">
<div class="highlight"><pre><span class="c">#Load the R Magic so we can execute R scripts within this notebook</span>
<span class="o">%</span><span class="k">load_ext</span> <span class="n">rmagic</span>
</pre></div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell vbox">
<div class="input hbox">
<div class="prompt input_prompt">
In&nbsp;[2]:
</div>
<div class="input_area box-flex1">
<div class="highlight"><pre><span class="o">%%</span><span class="k">R</span>
<span class="c">#Note that every code block in this notebook will need to have the above line to enable IPython to understand we&#39;re coding R.</span>

<span class="c">#I&#39;ve downloaded the train and test CSV files to my work directory. You should too unless you cloned this repo.</span>
<span class="c">#While downloading the CSV files in R, let&#39;s do some data handling so it saves us the headache later on.</span>

<span class="c">#Define a read function so we don&#39;t need to do it twice. Column types specifies data types for each column and missing</span>
<span class="c">#types specify different types of null values possible.</span>
<span class="n">read_better</span> <span class="o">&lt;-</span> <span class="n">function</span><span class="p">(</span><span class="nb">file</span><span class="o">.</span><span class="n">name</span><span class="p">,</span> <span class="n">column</span><span class="o">.</span><span class="n">types</span><span class="p">,</span> <span class="n">missing</span><span class="o">.</span><span class="n">types</span><span class="p">)</span> <span class="p">{</span>
  <span class="n">read</span><span class="o">.</span><span class="n">csv</span><span class="p">(</span> <span class="nb">file</span><span class="o">.</span><span class="n">name</span><span class="p">,</span> 
            <span class="n">colClasses</span><span class="o">=</span><span class="n">column</span><span class="o">.</span><span class="n">types</span><span class="p">,</span>
            <span class="n">na</span><span class="o">.</span><span class="n">strings</span><span class="o">=</span><span class="n">missing</span><span class="o">.</span><span class="n">types</span> <span class="p">)</span>
<span class="p">}</span>

<span class="c">#Let&#39;s now define the column types</span>
<span class="n">column</span><span class="o">.</span><span class="n">types</span><span class="o">=</span><span class="n">c</span><span class="p">(</span><span class="s">&#39;integer&#39;</span><span class="p">,</span>   <span class="c"># PassengerId</span>
               <span class="s">&#39;factor&#39;</span><span class="p">,</span>    <span class="c"># Survived </span>
               <span class="s">&#39;factor&#39;</span><span class="p">,</span>    <span class="c"># Pclass</span>
               <span class="s">&#39;character&#39;</span><span class="p">,</span> <span class="c"># Name</span>
               <span class="s">&#39;factor&#39;</span><span class="p">,</span>    <span class="c"># Sex</span>
               <span class="s">&#39;numeric&#39;</span><span class="p">,</span>   <span class="c"># Age</span>
               <span class="s">&#39;integer&#39;</span><span class="p">,</span>   <span class="c"># SibSp</span>
               <span class="s">&#39;integer&#39;</span><span class="p">,</span>   <span class="c"># Parch</span>
               <span class="s">&#39;character&#39;</span><span class="p">,</span> <span class="c"># Ticket</span>
               <span class="s">&#39;numeric&#39;</span><span class="p">,</span>   <span class="c"># Fare</span>
               <span class="s">&#39;character&#39;</span><span class="p">,</span> <span class="c"># Cabin</span>
               <span class="s">&#39;factor&#39;</span><span class="p">)</span>    <span class="c"># Embarked</span>
<span class="c">#Different types of null values</span>
<span class="n">missing</span><span class="o">.</span><span class="n">types</span><span class="o">=</span><span class="n">c</span><span class="p">(</span><span class="s">&#39;NA&#39;</span><span class="p">,</span><span class="s">&#39;&#39;</span><span class="p">)</span> 

<span class="c">#Alright,let&#39;s read train</span>
<span class="n">orig_train</span><span class="o">&lt;-</span><span class="n">read_better</span><span class="p">(</span><span class="s">&#39;train.csv&#39;</span><span class="p">,</span> <span class="n">column</span><span class="o">.</span><span class="n">types</span><span class="p">,</span> <span class="n">missing</span><span class="o">.</span><span class="n">types</span><span class="p">)</span>

<span class="c">#For test, the Survived column (2nd col) doesn&#39;t exist, let&#39;s remove that type before reading.</span>
<span class="n">orig_test</span><span class="o">&lt;-</span><span class="n">read_better</span><span class="p">(</span><span class="s">&#39;test.csv&#39;</span><span class="p">,</span> <span class="n">column</span><span class="o">.</span><span class="n">types</span><span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">],</span> <span class="n">missing</span><span class="o">.</span><span class="n">types</span><span class="p">)</span>

<span class="c">#Let&#39;s make copies so we never have to read again</span>
<span class="n">train</span><span class="o">&lt;-</span><span class="n">orig_train</span>
<span class="n">test</span><span class="o">&lt;-</span><span class="n">orig_test</span>

<span class="c">#Quickly print a summary of train</span>
<span class="n">summary</span><span class="p">(</span><span class="n">train</span><span class="p">)</span>
</pre></div>

</div>
</div>

<div class="vbox output_wrapper">
<div class="output vbox">


<div class="hbox output_area"><div class="prompt"></div>
<div class="box-flex1 output_subarea output_display_data">


<pre>
  PassengerId    Survived Pclass      Name               Sex     
 Min.   :  1.0   0:549    1:216   Length:891         female:314  
 1st Qu.:223.5   1:342    2:184   Class :character   male  :577  
 Median :446.0            3:491   Mode  :character               
 Mean   :446.0                                                   
 3rd Qu.:668.5                                                   
 Max.   :891.0                                                   
                                                                 
      Age            SibSp           Parch           Ticket         
 Min.   : 0.42   Min.   :0.000   Min.   :0.0000   Length:891        
 1st Qu.:20.12   1st Qu.:0.000   1st Qu.:0.0000   Class :character  
 Median :28.00   Median :0.000   Median :0.0000   Mode  :character  
 Mean   :29.70   Mean   :0.523   Mean   :0.3816                     
 3rd Qu.:38.00   3rd Qu.:1.000   3rd Qu.:0.0000                     
 Max.   :80.00   Max.   :8.000   Max.   :6.0000                     
 NA&apos;s   :177                                                        
      Fare           Cabin           Embarked  
 Min.   :  0.00   Length:891         C   :168  
 1st Qu.:  7.91   Class :character   Q   : 77  
 Median : 14.45   Mode  :character   S   :644  
 Mean   : 32.20                      NA&apos;s:  2  
 3rd Qu.: 31.00                                
 Max.   :512.33                                
                                               

</pre>

</div>
</div>

</div>
</div>

</div>
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="data-munging">Data Munging</h3>
<p>Munging is essentially cleansing the data so it's ready for our super sophisticated Machine Learning algorithms :-)</p>
<p>Ideally I'd like to use Pandas which is an awesome tool for these types of things but considering Pandas itself was inspired from R, we will try the whole thing in R this time. I'll create a seperate notebook later to do it all in sklearn/pandas.</p>
<p>Alright let's get started. The first step of any Data Cleansing process is Visualization. Why is that? I asked the question myself but how would you cleanse something when you don't know what it is? And what better way to understand data than by looking at in colourful visualizations. Let's go and create some.</p>
</div>
<div class="cell border-box-sizing code_cell vbox">
<div class="input hbox">
<div class="prompt input_prompt">
In&nbsp;[3]:
</div>
<div class="input_area box-flex1">
<div class="highlight"><pre><span class="o">%%</span><span class="k">R</span>
<span class="c">#I loved the look of this R package that provides the missing map which can give you a super quick peek into the dataset.</span>
<span class="c">#You&#39;ll need the Amelia package for this visualization.</span>

<span class="c">#install.packages(&quot;Amelia&quot;)</span>
<span class="n">require</span><span class="p">(</span><span class="n">Amelia</span><span class="p">)</span>
<span class="n">missmap</span><span class="p">(</span><span class="n">train</span><span class="p">,</span> <span class="n">main</span><span class="o">=</span><span class="s">&quot;Titanic - Missing Data Map&quot;</span><span class="p">,</span> <span class="n">col</span><span class="o">=</span><span class="n">c</span><span class="p">(</span><span class="s">&quot;forestgreen&quot;</span><span class="p">,</span><span class="s">&quot;lightskyblue2&quot;</span><span class="p">),</span> <span class="n">legend</span><span class="o">=</span><span class="n">FALSE</span><span class="p">)</span>
</pre></div>

</div>
</div>

<div class="vbox output_wrapper">
<div class="output vbox">


<div class="hbox output_area"><div class="prompt"></div>
<div class="box-flex1 output_subarea output_display_data">


<pre>
Loading required package: Amelia
Loading required package: Rcpp
## 
## Amelia II: Multiple Imputation
## (Version 1.7.3, built: 2014-11-14)
## Copyright (C) 2005-2014 James Honaker, Gary King and Matthew Blackwell
## Refer to http://gking.harvard.edu/amelia/ for more information
## 

</pre>

</div>
</div>

<div class="hbox output_area"><div class="prompt"></div>
<div class="box-flex1 output_subarea output_display_data">


<img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAeAAAAHgCAIAAADytinCAAAgAElEQVR4nO3de1zM6f8//mvGdJBm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">

</div>
</div>

</div>
</div>

</div>
<div class="text_cell_render border-box-sizing rendered_html">
<p>It's obvious looking at this map that the most values missing are in the Cabin and Age columns. Cabin basically refers to the cabin# of each passenger and considering how many values are missing, we could as well just drop it. Age however is critical and we need a better mechanism to handle. There is also one missing Embarked value.</p>
</div>
<div class="cell border-box-sizing code_cell vbox">
<div class="input hbox">
<div class="prompt input_prompt">
In&nbsp;[4]:
</div>
<div class="input_area box-flex1">
<div class="highlight"><pre><span class="o">%%</span><span class="k">R</span>
<span class="c">#OK let&#39;s plot a series of visualizations that can hopefully explain the data better&quot;</span>

<span class="c">#Proportion of Survivors</span>
<span class="n">barplot</span><span class="p">(</span><span class="n">prop</span><span class="o">.</span><span class="n">table</span><span class="p">(</span><span class="n">table</span><span class="p">(</span><span class="n">train</span><span class="err">$</span><span class="n">Survived</span><span class="p">)),</span> <span class="n">names</span><span class="o">.</span><span class="n">arg</span><span class="o">=</span><span class="n">c</span><span class="p">(</span><span class="s">&#39;Didn</span><span class="se">\&#39;</span><span class="s">t Survive&#39;</span><span class="p">,</span> <span class="s">&#39;Survived&#39;</span><span class="p">),</span> <span class="n">main</span><span class="o">=</span><span class="s">&quot;Proportion of Survivors&quot;</span><span class="p">,</span>
       <span class="n">col</span><span class="o">=</span><span class="n">c</span><span class="p">(</span><span class="s">&#39;mistyrose&#39;</span><span class="p">,</span><span class="s">&#39;lightseagreen&#39;</span><span class="p">))</span>

<span class="c">#Clearly more people died than survived.</span>
</pre></div>

</div>
</div>

<div class="vbox output_wrapper">
<div class="output vbox">


<div class="hbox output_area"><div class="prompt"></div>
<div class="box-flex1 output_subarea output_display_data">


<img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAeAAAAHgCAMAAABKCk6nAAAC+lBMVEUAAAABAQECAgIDAwMEBAQF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">

</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell vbox">
<div class="input hbox">
<div class="prompt input_prompt">
In&nbsp;[5]:
</div>
<div class="input_area box-flex1">
<div class="highlight"><pre><span class="o">%%</span><span class="k">R</span>
<span class="c">#Proportion of Survivors by Gender</span>
<span class="n">barplot</span><span class="p">(</span><span class="n">prop</span><span class="o">.</span><span class="n">table</span><span class="p">(</span><span class="n">table</span><span class="p">(</span><span class="n">train</span><span class="err">$</span><span class="n">Sex</span><span class="p">,</span> <span class="n">train</span><span class="err">$</span><span class="n">Survived</span><span class="p">),</span> <span class="mi">1</span><span class="p">),</span> <span class="n">names</span><span class="o">.</span><span class="n">arg</span><span class="o">=</span><span class="n">c</span><span class="p">(</span><span class="s">&#39;Didn</span><span class="se">\&#39;</span><span class="s">t Survive&#39;</span><span class="p">,</span> <span class="s">&#39;Survived&#39;</span><span class="p">),</span> 
        <span class="n">main</span><span class="o">=</span><span class="s">&quot;Proportion of Survivors by Gender&quot;</span><span class="p">,</span> <span class="n">legend</span><span class="o">=</span><span class="n">TRUE</span><span class="p">,</span> <span class="n">col</span><span class="o">=</span><span class="n">c</span><span class="p">(</span><span class="s">&#39;darksalmon&#39;</span><span class="p">,</span><span class="s">&#39;paleturquoise&#39;</span><span class="p">))</span>

<span class="c">#More Females survived than Males. This is understandable considering the ladies and children first approach for survival.</span>
</pre></div>

</div>
</div>

<div class="vbox output_wrapper">
<div class="output vbox">


<div class="hbox output_area"><div class="prompt"></div>
<div class="box-flex1 output_subarea output_display_data">


<img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAeAAAAHgCAIAAADytinCAAAgAElEQVR4nO3de1hUdeL48Q8wMVwF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==
">

</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell vbox">
<div class="input hbox">
<div class="prompt input_prompt">
In&nbsp;[6]:
</div>
<div class="input_area box-flex1">
<div class="highlight"><pre><span class="o">%%</span><span class="k">R</span>
<span class="c">#Proportion of Survivors by Class of Travel - let&#39;s do a mosaicplot this time for fun.</span>
<span class="n">mosaicplot</span><span class="p">(</span><span class="n">prop</span><span class="o">.</span><span class="n">table</span><span class="p">(</span><span class="n">table</span><span class="p">(</span><span class="n">train</span><span class="err">$</span><span class="n">Pclass</span><span class="p">,</span> <span class="n">train</span><span class="err">$</span><span class="n">Survived</span><span class="p">),</span> <span class="mi">1</span><span class="p">),</span> <span class="n">main</span><span class="o">=</span><span class="s">&quot;Proportion of Survivors by Pclass&quot;</span><span class="p">,</span> 
           <span class="n">xlab</span><span class="o">=</span><span class="s">&#39;Pclass&#39;</span><span class="p">,</span> <span class="n">ylab</span><span class="o">=</span><span class="s">&#39;Survived ?&#39;</span><span class="p">,</span><span class="n">col</span><span class="o">=</span><span class="n">c</span><span class="p">(</span><span class="s">&#39;darkturquoise&#39;</span><span class="p">,</span><span class="s">&#39;mediumspringgreen&#39;</span><span class="p">))</span>

<span class="c">#Looks like those traveling in upper class (3) were more lucky than the rest. We&#39;ll keep this in mind.</span>
</pre></div>

</div>
</div>

<div class="vbox output_wrapper">
<div class="output vbox">


<div class="hbox output_area"><div class="prompt"></div>
<div class="box-flex1 output_subarea output_display_data">


<img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAeAAAAHgCAIAAADytinCAAAc70lEQVR4nO3de1RVZfrA8fdwGC5y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">

</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell vbox">
<div class="input hbox">
<div class="prompt input_prompt">
In&nbsp;[7]:
</div>
<div class="input_area box-flex1">
<div class="highlight"><pre><span class="o">%%</span><span class="k">R</span>
<span class="c">#OK let&#39;s do a quick plot by Age - remember that we need to fill in missing values for this column.</span>
<span class="n">boxplot</span><span class="p">(</span><span class="n">train</span><span class="err">$</span><span class="n">Age</span><span class="o">~</span><span class="n">train</span><span class="err">$</span><span class="n">Survived</span><span class="p">,</span><span class="n">main</span><span class="o">=</span><span class="s">&quot;Proportion of Survivors by Age&quot;</span><span class="p">,</span> <span class="n">col</span><span class="o">=</span><span class="n">c</span><span class="p">(</span><span class="s">&#39;darkseagreen4&#39;</span><span class="p">,</span><span class="s">&#39;salmon4&#39;</span><span class="p">),</span> <span class="n">xlab</span><span class="o">=</span><span class="s">&quot;Survived ?&quot;</span><span class="p">,</span>
       <span class="n">ylab</span><span class="o">=</span><span class="s">&quot;Age&quot;</span><span class="p">)</span>

<span class="c">#OK that was a helpful plot, it clearly tells us that there were more survivors in the 20-35 Age bracket, young legs perhaps?</span>
</pre></div>

</div>
</div>

<div class="vbox output_wrapper">
<div class="output vbox">


<div class="hbox output_area"><div class="prompt"></div>
<div class="box-flex1 output_subarea output_display_data">


<img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAeAAAAHgCAIAAADytinCAAAgAElEQVR4nO3de1zUdb7H8e/AwHAV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==
">

</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell vbox">
<div class="input hbox">
<div class="prompt input_prompt">
In&nbsp;[8]:
</div>
<div class="input_area box-flex1">
<div class="highlight"><pre><span class="o">%%</span><span class="k">R</span>
<span class="c">#OK let&#39;s get down to business. We&#39;ll look at how many values are missing for Age.</span>
<span class="n">summary</span><span class="p">(</span><span class="n">train</span><span class="err">$</span><span class="n">Age</span><span class="p">)</span>

<span class="c">#177 is a lot considering our dataset is really small. Let&#39;s try to find a meaningful way to fill these up.</span>

<span class="c">#The determining factors so far has been Gender and Pclass. Can we find out how many Age values are missing by Gender?</span>
<span class="n">barplot</span><span class="p">(</span><span class="n">table</span><span class="p">(</span><span class="n">train</span><span class="err">$</span><span class="n">Sex</span><span class="p">[</span><span class="n">which</span><span class="p">(</span><span class="ow">is</span><span class="o">.</span><span class="n">na</span><span class="p">(</span><span class="n">train</span><span class="err">$</span><span class="n">Age</span><span class="p">))]),</span><span class="n">main</span><span class="o">=</span><span class="s">&quot;Proportion of Missing Ages by Gender&quot;</span><span class="p">,</span> 
        <span class="n">col</span><span class="o">=</span><span class="n">c</span><span class="p">(</span><span class="s">&#39;lightsteelblue&#39;</span><span class="p">,</span><span class="s">&#39;bisque3&#39;</span><span class="p">),</span> <span class="n">xlab</span><span class="o">=</span><span class="s">&quot;Gender&quot;</span><span class="p">,</span> <span class="n">ylab</span><span class="o">=</span><span class="s">&quot;Missing Ages&quot;</span><span class="p">)</span>

<span class="c">#OK that&#39;s clearly tilted in favor of males. We&#39;re a sloppy bunch, aren&#39;t we?</span>
</pre></div>

</div>
</div>

<div class="vbox output_wrapper">
<div class="output vbox">


<div class="hbox output_area"><div class="prompt"></div>
<div class="box-flex1 output_subarea output_display_data">


<img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAeAAAAHgCAIAAADytinCAAAgAElEQVR4nO3de1xU9b7/8e/gxHAV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">

</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell vbox">
<div class="input hbox">
<div class="prompt input_prompt">
In&nbsp;[9]:
</div>
<div class="input_area box-flex1">
<div class="highlight"><pre><span class="o">%%</span><span class="k">R</span>
<span class="c">#How about missing Age values by Pclass?</span>
<span class="n">barplot</span><span class="p">(</span><span class="n">table</span><span class="p">(</span><span class="n">train</span><span class="err">$</span><span class="n">Pclass</span><span class="p">[</span><span class="n">which</span><span class="p">(</span><span class="ow">is</span><span class="o">.</span><span class="n">na</span><span class="p">(</span><span class="n">train</span><span class="err">$</span><span class="n">Age</span><span class="p">))]),</span><span class="n">main</span><span class="o">=</span><span class="s">&quot;Proportion of Missing Ages by Pclass&quot;</span><span class="p">,</span> 
        <span class="n">col</span><span class="o">=</span><span class="n">c</span><span class="p">(</span><span class="s">&#39;mediumseagreen&#39;</span><span class="p">,</span><span class="s">&#39;rosybrown4&#39;</span><span class="p">,</span><span class="s">&#39;mediumslateblue&#39;</span><span class="p">),</span> <span class="n">xlab</span><span class="o">=</span><span class="s">&quot;Pclass&quot;</span><span class="p">,</span> <span class="n">ylab</span><span class="o">=</span><span class="s">&quot;Missing Ages&quot;</span><span class="p">)</span>

<span class="c">#There&#39;s our most important highlight yet. Most of the ages we&#39;re missing are in Pclass 3. So this goes to show, we will</span>
<span class="c">#probably be better off taking the median of ages for each Pclass and gender and filling the null values with it. That</span>
<span class="c">#should be better than simply filling all with overall median.</span>
</pre></div>

</div>
</div>

<div class="vbox output_wrapper">
<div class="output vbox">


<div class="hbox output_area"><div class="prompt"></div>
<div class="box-flex1 output_subarea output_display_data">


<img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAeAAAAHgCAIAAADytinCAAAgAElEQVR4nO3df1yUdb7///fALMNP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">

</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell vbox">
<div class="input hbox">
<div class="prompt input_prompt">
In&nbsp;[10]:
</div>
<div class="input_area box-flex1">
<div class="highlight"><pre><span class="o">%%</span><span class="k">R</span>
<span class="c">#Let&#39;s go ahead and do the honors. Note that we could do all of this with a single sophisticated function but I am</span>
<span class="c">#choosing to keep things simple at the moment.</span>

<span class="c">#Before we make any changes to Train, let&#39;s combine Train and Test temporarily to a new dataset. Since any change we need</span>
<span class="c">#to make to Train needs to be made to Test as well, we can do the changes only once and split the datasets again later.</span>

<span class="c">#We&#39;ll first add the Survived Column to the Test set since it doesn&#39;t exist and init to NULL values since we won&#39;t use it.</span>
<span class="n">test</span><span class="err">$</span><span class="n">Survived</span><span class="o">&lt;-</span><span class="n">rep</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="n">nrow</span><span class="p">(</span><span class="n">test</span><span class="p">))</span>
<span class="n">titanic</span><span class="o">&lt;-</span><span class="n">rbind</span><span class="p">(</span><span class="n">train</span><span class="p">,</span><span class="n">test</span><span class="p">)</span>

<span class="c">#na.rm basically calculates mean for all non-null values. We then plug the medi</span>
<span class="n">titanic</span><span class="err">$</span><span class="n">Age</span><span class="p">[</span><span class="n">which</span><span class="p">(</span><span class="n">titanic</span><span class="err">$</span><span class="n">Pclass</span><span class="o">==</span><span class="mi">3</span> <span class="o">&amp;</span> <span class="n">titanic</span><span class="err">$</span><span class="n">Sex</span><span class="o">==</span><span class="s">&quot;female&quot;</span> <span class="o">&amp;</span> <span class="ow">is</span><span class="o">.</span><span class="n">na</span><span class="p">(</span><span class="n">titanic</span><span class="err">$</span><span class="n">Age</span><span class="p">))]</span><span class="o">&lt;-</span>
        <span class="n">median</span><span class="p">(</span><span class="n">titanic</span><span class="err">$</span><span class="n">Age</span><span class="p">[</span><span class="n">which</span><span class="p">(</span><span class="n">titanic</span><span class="err">$</span><span class="n">Pclass</span><span class="o">==</span><span class="mi">3</span> <span class="o">&amp;</span> <span class="n">titanic</span><span class="err">$</span><span class="n">Sex</span><span class="o">==</span><span class="s">&quot;female&quot;</span><span class="p">)],</span><span class="n">na</span><span class="o">.</span><span class="n">rm</span><span class="o">=</span><span class="n">TRUE</span><span class="p">)</span>
<span class="n">titanic</span><span class="err">$</span><span class="n">Age</span><span class="p">[</span><span class="n">which</span><span class="p">(</span><span class="n">titanic</span><span class="err">$</span><span class="n">Pclass</span><span class="o">==</span><span class="mi">2</span> <span class="o">&amp;</span> <span class="n">titanic</span><span class="err">$</span><span class="n">Sex</span><span class="o">==</span><span class="s">&quot;female&quot;</span> <span class="o">&amp;</span> <span class="ow">is</span><span class="o">.</span><span class="n">na</span><span class="p">(</span><span class="n">titanic</span><span class="err">$</span><span class="n">Age</span><span class="p">))]</span><span class="o">&lt;-</span>
        <span class="n">median</span><span class="p">(</span><span class="n">titanic</span><span class="err">$</span><span class="n">Age</span><span class="p">[</span><span class="n">which</span><span class="p">(</span><span class="n">titanic</span><span class="err">$</span><span class="n">Pclass</span><span class="o">==</span><span class="mi">3</span> <span class="o">&amp;</span> <span class="n">titanic</span><span class="err">$</span><span class="n">Sex</span><span class="o">==</span><span class="s">&quot;female&quot;</span><span class="p">)],</span><span class="n">na</span><span class="o">.</span><span class="n">rm</span><span class="o">=</span><span class="n">TRUE</span><span class="p">)</span>
<span class="n">titanic</span><span class="err">$</span><span class="n">Age</span><span class="p">[</span><span class="n">which</span><span class="p">(</span><span class="n">titanic</span><span class="err">$</span><span class="n">Pclass</span><span class="o">==</span><span class="mi">1</span> <span class="o">&amp;</span> <span class="n">titanic</span><span class="err">$</span><span class="n">Sex</span><span class="o">==</span><span class="s">&quot;female&quot;</span> <span class="o">&amp;</span> <span class="ow">is</span><span class="o">.</span><span class="n">na</span><span class="p">(</span><span class="n">titanic</span><span class="err">$</span><span class="n">Age</span><span class="p">))]</span><span class="o">&lt;-</span>
        <span class="n">median</span><span class="p">(</span><span class="n">titanic</span><span class="err">$</span><span class="n">Age</span><span class="p">[</span><span class="n">which</span><span class="p">(</span><span class="n">titanic</span><span class="err">$</span><span class="n">Pclass</span><span class="o">==</span><span class="mi">3</span> <span class="o">&amp;</span> <span class="n">titanic</span><span class="err">$</span><span class="n">Sex</span><span class="o">==</span><span class="s">&quot;female&quot;</span><span class="p">)],</span><span class="n">na</span><span class="o">.</span><span class="n">rm</span><span class="o">=</span><span class="n">TRUE</span><span class="p">)</span>
<span class="n">titanic</span><span class="err">$</span><span class="n">Age</span><span class="p">[</span><span class="n">which</span><span class="p">(</span><span class="n">titanic</span><span class="err">$</span><span class="n">Pclass</span><span class="o">==</span><span class="mi">3</span> <span class="o">&amp;</span> <span class="n">titanic</span><span class="err">$</span><span class="n">Sex</span><span class="o">==</span><span class="s">&quot;male&quot;</span> <span class="o">&amp;</span> <span class="ow">is</span><span class="o">.</span><span class="n">na</span><span class="p">(</span><span class="n">titanic</span><span class="err">$</span><span class="n">Age</span><span class="p">))]</span><span class="o">&lt;-</span>
        <span class="n">median</span><span class="p">(</span><span class="n">titanic</span><span class="err">$</span><span class="n">Age</span><span class="p">[</span><span class="n">which</span><span class="p">(</span><span class="n">titanic</span><span class="err">$</span><span class="n">Pclass</span><span class="o">==</span><span class="mi">3</span> <span class="o">&amp;</span> <span class="n">titanic</span><span class="err">$</span><span class="n">Sex</span><span class="o">==</span><span class="s">&quot;female&quot;</span><span class="p">)],</span><span class="n">na</span><span class="o">.</span><span class="n">rm</span><span class="o">=</span><span class="n">TRUE</span><span class="p">)</span>
<span class="n">titanic</span><span class="err">$</span><span class="n">Age</span><span class="p">[</span><span class="n">which</span><span class="p">(</span><span class="n">titanic</span><span class="err">$</span><span class="n">Pclass</span><span class="o">==</span><span class="mi">2</span> <span class="o">&amp;</span> <span class="n">titanic</span><span class="err">$</span><span class="n">Sex</span><span class="o">==</span><span class="s">&quot;male&quot;</span> <span class="o">&amp;</span> <span class="ow">is</span><span class="o">.</span><span class="n">na</span><span class="p">(</span><span class="n">titanic</span><span class="err">$</span><span class="n">Age</span><span class="p">))]</span><span class="o">&lt;-</span>
        <span class="n">median</span><span class="p">(</span><span class="n">titanic</span><span class="err">$</span><span class="n">Age</span><span class="p">[</span><span class="n">which</span><span class="p">(</span><span class="n">titanic</span><span class="err">$</span><span class="n">Pclass</span><span class="o">==</span><span class="mi">3</span> <span class="o">&amp;</span> <span class="n">titanic</span><span class="err">$</span><span class="n">Sex</span><span class="o">==</span><span class="s">&quot;female&quot;</span><span class="p">)],</span><span class="n">na</span><span class="o">.</span><span class="n">rm</span><span class="o">=</span><span class="n">TRUE</span><span class="p">)</span>
<span class="n">titanic</span><span class="err">$</span><span class="n">Age</span><span class="p">[</span><span class="n">which</span><span class="p">(</span><span class="n">titanic</span><span class="err">$</span><span class="n">Pclass</span><span class="o">==</span><span class="mi">1</span> <span class="o">&amp;</span> <span class="n">titanic</span><span class="err">$</span><span class="n">Sex</span><span class="o">==</span><span class="s">&quot;male&quot;</span> <span class="o">&amp;</span> <span class="ow">is</span><span class="o">.</span><span class="n">na</span><span class="p">(</span><span class="n">titanic</span><span class="err">$</span><span class="n">Age</span><span class="p">))]</span><span class="o">&lt;-</span>
        <span class="n">median</span><span class="p">(</span><span class="n">titanic</span><span class="err">$</span><span class="n">Age</span><span class="p">[</span><span class="n">which</span><span class="p">(</span><span class="n">titanic</span><span class="err">$</span><span class="n">Pclass</span><span class="o">==</span><span class="mi">3</span> <span class="o">&amp;</span> <span class="n">titanic</span><span class="err">$</span><span class="n">Sex</span><span class="o">==</span><span class="s">&quot;female&quot;</span><span class="p">)],</span><span class="n">na</span><span class="o">.</span><span class="n">rm</span><span class="o">=</span><span class="n">TRUE</span><span class="p">)</span>

<span class="c">#Let&#39;s do a quick summary of the Age column to make sure there are no nulls remaining</span>

<span class="n">summary</span><span class="p">(</span><span class="n">titanic</span><span class="err">$</span><span class="n">Age</span><span class="p">)</span>
</pre></div>

</div>
</div>

<div class="vbox output_wrapper">
<div class="output vbox">


<div class="hbox output_area"><div class="prompt"></div>
<div class="box-flex1 output_subarea output_display_data">


<pre>
   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
   0.17   22.00   24.00   28.30   35.00   80.00 

</pre>

</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell vbox">
<div class="input hbox">
<div class="prompt input_prompt">
In&nbsp;[11]:
</div>
<div class="input_area box-flex1">
<div class="highlight"><pre><span class="o">%%</span><span class="k">R</span>
<span class="c">#Let&#39;s turn our attention to the Embarked Column</span>
<span class="n">summary</span><span class="p">(</span><span class="n">titanic</span><span class="err">$</span><span class="n">Embarked</span><span class="p">)</span>

<span class="c">#There are just 2 missing values and S seems to be the majority so let&#39;s plug in S</span>
<span class="n">titanic</span><span class="err">$</span><span class="n">Embarked</span><span class="p">[</span><span class="n">which</span><span class="p">(</span><span class="ow">is</span><span class="o">.</span><span class="n">na</span><span class="p">(</span><span class="n">titanic</span><span class="err">$</span><span class="n">Embarked</span><span class="p">))]</span> <span class="o">&lt;-</span> <span class="s">&#39;S&#39;</span>

<span class="n">summary</span><span class="p">(</span><span class="n">titanic</span><span class="err">$</span><span class="n">Embarked</span><span class="p">)</span>
</pre></div>

</div>
</div>

<div class="vbox output_wrapper">
<div class="output vbox">


<div class="hbox output_area"><div class="prompt"></div>
<div class="box-flex1 output_subarea output_display_data">


<pre>
  C   Q   S 
270 123 916 

</pre>

</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell vbox">
<div class="input hbox">
<div class="prompt input_prompt">
In&nbsp;[12]:
</div>
<div class="input_area box-flex1">
<div class="highlight"><pre><span class="o">%%</span><span class="k">R</span>
<span class="c">#Let&#39;s remove the Cabin column which contains way too many NULLs and will probably not give anything new considering</span>
<span class="c">#we already have the port of embarcation.</span>
<span class="n">titanic</span><span class="err">$</span><span class="n">Cabin</span><span class="o">&lt;-</span><span class="n">NULL</span>
</pre></div>

</div>
</div>

</div>
<div class="text_cell_render border-box-sizing rendered_html">
<h4 id="feature-engineering">Feature Engineering</h4>
<p>Feature Engineering refers to manufacturing new features based on the idea that they may replace existing ones because they are easier for the machine learning algorithms to digest or extend the value of existing feature(s) because they're more relevant for the predictions we're trying to make. Let's see what new features we can add to the Titanic dataset.</p>
</div>
<div class="cell border-box-sizing code_cell vbox">
<div class="input hbox">
<div class="prompt input_prompt">
In&nbsp;[13]:
</div>
<div class="input_area box-flex1">
<div class="highlight"><pre><span class="o">%%</span><span class="k">R</span>
<span class="c">#OK we all know that they tried to save the women and children first aboard the titanic. We have gender which identifies</span>
<span class="c">#women but no identifier for children. Let&#39;s call all passengers with Age &lt; 18 children shall we?</span>
<span class="n">titanic</span><span class="err">$</span><span class="n">Child</span><span class="o">&lt;-</span><span class="mi">0</span>
<span class="n">titanic</span><span class="err">$</span><span class="n">Child</span><span class="p">[</span><span class="n">which</span><span class="p">(</span><span class="n">titanic</span><span class="err">$</span><span class="n">Age</span><span class="o">&lt;</span><span class="mi">18</span><span class="p">)]</span><span class="o">&lt;-</span><span class="mi">1</span>
</pre></div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell vbox">
<div class="input hbox">
<div class="prompt input_prompt">
In&nbsp;[14]:
</div>
<div class="input_area box-flex1">
<div class="highlight"><pre><span class="o">%%</span><span class="k">R</span>
<span class="c">#We have a column called fare which is a numeric value of the actual fare that was paid for the trip. This column as such</span>
<span class="c">#might not be very useful but what if we can break it down to different buckets - say &lt;20, 20-40, 40-60, 60+. Recall that</span>
<span class="c">#we had noticed a curious fact with respect to the range 20-35, let&#39;s make sure that is covered in a single bucket.</span>
<span class="n">titanic</span><span class="err">$</span><span class="n">FareGroup</span><span class="o">&lt;-</span><span class="s">&#39;40+&#39;</span>
<span class="n">titanic</span><span class="err">$</span><span class="n">FareGroup</span><span class="p">[</span><span class="n">which</span><span class="p">(</span><span class="n">titanic</span><span class="err">$</span><span class="n">Fare</span><span class="o">&lt;</span><span class="mi">10</span><span class="p">)]</span> <span class="o">&lt;-</span> <span class="s">&#39;&lt;10&#39;</span>
<span class="n">titanic</span><span class="err">$</span><span class="n">FareGroup</span><span class="p">[</span><span class="n">which</span><span class="p">(</span><span class="n">titanic</span><span class="err">$</span><span class="n">Fare</span><span class="o">&gt;=</span><span class="mi">10</span> <span class="o">&amp;</span> <span class="n">titanic</span><span class="err">$</span><span class="n">Fare</span><span class="o">&lt;</span><span class="mi">20</span><span class="p">)]</span> <span class="o">&lt;-</span> <span class="s">&#39;10-20&#39;</span>
<span class="n">titanic</span><span class="err">$</span><span class="n">FareGroup</span><span class="p">[</span><span class="n">which</span><span class="p">(</span><span class="n">titanic</span><span class="err">$</span><span class="n">Fare</span><span class="o">&gt;=</span><span class="mi">20</span> <span class="o">&amp;</span> <span class="n">titanic</span><span class="err">$</span><span class="n">Fare</span><span class="o">&lt;</span><span class="mi">40</span><span class="p">)]</span> <span class="o">&lt;-</span> <span class="s">&#39;20-40&#39;</span>

<span class="n">titanic</span><span class="err">$</span><span class="n">FareGroup</span><span class="o">&lt;-</span><span class="k">as</span><span class="o">.</span><span class="n">factor</span><span class="p">(</span><span class="n">titanic</span><span class="err">$</span><span class="n">FareGroup</span><span class="p">)</span>

<span class="n">barplot</span><span class="p">(</span><span class="n">table</span><span class="p">(</span><span class="n">titanic</span><span class="err">$</span><span class="n">FareGroup</span><span class="p">),</span><span class="n">col</span><span class="o">=</span><span class="s">&#39;tomato1&#39;</span><span class="p">,</span><span class="n">main</span><span class="o">=</span><span class="s">&#39;Fare Groups&#39;</span><span class="p">)</span>
</pre></div>

</div>
</div>

<div class="vbox output_wrapper">
<div class="output vbox">


<div class="hbox output_area"><div class="prompt"></div>
<div class="box-flex1 output_subarea output_display_data">


<img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAeAAAAHgCAMAAABKCk6nAAAC31BMVEUAAAABAQECAgIDAwMEBAQG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">

</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell vbox">
<div class="input hbox">
<div class="prompt input_prompt">
In&nbsp;[15]:
</div>
<div class="input_area box-flex1">
<div class="highlight"><pre><span class="o">%%</span><span class="k">R</span>
<span class="c">#Name is another clear candidate that might not be of great value to us. What could a name contribute to predicting if he/she</span>
<span class="c">#actually survived? Well, it may not directly but it could contain things that influence the prediction. Let&#39;s print a few </span>
<span class="c">#names to see.</span>
<span class="n">tail</span><span class="p">(</span><span class="n">titanic</span><span class="err">$</span><span class="n">Name</span><span class="p">)</span>

<span class="c">#We can see that the names seem to be in similar format and have a title in between the surname and first name. Can we </span>
<span class="c">#extract the Titles from the names?</span>
</pre></div>

</div>
</div>

<div class="vbox output_wrapper">
<div class="output vbox">


<div class="hbox output_area"><div class="prompt"></div>
<div class="box-flex1 output_subarea output_display_data">


<pre>
[1] &quot;Henriksson, Miss. Jenny Lovisa&quot; &quot;Spector, Mr. Woolf&quot;            
[3] &quot;Oliva y Ocana, Dona. Fermina&quot;   &quot;Saether, Mr. Simon Sivertsen&quot;  
[5] &quot;Ware, Mr. Frederick&quot;            &quot;Peter, Master. Michael J&quot;      

</pre>

</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell vbox">
<div class="input hbox">
<div class="prompt input_prompt">
In&nbsp;[16]:
</div>
<div class="input_area box-flex1">
<div class="highlight"><pre><span class="o">%%</span><span class="k">R</span>
<span class="c">#We could use the strsplit function to split based on , and . then capture the middle items which should be the title. The</span>
<span class="c">#sapply function helps to perform this for the entire dataframe. function keyword is just like lambda in python. We will</span>
<span class="c">#also remove any extra whitespaces.</span>
<span class="n">titanic</span><span class="err">$</span><span class="n">Title</span><span class="o">&lt;-</span><span class="n">sapply</span><span class="p">(</span><span class="n">titanic</span><span class="err">$</span><span class="n">Name</span><span class="p">,</span> <span class="n">FUN</span><span class="o">=</span><span class="n">function</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="p">{</span><span class="n">strsplit</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">split</span><span class="o">=</span><span class="s">&#39;[,.]&#39;</span><span class="p">)[[</span><span class="mi">1</span><span class="p">]][</span><span class="mi">2</span><span class="p">]})</span>
<span class="n">titanic</span><span class="err">$</span><span class="n">Title</span><span class="o">&lt;-</span><span class="n">sub</span><span class="p">(</span><span class="s">&#39; &#39;</span><span class="p">,</span><span class="s">&#39;&#39;</span><span class="p">,</span><span class="n">titanic</span><span class="err">$</span><span class="n">Title</span><span class="p">)</span>
<span class="n">head</span><span class="p">(</span><span class="n">titanic</span><span class="err">$</span><span class="n">Title</span><span class="p">)</span>
</pre></div>

</div>
</div>

<div class="vbox output_wrapper">
<div class="output vbox">


<div class="hbox output_area"><div class="prompt"></div>
<div class="box-flex1 output_subarea output_display_data">


<pre>
[1] &quot;Mr&quot;   &quot;Mrs&quot;  &quot;Miss&quot; &quot;Mrs&quot;  &quot;Mr&quot;   &quot;Mr&quot;  

</pre>

</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell vbox">
<div class="input hbox">
<div class="prompt input_prompt">
In&nbsp;[17]:
</div>
<div class="input_area box-flex1">
<div class="highlight"><pre><span class="o">%%</span><span class="k">R</span>
<span class="c">#Let&#39;s take a look at the different values of Title and see if further grouping is necessary.</span>
<span class="c">#To be safe, we&#39;ll perform any analysis only on the training set. Let&#39;s temporarily split Train.</span>
<span class="n">temp</span> <span class="o">&lt;-</span> <span class="n">titanic</span><span class="p">[</span><span class="mi">1</span><span class="p">:</span><span class="n">nrow</span><span class="p">(</span><span class="n">train</span><span class="p">),]</span>
<span class="n">table</span><span class="p">(</span><span class="n">temp</span><span class="err">$</span><span class="n">Title</span><span class="p">)</span>

<span class="c">#OK there&#39;s obviously only a few titles that are most prominent namely Mr, Miss, Mrs and Master. Perhaps we can group the</span>
<span class="c">#other titles further?</span>
</pre></div>

</div>
</div>

<div class="vbox output_wrapper">
<div class="output vbox">


<div class="hbox output_area"><div class="prompt"></div>
<div class="box-flex1 output_subarea output_display_data">


<pre>

        Capt          Col          Don           Dr     Jonkheer         Lady 
           1            2            1            7            1            1 
       Major       Master         Miss         Mlle          Mme           Mr 
           2           40          182            2            1          517 
         Mrs           Ms          Rev          Sir the Countess 
         125            1            6            1            1 

</pre>

</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell vbox">
<div class="input hbox">
<div class="prompt input_prompt">
In&nbsp;[18]:
</div>
<div class="input_area box-flex1">
<div class="highlight"><pre><span class="o">%%</span><span class="k">R</span>
<span class="c">#Looking at wikipedia definitions, the following grouping makes reasonable sense because of similar definitions.</span>
<span class="c">#Note it&#39;s definitely possible to nitpick these groupings, feel free to make your own judgement call.</span>
<span class="n">titanic</span><span class="err">$</span><span class="n">Title</span><span class="p">[</span><span class="n">titanic</span><span class="err">$</span><span class="n">Title</span> <span class="o">%</span><span class="k">in</span><span class="o">%</span> <span class="n">c</span><span class="p">(</span><span class="s">&#39;Dona&#39;</span><span class="p">,</span><span class="s">&#39;Ms&#39;</span><span class="p">,</span><span class="s">&#39;Lady&#39;</span><span class="p">,</span><span class="s">&#39;the Countess&#39;</span><span class="p">,</span><span class="s">&#39;Jonkheer&#39;</span><span class="p">)]</span> <span class="o">&lt;-</span> <span class="s">&#39;Mrs&#39;</span>
<span class="n">titanic</span><span class="err">$</span><span class="n">Title</span><span class="p">[</span><span class="n">titanic</span><span class="err">$</span><span class="n">Title</span> <span class="o">%</span><span class="k">in</span><span class="o">%</span> <span class="n">c</span><span class="p">(</span><span class="s">&#39;Col&#39;</span><span class="p">,</span><span class="s">&#39;Dr&#39;</span><span class="p">,</span><span class="s">&#39;Rev&#39;</span><span class="p">)]</span> <span class="o">&lt;-</span> <span class="s">&#39;Noble&#39;</span>
<span class="n">titanic</span><span class="err">$</span><span class="n">Title</span><span class="p">[</span><span class="n">titanic</span><span class="err">$</span><span class="n">Title</span> <span class="o">%</span><span class="k">in</span><span class="o">%</span> <span class="n">c</span><span class="p">(</span><span class="s">&#39;Mme&#39;</span><span class="p">,</span><span class="s">&#39;Mile&#39;</span><span class="p">,</span><span class="s">&#39;Mlle&#39;</span><span class="p">)]</span> <span class="o">&lt;-</span> <span class="s">&#39;Miss&#39;</span>
<span class="n">titanic</span><span class="err">$</span><span class="n">Title</span><span class="p">[</span><span class="n">titanic</span><span class="err">$</span><span class="n">Title</span> <span class="o">%</span><span class="k">in</span><span class="o">%</span> <span class="n">c</span><span class="p">(</span><span class="s">&#39;Capt&#39;</span><span class="p">,</span><span class="s">&#39;Don&#39;</span><span class="p">,</span><span class="s">&#39;Major&#39;</span><span class="p">,</span><span class="s">&#39;Sir&#39;</span><span class="p">)]</span> <span class="o">&lt;-</span> <span class="s">&#39;Mr&#39;</span>

<span class="n">titanic</span><span class="err">$</span><span class="n">Title</span><span class="o">&lt;-</span><span class="k">as</span><span class="o">.</span><span class="n">factor</span><span class="p">(</span><span class="n">titanic</span><span class="err">$</span><span class="n">Title</span><span class="p">)</span>

<span class="n">table</span><span class="p">(</span><span class="n">titanic</span><span class="err">$</span><span class="n">Title</span><span class="p">)</span>
</pre></div>

</div>
</div>

<div class="vbox output_wrapper">
<div class="output vbox">


<div class="hbox output_area"><div class="prompt"></div>
<div class="box-flex1 output_subarea output_display_data">


<pre>

Master   Miss     Mr    Mrs  Noble 
    61    263    762    203     20 

</pre>

</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell vbox">
<div class="input hbox">
<div class="prompt input_prompt">
In&nbsp;[19]:
</div>
<div class="input_area box-flex1">
<div class="highlight"><pre><span class="o">%%</span><span class="k">R</span>
<span class="c">#OK so we split the Titles out, but what about Surnames? Surnames could indicate families traveling together, maybe </span>
<span class="c">#many of them tried to stick together trying to escape? Let&#39;s capture the surnames.</span>
<span class="n">titanic</span><span class="err">$</span><span class="n">Surname</span><span class="o">&lt;-</span><span class="n">sapply</span><span class="p">(</span><span class="n">titanic</span><span class="err">$</span><span class="n">Name</span><span class="p">,</span> <span class="n">FUN</span><span class="o">=</span><span class="n">function</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="p">{</span><span class="n">strsplit</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">split</span><span class="o">=</span><span class="s">&#39;[,.]&#39;</span><span class="p">)[[</span><span class="mi">1</span><span class="p">]][</span><span class="mi">1</span><span class="p">]})</span>
<span class="n">titanic</span><span class="err">$</span><span class="n">Surname</span><span class="o">&lt;-</span><span class="n">sub</span><span class="p">(</span><span class="s">&#39; &#39;</span><span class="p">,</span><span class="s">&#39;&#39;</span><span class="p">,</span><span class="n">titanic</span><span class="err">$</span><span class="n">Surname</span><span class="p">)</span>
<span class="n">head</span><span class="p">(</span><span class="n">titanic</span><span class="err">$</span><span class="n">Surname</span><span class="p">)</span>
</pre></div>

</div>
</div>

<div class="vbox output_wrapper">
<div class="output vbox">


<div class="hbox output_area"><div class="prompt"></div>
<div class="box-flex1 output_subarea output_display_data">


<pre>
[1] &quot;Braund&quot;    &quot;Cumings&quot;   &quot;Heikkinen&quot; &quot;Futrelle&quot;  &quot;Allen&quot;     &quot;Moran&quot;    

</pre>

</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell vbox">
<div class="input hbox">
<div class="prompt input_prompt">
In&nbsp;[20]:
</div>
<div class="input_area box-flex1">
<div class="highlight"><pre><span class="o">%%</span><span class="k">R</span>
<span class="c">#Very quickly let&#39;s get a quick rundown of the families</span>
<span class="n">temp</span> <span class="o">&lt;-</span> <span class="n">titanic</span><span class="p">[</span><span class="mi">1</span><span class="p">:</span><span class="n">nrow</span><span class="p">(</span><span class="n">train</span><span class="p">),]</span>
<span class="n">fams</span><span class="o">&lt;-</span><span class="n">data</span><span class="o">.</span><span class="n">frame</span><span class="p">(</span><span class="n">table</span><span class="p">(</span><span class="n">temp</span><span class="err">$</span><span class="n">Surname</span><span class="p">))</span>
<span class="k">print</span><span class="p">(</span><span class="n">summary</span><span class="p">(</span><span class="n">fams</span><span class="err">$</span><span class="n">Freq</span><span class="p">))</span>
<span class="c">#There we we have it. Looks like a lot of the passengers don&#39;t share a Surname with each other since the Median is 1</span>
<span class="c">#but there are families as well with upto 9 members (in the training set). So we were on the right track.</span>
<span class="n">hist</span><span class="p">(</span><span class="n">fams</span><span class="err">$</span><span class="n">Freq</span><span class="p">,</span> <span class="n">ylim</span><span class="o">=</span><span class="n">c</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">50</span><span class="p">),</span> <span class="n">col</span><span class="o">=</span><span class="s">&#39;darkcyan&#39;</span><span class="p">)</span>

<span class="c">#The histogram tells us there are a lot of ones and about 50 odd families with sizes 2 and 3, the remaining few have</span>
<span class="c">#large families. Perhaps there&#39;s a bigger question, how do we which of them are families? There could be multiple passengers</span>
<span class="c">#with the same surname traveling different groups, which would negate our purpose.</span>
</pre></div>

</div>
</div>

<div class="vbox output_wrapper">
<div class="output vbox">


<div class="hbox output_area"><div class="prompt"></div>
<div class="box-flex1 output_subarea output_display_data">


<pre>
   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
  1.000   1.000   1.000   1.336   1.000   9.000 

</pre>

</div>
</div>

<div class="hbox output_area"><div class="prompt"></div>
<div class="box-flex1 output_subarea output_display_data">


<img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAeAAAAHgCAIAAADytinCAAAgAElEQVR4nO3de1iUZf748Xtg5CCM
48hggpwmBC1FPKBhshzEVtdDaZKnzb3MkgzLXHPbamuV2mxrqbTdNvsia2VpkV2LmGJqAlppHrNE
MFEREEVGQETOw/z+mI2fEZKlPM898n790QXPHO4Pk727fWaY0VitVgEAkI+D2gMAANpGoAFAUgQa
ACRFoAFAUgQaACRFoAFAUgQaACRFoAFAUgQaACRFoAFAUgQaACRFoAFAUgQaACRFoAFAUgQaACRF
oAFAUgQaACRFoAFAUgQaACRFoAFAUgQaACRFoAFAUgQaUF9iYuJLL72k9hSQDoHu1JqamjQajUaj
yc/Pbzk4YcIEjUbz97//va6uTqPRaLVaFSfsaAcPHgwODnZ0dHzjjTeu/aIbaOvWraGhoUuXLl2y
ZMnQoUM///xz2/Hu3btrfmL58uUdNwkkdDP/t4frpNFo+vfv7+jo2P7VwsLCDhw4sHv37vDwcGUG
u4GWL19+/PjxiIiIQYMGXftFN8rJkyfvvvvu7t2733nnnVar9ejRo5MmTTp27Ji3t7ftCgEBAW5u
bi3X9/Dw6KBJICcCjatydnY+cuSI2lN0rPLyciHEH//4x8jIyGu/6EbJysqqr69/5plnysvLtVpt
TEzMsmXLduzYcf/999uusGbNmoiIiA5aHfLjFAeuqtUpjp07d/7mN7/R6XSenp4TJ060tdu2fRZC
jBgx4sMPPxRCXL58efHixcHBwe7u7kOGDHn33XetVqvtHioqKmbMmNGjR4877rgjIyNDo9GEhYUJ
Ic6dO6fRaIxG4+7du8PCwtavXy+E2L59+4gRI3Q6ncFgiI2NPXjwoBAiPz9fo9EEBga+/vrrPj4+
/v7+K1as2LNnz5AhQ9zd3aOjo0+ePPnTH+RqI4WFhW3atEkIMWXKlGefffbKm/z0ouucp81Hz2Aw
CCG2bt168eJFIcQLL7zQ2Ng4c+bMdv6ltPlYFRQUTJo0yWg0Go3G6dOnFxcX265cUlJy9913GwyG
8PDwdevWaTSafv36/dI/BlCTFZ1YY2Oj7Y9Bv379Qn+g0+mEEC+99FJtba0QwtHR0Wq1njt3zs3N
TaPR3HPPPbYdpbe39+XLlzdt2hQQECCEWLJkyalTp5qbm2NjY4UQPj4+48aNc3FxEUIsX77carU2
NzfbNoNeXl6DBg2yrTJ06FCr1Xr27FkhhJubm6+vrxDi448/LiwsdHV1dXR0jI6OvuOOO4QQ/v7+
zc3Nx48ftw3s5OTUt2/flq8DAwNtpwImT57c6mdsZ6RNmzaFhoYKIR5//PFDhw5deatWF13nPFd7
9Orq6gYOHGi71fDhw9PS0iwWi20AvV4vhNi1a1erH+enj9WlS5e8vLy0Wu3EiRPHjBkjhDCZTNXV
1Q0NDbaR/Pz8QkNDXV1dhRB9+/btkD9J6BgEulNrCfRPtQr01q1bhRCBgYGnT5+2Wq0LFy6cMmXK
8ePHrVbr0KFDhRC7d++2Wq3Z2dlCiN69e1dUVFitVttTXt27d7dYLLaL/Pz8Kisrm5ubH3300VaB
ti1qNpvr6uqysrLGjBnz/PPPW63WiooK2y6+rKysJYi5ublWq9UWuxkzZjQ3N+/YscM2YaufsZ2R
rFbr+PHjhRD//e9/f/rgXHnRdc7TzqNXVVX1zDPPtJx0joqKqqmpsf4Q6Cv179+/zcdqxYoVQog5
c+aUlZWVlZXFxMQIIT766KOPPvpICDFgwICamprm5ubZs2cTaLvDKQ4IIYQtFja2MLUyZMgQf3//
EydO+Pv7h4SEODg4vPzyy3369Gl1tW+//VYIYXviSwgxatSo3r17V1ZWFhcXHzp0SAhxzz336PV6
jUYTHx/f6rYuLi5PPvmkh4eHs7NzVFTUK6+8Ul1dPWrUKF9f36amJiGE7Z9CiN69e9v+qm7bRY4a
NUqj0di+brnOtYx07Y/Pdc7TzqOn0+lefPHFuXPnzpo1KzQ0NDs7e9WqVS3rBgQE9P/BlY/2lY/V
d999J4T4z3/+4+np6enpmZmZKYTIy8s7fPiwEGLq1Kmurq4ajablvDbsCIHGNfHw8Dh27Nh77703
ZcqU06dPv/baa/3798/JyWl1NesPp5tbODg4CCEsFktDQ4MQouU1IT999Z6bm5vtykKIL7/8csiQ
IcnJyYMGDXrnnXeMRuOV12x12/ZfCNjOSO3cqpXrnOdqj97SpUvDwsJse+3g4OBHHnlECFFUVNRy
wzVr1hz5QVpaWsvxKx8r2wP7+OOPb7vC9OnTm5ubf/pTw77w7wzXJC0tbf78+c7OzuvXry8rKxsz
Zkx9fX1WVlbLFWxbRdsZ1Y0bN9qe9crKyioqKtLr9f7+/rY95saNG6urq4UQ//nPf9pZ7r///a/F
YomPj3/ttdeGDx9+4cKFXz15OyNd+51c5zxXe/R69ep14MCB559//uzZsyUlJR988IEQwvbE6bW7
7bbbhBDV1dWjR48ePXr0iRMntmzZUl1dHRISIoRYv359bW2t1Wq13TnsCy+zwzXR6XQpKSkffPDB
u+++26VLl8zMTAcHhzvvvFMI4e7uLoRYunTpK6+8EhkZGRMTk5mZGRISMnDgQNveMDEx0cHBYezY
sUFBQcePH7/99ts9PT1tZzyuxsvLSwjx5ptv5uTk7N+/37YLbrUlvEbtjHTtd3Kd81zt0QsJCdm8
efPGjRttJ8qFEPfee++UKVN+0Q/40EMPvfLKKykpKRcvXqytrd20adOtt966ZMmS/v37P/30099+
++1tt91mMBjy8vJ+0d1CBuygcU1iY2PXrVsXEhLyxRdfbNu2rX///h9//PHgwYOFEIsXL/by8tqz
Z8+ZM2c0Gs2GDRsWLlzo5OSUmZnZr1+/d955Z8GCBUKILl26bN26dcyYMZWVlY2NjWvXrm1nuXnz
5v3+97/XaDS5ublPP/207f8Etqfafql2Rrp21znP1R49rVa7YcOGzz//fMyYMRMnTszJyVm/fv3P
/mZQK0aj8csvvxwzZsz27dv37t07a9asnTt36nQ6Z2fnnTt3jhs3rrKyskuXLlee2oa90Pz0DB3Q
EUpKSvbu3avT6WwvesvKyoqJiRkzZsyWLVvUHk19S5cu1Wq1rV6LfWN98803gwcP7tu3L1tpO8Ip
DiiktrZ22rRpDQ0NTz/9dJ8+ff7+978LIaZOnar2XFJYunSp2iNARgQaCgkMDNy6deuSJUtWrlzZ
0NAQFBSUnJz8wAMPqD0XIC9OcQCApHiSEAAkRaABQFIEGgAkRaABQFIEGgAkRaABQFIEGgAkRaAB
QFIEGgAkRaABQFIEGgAkRaABQFIEGgAkRaABQFIEGgAkRaABQFIEGgAkRaABQFIEGgAkRaABQFI3
86d6x8TEZI0fr/YUQqxbV7Rhg4+Pj9pzALAz7KABQFIEGgAkRaABQFIEGgAkRaABQFKKBtpqtVZV
VTU3Nyu5KADYKSUCXVNTs2zZsuDgYBcXF71e7+TkFBQUlJiYWF9fr8DqAGCnlAh0QkJCZmZmcnJy
SUlJQ0NDaWnp6tWrDxw4kJCQoMDqAGCnlPhFlbS0tKNHj3p7e9u+9fDwiIiICA0NNZlMKSkpCgwA
APZIiR20yWTKyMhodXDLli1+fn4KrA4AdkqJHXRycnJcXFxSUlJISIhOp6uurs7JyamoqEhPT1dg
dQCwU0oEOiwsLD8/Pzs7u6CgwGw2GwyG+Pj4qKgorba91S9cuLBq1apWBxsaGsaNGzd06NCOnBcA
pKDQmyVptdrY2Fjb12VlZV26dGm/zkIIFxeXn4Y4Ozt7x44dBBpAZ6BEoMeOHfvuu+/ecsstZ86c
mTp16p49exwdHSMjI9esWePl5XW1W7m5uY0ePbrVwfLycrPZ3MHzAoAUlHiS8LPPPqutrRVCPPHE
E7feemtVVVV1dXVoaOijjz6qwOoAYKcUfT/offv2bd682c3NTQjx9NNP9+nTR8nVAcC+KPSr3iUl
JU1NTf379y8oKLAdycnJueWWW5RZHQDskRI76MjIyOnTp58/f97V1bWwsHDMmDE7d+6cNGnSyy+/
rMDqAGCnlAh0dna2EKKhoaGwsLCsrEwI4erqunHjxoiICAVWBwA7pdw5aCcnpz59+tjOOw8bNkyx
dQHATvF+0AAgKQINAJIi0AAgKQINAJIi0AAgKQINAJIi0AAgKQINAJIi0AAgKQINAJIi0AAgKQIN
AJIi0AAgKQINAJIi0AAgKQINAJIi0AAgKQINAJIi0AAgKQINAJIi0AAgKQINAJIi0AAgKQINAJIi
0AAgKQINAJIi0AAgKQINAJIi0AAgKQINAJIi0AAgKQINAJIi0AAgKQINAJIi0AAgKQINAJIi0AAg
KQINAJIi0AAgKQINAJIi0AAgKQINAJIi0AAgKQINAJIi0AAgKQINAJIi0AAgKQINAJIi0AAgKUUD
bbVaq6qqmpublVwUAOyUEoGuqalZtmxZcHCwi4uLXq93cnIKCgpKTEysr69XYHUAsFNKBDohISEz
MzM5ObmkpKShoaG0tHT16tUHDhxISEhQYHUAsFNaBdZIS0s7evSot7e37VsPD4+IiIjQ0FCTyZSS
kqLAAABgj5TYQZtMpoyMjFYHt2zZ4ufnp8DqAGCnlNhBJycnx8XFJSUlhYSE6HS66urqnJycioqK
9PR0BVYHADulRKDDwsLy8/Ozs7MLCgrMZrPBYIiPj4+KitJq21u9sbGxqKio1cHS0tKOnBQAJKJE
oIUQWq02Nja25ds9e/ZYLJb2A202m19++eVWB0+ePBkWFtYhIwKAZBQKdCsTJkz45ptvfHx82rmO
l5fX22+/3epgamqq2WzuyNEAQBZKBNrd3b2uru7KIxaLxd/fX6PRNDU1KTAAANgjJV7FsW/fvuHD
h997773ff//9uXPnzp07ZzAYDh06dO7cOQVWBwA7pUSgb7vttl27dt15553jxo3bu3ev0Wh0cHDo
0aOH0WhUYHUAsFMKnYN2dHRcuHDhxIkTH3rooXXr1jU0NCizLgDYL0WfJAwMDPz8889XrVrV2Njo
6uqq5NIAYHeUfhWHg4NDfHx8fHy8wusCgN3h/aABQFIEGgAkRaABQFIEGgAkRaABQFIEGgAkRaAB
QFIEGgAkRaABQFIEGgAkRaABQFIEGgAkRaABQFIEGgAkRaABQFIEGgAkRaABQFIEGgAkRaABQFIE
GgAkRaABQFIEGgAkRaABQFIEGgAkRaABQFIEGgAkRaABQFIEGgAkRaABQFIEGgAkRaABQFIEGgAk
RaABQFIEGgAkRaABQFIEGgAkRaABQFIEGgAkRaABQFIEGgAkRaABQFIEGgAkRaABQFIEGgAkRaAB
QFIEGgAkRaABQFIEGgAkRaABQFIEGgAkpWigrVZrVVVVc3OzkosCgJ1SItA1NTXLli0LDg52cXHR
6/VOTk5BQUGJiYn19fUKrA4AdkqJQCckJGRmZiYnJ5eUlDQ0NJSWlq5evfrAgQMJCQkKrA4Adkqr
wBppaWlHjx719va2fevh4REREREaGmoymVJSUhQYAADskRI7aJPJlJGR0ergli1b/Pz8FFgdAOyU
Ejvo5OTkuLi4pKSkkJAQnU5XXV2dk5NTUVGRnp6uwOoAYKeUCHRYWFh+fn52dnZBQYHZbDYYDPHx
8VFRUVpte6sXFhY++OCDrQ6WlpaOHTu2I4cFAFkoEWghhFarjY2NtX1dX1+v1WodHR3bv4mfn9+2
bdtaHUxNTTWbzR0yIgBIRolz0EePHh03btzs2bMLCgpiYmK6devm7u4+ffp0UgsA7VAi0HPnzvXy
8urdu/ewYcOGDRtWUlLy/fffOzs7P/bYYwqsDgB2qo1THAsWLIiLixs5cuTPnoW4RgcPHkxLS+vS
pcuyZcuWLl3atWtXDw+PpKSk4ODgG3L/AHBTamMHbTAYHnvssd69eyckJOzYsaOpqek61+jWrZvZ
bNbr9R9++GHXrl1tB0+cONG7d+/rvGcAuIm1EejExMTDhw9/9dVXffr0Wbp0qY+PT3x8/NatWxsb
G3/dGvHx8WPHjt2/f/+0adOEEIWFhQsXLrznnnsWL158XbMDwE3tquege/To4evrGxgY2NDQ8NVX
Xy1dutRkMm3YsOFXrPH888+npKQYjUbbt3V1dd7e3ps2bZo9e/avGxoAOoM2zkH/4x//2LRp0/79
+0eOHDlhwoS//vWvJpNJCJGVlTVjxox77rnnl66h0WhGjx7d8m1wcPCTTz55PUMDQGfQRqBzc3MX
LFhw11136XS6K48PGzbs3//+t1KDAUBn18YpjrfeequiouLQoUNCiPfff3/58uUNDQ1CCDc3t8mT
Jys9IAB0Vm0E+vHHH3/rrbf0er0QIjAwcO3atY888ojigwFAZ9dGoD/++OPU1NTQ0FAhxIgRIz78
8MNPPvlE8cEAoLNr4xy0wWAoKyu79dZbbd+Wlpa2vAADv8bZs7533CEc1P74x/r6rzZsGDFihMpj
ALhmbQT6xRdfHD9+/MyZM/39/YuLi9esWfP6668rP9nNo75eJCQIvV7lMb76qri4WOUZAPwSbWzr
pk2b9uWXX/bs2fP48eN6vX7Hjh2zZs1SfjIA6OTafrvRvn37PvvsswqPAgC4UhuB/vzzz5977rny
8vIrD+bl5Sk1EgBAiDYDPWfOnBkzZtx///3tf+IJAKBDtZHgxsbGJUuWuLq6Kj8NAKBFG08SLlq0
6I033rBYLMpPAwBo0cYOOi0t7Ztvvlm2bFmvXr00Go3tIOegAUBhbQR61apVys8BAGiljUD369dP
CGGxWM6fP3/lJhoAoKQ2zkGfOXPG9tnbt99++4EDB37zm9+cOnVK+ckAoJNrI9APPPDAgAEDLly4
oNfrBw0aFB4ePnfuXOUnA4BOro1THF988UVqaqqLi4sQQqvV/vnPf/b391d8MADo7NrYQQcFBX3x
xRct33799dct72wHAFBMGzvoN954Y8qUKdHR0eXl5VOmTNm1a9f777+v/GQA0Mm1EeioqKhjx45t
3Lhx0KBBXl5eb775Zq9evZSfDAA6ubbfbcPDw2P27NnKTgIA+JE2Ah0eHv7Tg3v27On4YQAA/18b
gV6+fLntC6vVWlxc/Oabbz766KPKTgUAuIYddExMzKhRo+Li4pQaCQAgRJsvs2ulqKiooKCg4ycB
APzIz+ygm5qaDh8+PH/+fAVHAgAI0f45aJvu3bv37dtXqXkAAP9zra/iAAAorI1A+/j4VFdXX+0G
lZWVHTkPAOB/2niS8C9/+cvQoUM3b96cm5ubkZExdOjQ559/vuAHik8IAJ1UGzvoF198ce/evd7e
3kIILy+v9957Lzw8fMGCBYrPBgCdWhs7aAcHh/z8/JZvT5w40dzcrOBIAAAh2txBP/vss5MmTXr4
4YcDAwNPnDjx9ttvP/PMM8pPBgCdXBs76Pj4+M8++6yxsXH79u3V1dXr169/4oknlJ8MADq5tt/N
btiwYUOGDOFDYwFARXxoLABIig+NBQBJ8aGxACApPjQWACTFh8YCgKT40FgAkFQbgR44cOC6dev4
0FgAUFcb56CnTp2alJRUX1+v/DQAgBZt7KC3b9/+zTffrF271tfXV6v93xXy8vKUHQwAOrs2Av2v
f/1L+TkAAK38KNDu7u7FxcUDBgwQQqxdu/buu+92d3dXaTAA6Ox+dA768uXLLV8nJCSYzWbF5wEA
/E8bTxICAGSgaKCtVmtVVRVv/w8A16L1k4SHDh3S6XRCiKampm+//bblLEdYWNivXqOmpmb58uXv
vPPO6dOnGxoaHB0dTSbT/fff/9RTTzk7O//quwWAm9uPAu3h4XHffffZvnZxcZkzZ07LRddzPjoh
IeHMmTPJyckDBgzo1q1bVVVVbm7uK6+8kpCQkJKS8qvvFgBubj8KdAc9K5iWlnb06FHbp9AKITw8
PCIiIkJDQ00mE4EGgKtR4hy0yWTKyMhodXDLli1+fn4KrA4Adqrtj7y6sZKTk+Pi4pKSkkJCQnQ6
XXV1dU5OTkVFRXp6ugKrA4CdUiLQYWFh+fn52dnZBQUFZrPZYDDEx8dHRUW1/B55myorK1NTU1sd
3L9/v6+vb0cOCwCyUCLQQgitVjtkyJBRo0a1fAStxWIxm81Go/FqN3FwcDAYDK0Ouru7t591ALhp
KBG7nJycqVOn5ubmmkymFStWTJgwQQhRVFRkMpmsVuvVbtWtW7eWl5S0sFqt/H4jgE5CiScJH374
4SlTptTV1a1evXrevHn79+9XYFEAsHdKBPrQoUOLFy92cnKKjIx88803582bZ7FYFFgXAOyaEoEO
CgraunWr7eu7777b19f3r3/9qwLrAoBdUyLQ//jHPx544IERI0acP39eo9EkJydnZGRMnjxZgaUB
wH4p8SThXXfd9f333+/cudPV1VUIYTQad+/enZaWdvDgQQVWBwA7pdBL1ry8vKZNm9byrbOz87Rp
0648AgBohfeDBgBJEWgAkBSBBgBJEWgAkBSBBgBJEWgAkBSBBgBJEWgAkBSBBgBJEWgAkBSBBgBJ
EWgAkBSBBgBJEWgAkBSBBgBJEWgAkBSBBgBJEWgAkBSBBgBJEWgAkBSBBgBJEWgAkBSBBgBJEWgA
kBSBBgBJEWgAkBSBBgBJEWgAkBSBBgBJEWgAkJRW7QGglLKyJUuW/N///Z+6U1gsltmzZ//hD39Q
dwzALhDoTuPSpdywsNyBA1Ue48yZwYcPqzwDYCc4xQEAkiLQACApAg0AkiLQACApAg0AkiLQACAp
Ag0AkiLQACApAg0AkiLQACApAg0AkiLQACApAg0AkiLQACApAg0AkiLQACApAg0AklI00Fartaqq
qrm5WclFAcBOKRHompqaZcuWBQcHu7i46PV6JyenoKCgxMTE+vp6BVYHADulRKATEhIyMzOTk5NL
SkoaGhpKS0tXr1594MCBhIQEBVYHADulxIfGpqWlHT161Nvb2/ath4dHREREaGioyWRKSUlRYAAA
sEdK7KBNJlNGRkarg1u2bPHz81NgdQCwU0rsoJOTk+Pi4pKSkkJCQnQ6XXV1dU5OTkVFRXp6ugKr
A4CdUiLQYWFh+fn52dnZBQUFZrPZYDDEx8dHRUVpte2tbrFYqqqqWh28fPmy1WrtyGEBQBZKBFoI
odVqY2Njf9FNzp0798c//rHVwaKiosjIyBs3FwDIS6FA/wq9e/dOTU1tdTA1NdVsNqsyDwAoTIlA
5+XlXe2ifv36KTAAANgjJQK9aNGijIyMrl27GgyGVhcVFxcrMAAA2CMlAr158+a5c+c6Ozv/61//
UmA5ALg5KPReHNOnTw8ICFBmLQC4OSj0JGFsbOwvfRUHAHRyvN0oAEiKQAOApAg0AEiKQAOApAg0
AEiKQAOApAg0AEiKQAOApAg0AEiKQAOApAg0AEiKQAOApAg0AEiKQAOApAg0AEiKQAOApAg0AEiK
QAOApAg0AEiKQAOApAg0AEiKQAOApAg0AEiKQAOApAg0AEhKq/YAgDqGDx/e3Nys9hSiubn54MGD
ak8BSRFodFL7ysvFvHlqTyHEypVqTwB5cYoDACRFoAFAUgQaACRFoAFAUgQaACRFoAFAUgQaACRF
oAFAUgQaACRFoAFAUgQaACRFoAFAUgQaACRFoAFAUgQaACRFoAFAUgQaACRFoAFAUgQaACRFoAFA
UgQaACRFoAFAUgQaACSlVXsAdDqXLl06efKk2lNIo7lZhkdDq9X6+fmpPYUQQpw6dcpqtao9hbjl
llvc3NzUnoJAQ2EXLiRv35783XdqzyGN0tLA3/9e7SGEKCw8tGnToEGD1J3is88+G/vww8LLS90x
RGPjrNtvf++991Qeg0BDaRaLCAoSEyeqPYcQK1eqPYEQQgirVUyZovYQQmzeXFdXp/YQoq6uTgwc
KCIjVZ6juro+N1flGYQQnIMGAGkpGmir1VpVVdXc3KzkogBgp5QIdE1NzbJly4KDg11cXPR6vZOT
U1BQUGJiYn19vQKrA4CdUiLQCQkJmZmZycnJJSUlDQ0NpaWlq1evPnDgQEJCggKrA4Cd0ijwipbu
3bsfPXrU29v7yoOXLl0ymUxms/lqtyosLHzwwQdbHbx48eL999+/YMGCa1k3PDz86/LyXzHwDVZY
KLy9hVbt52NLS4Wbm3B3V3mM6mpRVyeMRpXHEEKUl4sePdQeQoiCAhEQoPYQQpSVhffr5672H4/y
8vKDRUWie3d1xxAWy4MxMatWrVJ5DGVexWEymTIyMlrVdsuWLe2/7tLPz2/btm3Xs+6ePXuu5+YA
oC4ldtD79++Pi4tzdXUNCQnR6XTV1dU5OTkVFRXp6elDhw7t6NUBwE4pEWghRFNTU3Z2dkFBgdls
NhgMgYGBUVFRWtX/1g8AElMo0ACAX4pfVAEASRFoAJAUgQYASRFoAJAUgQYASRFoAJAUgQYASRFo
AJAUv8vX4V577bU1a9Y4OjqqPYgUGhsb6+rqdDqd2oPIory8vIcM79kkh/r6+vnz58+bN0/tQWRB
oDvcoUOHNm7c6OPjo/YgUjh48OAHH3zw6quvqj2ILGJiYjIzM9WeQhYbNmyQ4SN05cEpDgCQFIEG
AEkRaACQFIEGAEkRaACQFK/i6HD9+/d3cXFRewpZ6HS6oKAgtaeQCB8qdCVPT8+mpia1p5AIb9gP
AJLiFAcASIpAA4CkCDQASIpAA4CkCDQASIpAA4CkCDQASIpAA4CkCHQH2r59+6BBg9zc3CIiInJy
ctQeRxZ5eXnu7u5qT6G+s2fPjhs3rlu3buHh4ceOHVN7HPW9/fbbAQEBXbt2jY6OzsvLU3scKRDo
jnL27NnJkyf/5S9/KSkpiYmJmTp1qtoTScFiscyZM6eurk7tQVRmtVonTJgQGxv7/fff33nnnXyG
SH5+/mOPPZaSknLy5MkBAwYkJCSoPZEUCExVjr4AAAeZSURBVHRH2blz54ABA+677z69Xv/cc8/l
5uZWVFSoPZT6/vnPf/LhMkKI/fv319TULFq0qFevXi+99NKKFSvUnkhlbm5uLi4u7u7ubm5urq6u
fAyYDe/F0VEuXbpUW1vbs2dPIcTOnTtnz5594sQJjUaj9lxqOnHixPjx4zdv3hwcHNzJ3xPnnXfe
SUtL69mzZ1ZW1sCBA19//XVfX1+1h1LZW2+9lZCQoNFoevTocezYMQ8PD7UnUh876I6i0+l69uxp
tVo3bNgwc+bMFStWdPI6Nzc3z50799VXX+3WrZvas6ivrKwsPT198ODBn3766S233DJt2jS1J1JZ
Xl7eCy+88NVXX12+fHnOnDkPPPCA2hNJgbcb7UAXLlyYO3duYWFhWlpaWFiY2uOobNWqVd7e3uPH
jzebzWrPor6uXbtGRkY+8sgjQoikpCSdTmc2m41Go9pzqWbjxo3jxo0bMWKEEOKFF17Q6/UXL17U
6/Vqz6UydtAdpb6+/re//e1tt9329ddfU2chxI4dO9LT041GY3BwsMViMRqNe/bsUXso1fj7+7d8
7eDgoNFotNpOvVuyWCwWi8X2tdVqtVgsnH0VnIPuOB999NFLL72UlpbWcsTX19fR0VHFkdR14cKF
2tpaIUR5efngwYNPnz7t6enp7Oys9lzqqK+v9/f3f/XVV8eOHfviiy8ePHgwKytL7aHUlJOTM3Lk
yPXr1w8ePDgxMfHIkSM7duxQeygJWNExnnzyyVYPdVlZmdpDSaGsrMzR0VHtKdT39ddfDxkyxN3d
/Xe/+11RUZHa46jvk08+6du3r06nmzhxYnFxsdrjSIEdNABIinPQACApAg0AkiLQACApAg0AkiLQ
ACApAg0AkiLQACApAg0AkiLQACApAg0AkiLQACApAg0AkiLQACApAg0AkiLQACApAg0AkiLQACAp
Ag0AkiLQ6HQsFsv27dvvuuuuM2fOqD0L0B4CDTvwpz/9yWAwnD9//vrvqr6+PiYm5s9//vPx48fD
wsJSU1Ntx41Go+YK7u7u178WcJ0INOzAqlWrcnNze/bsef13lZaW5uTk9Nlnn0VHR69fv37JkiUt
F+3YsaPiB8XFxde/FnCdCDRkN3ny5IsXLw4fPrysrCw5OdlkMrm6uoaHhx87dkwIkZeXN3LkyMWL
FxuNxoiIiN27dw8bNkyn0y1cuFAI0dTU9MgjjxgMBqPR+MILLwghLl++3LI7HjFixIYNG1oW0ul0
3a9w5MiR6Ojov/3tbwMHDhRC7Nq1a/DgwW5ubmPHjm05N5KcnBwQEODr67ty5UofHx+FHxnc/KyA
9PR6/aVLlwoLC52cnLKzs8vKymbPnh0fH2+1WnNzcx0cHD744IMLFy4MHTq0Z8+eBQUFu3fvFkKc
P38+NTW1b9++p06dOnjwoLOzc35+fklJiZeX18SJE8eOHXv58uWWJTw8PPbt23flot99951er589
e/aRI0fMZrOHh0d6enp5efn8+fOjo6OtVuu+ffsMBkNWVlZxcXFMTIxer1f4YcFNjx007Ianp+fx
48cjIyNdXV2NRuPFixdtx728vGbOnNmjR4/Ro0dPnjzZ398/PDzc39/fdoXGxsbz588PGjSouLjY
19fXy8vr8OHDoaGhO3fu9Pb2TklJabn/6Ojolu3z2rVrhRC1tbUrV67s37//p59+Gh0dPXHiRIPB
kJSUtHfvXovF8uGHH8bHx0dFRfXu3ftvf/ubKo8Jbm5atQcArpVWq121alVGRoZer3d2dtbpdLbj
LacstFptr169Wr4WQtx7771VVVXx8fGlpaXz589/4oknhBCenp6PP/54UVHRnDlzYmNj4+Li9Hq9
EGLt2rW2sxlCCKPRWFBQ4Ovr6+zsLIQoKiraunVrQECA7VInJ6fz588XFxePHj3adsRkMinyGKBz
IdCwGx9//PGmTZu2bdvWo0eP999//9NPP/3Zm5w8eXLUqFEPPvhgYWHhfffd171798LCQh8fn5kz
ZwohIiMjg4ODz549awu0t7d3S4JtbJUXQnh5ed11112ffPKJEMJisRw6dKhXr16enp4nTpywXeH0
6dM39GcFhOBJQtiRCxcuuLu7u7q6nj9//p///Gdtbe3P3iQ9PX3GjBmlpaUWi6W+vt7V1XXAgAHr
1q2rrq62Wq3bt2+vrKwMCgr62fsZP378rl27Nm/ebDabn3rqqYULF2o0mkmTJr399tu7du0qKSl5
9tlnb8SPCPwIO2jYjVmzZqWnp/v4+PTr1++555576KGH1qxZM2zYsHZu8vDDD3/xxReBgYHOzs5T
p079wx/+IITYs2fPyJEjL1y4kJOTk5qa6ujo+LNL9+rV6/3331+0aNGpU6fuuOOO9957TwgxatSo
p556atq0aY6Ojn/605/2799/o35SwEZjtVrVngFQmtlsXrRoka2zN0RlZWVAQEBlZeWNukNAcIoD
nZOzs/PIkSPVngL4GeyggRuAHTQ6AoEGAElxigMAJEWgAUBSBBoAJEWgAUBSBBoAJEWgAUBSBBoA
JEWgAUBSBBoAJEWgAUBSBBoAJEWgAUBSBBoAJEWgAUBSBBoAJPX/AGFkYRZhvAbjAAAAAElFTkSu
QmCC
">

</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell vbox">
<div class="input hbox">
<div class="prompt input_prompt">
In&nbsp;[21]:
</div>
<div class="input_area box-flex1">
<div class="highlight"><pre><span class="o">%%</span><span class="k">R</span>
<span class="c">#To simplify this, let&#39;s use the variables we haven&#39;t explored so far, SibSp (No. of Siblings and Spouses) and Parch (No.</span>
<span class="c">#Parents and Children). Summing these up (+1 for self) should gives us the family size of each passenger. Making an</span>
<span class="c">#assumption that these attributes were entered correctly, we could then surmise that passengers with the same surname and </span>
<span class="c">#family size belong to same families. Of course, there&#39;re still loopholes if we want to nitpick but I am stopping here.</span>
<span class="n">titanic</span><span class="err">$</span><span class="n">FamSize</span><span class="o">&lt;-</span><span class="n">titanic</span><span class="err">$</span><span class="n">SibSp</span> <span class="o">+</span> <span class="n">titanic</span><span class="err">$</span><span class="n">Parch</span> <span class="o">+</span> <span class="mi">1</span>

<span class="c">#Club FamilySize with Surname to create a new Family ID </span>
<span class="n">titanic</span><span class="err">$</span><span class="n">FamID</span><span class="o">&lt;-</span><span class="n">paste</span><span class="p">(</span><span class="n">titanic</span><span class="err">$</span><span class="n">Surname</span><span class="p">,</span><span class="k">as</span><span class="o">.</span><span class="n">character</span><span class="p">(</span><span class="n">titanic</span><span class="err">$</span><span class="n">FamSize</span><span class="p">),</span><span class="n">sep</span><span class="o">=</span><span class="s">&#39;&#39;</span><span class="p">)</span>

<span class="c">#We&#39;ll call all passengers with Family Size = 1 as traveling Solo.</span>
<span class="n">titanic</span><span class="err">$</span><span class="n">FamID</span><span class="p">[</span><span class="n">which</span><span class="p">(</span><span class="n">titanic</span><span class="err">$</span><span class="n">FamSize</span><span class="o">==</span><span class="mi">1</span><span class="p">)]</span><span class="o">&lt;-</span><span class="s">&#39;Solo&#39;</span>
<span class="n">titanic</span><span class="err">$</span><span class="n">FamID</span><span class="o">&lt;-</span><span class="k">as</span><span class="o">.</span><span class="n">factor</span><span class="p">(</span><span class="n">titanic</span><span class="err">$</span><span class="n">FamID</span><span class="p">)</span>

<span class="c">#Finally let&#39;s remove some columns we won&#39;t use for model building.</span>
<span class="c">#Name and Ticket are unique for each passenger (we assume) and couldn&#39;t possible add any relevance to our prediction. Even</span>
<span class="c">#if multiple passengers had the same name, it shouldn&#39;t really help us decide if one or more survived.</span>
<span class="n">titanic</span><span class="err">$</span><span class="n">Name</span><span class="o">&lt;-</span><span class="n">NULL</span>
<span class="n">titanic</span><span class="err">$</span><span class="n">Ticket</span><span class="o">&lt;-</span><span class="n">NULL</span>

<span class="n">head</span><span class="p">(</span><span class="n">titanic</span><span class="p">)</span>
</pre></div>

</div>
</div>

<div class="vbox output_wrapper">
<div class="output vbox">


<div class="hbox output_area"><div class="prompt"></div>
<div class="box-flex1 output_subarea output_display_data">


<pre>
  PassengerId Survived Pclass    Sex Age SibSp Parch    Fare Embarked Child
1           1        0      3   male  22     1     0  7.2500        S     0
2           2        1      1 female  38     1     0 71.2833        C     0
3           3        1      3 female  26     0     0  7.9250        S     0
4           4        1      1 female  35     1     0 53.1000        S     0
5           5        0      3   male  35     0     0  8.0500        S     0
6           6        0      3   male  22     0     0  8.4583        Q     0
  FareGroup Title   Surname FamSize     FamID
1       &lt;10    Mr    Braund       2   Braund2
2       40+   Mrs   Cumings       2  Cumings2
3       &lt;10  Miss Heikkinen       1      Solo
4       40+   Mrs  Futrelle       2 Futrelle2
5       &lt;10    Mr     Allen       1      Solo
6       &lt;10    Mr     Moran       1      Solo

</pre>

</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell vbox">
<div class="input hbox">
<div class="prompt input_prompt">
In&nbsp;[22]:
</div>
<div class="input_area box-flex1">
<div class="highlight"><pre><span class="o">%%</span><span class="k">R</span>
<span class="c">#Great we&#39;re through. We&#39;ll now get back our Train and Test sets from Titanic.</span>
<span class="n">train</span><span class="o">&lt;-</span><span class="n">titanic</span><span class="p">[</span><span class="mi">1</span><span class="p">:</span><span class="n">nrow</span><span class="p">(</span><span class="n">train</span><span class="p">),]</span>
<span class="n">temp</span><span class="o">=</span><span class="n">nrow</span><span class="p">(</span><span class="n">train</span><span class="p">)</span><span class="o">+</span><span class="mi">1</span>
<span class="n">kaggletest</span><span class="o">&lt;-</span><span class="n">titanic</span><span class="p">[</span><span class="n">temp</span><span class="p">:</span><span class="n">nrow</span><span class="p">(</span><span class="n">titanic</span><span class="p">),]</span>

<span class="k">print</span><span class="p">(</span><span class="n">nrow</span><span class="p">(</span><span class="n">train</span><span class="p">))</span>
<span class="k">print</span><span class="p">(</span><span class="n">nrow</span><span class="p">(</span><span class="n">kaggletest</span><span class="p">))</span>
<span class="k">print</span><span class="p">(</span><span class="n">nrow</span><span class="p">(</span><span class="n">titanic</span><span class="p">))</span>
</pre></div>

</div>
</div>

<div class="vbox output_wrapper">
<div class="output vbox">


<div class="hbox output_area"><div class="prompt"></div>
<div class="box-flex1 output_subarea output_display_data">


<pre>
[1] 891
[1] 418
[1] 1309

</pre>

</div>
</div>

</div>
</div>

</div>
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="model-fitting-and-evaluation">Model Fitting and Evaluation</h3>
<p>I want to use this opportunity and challenge to try out different models in R and see how they stack up against each other. We'll run through one at a time, fit the parameters and submit to Kaggle. We'll then wrap things up by comparing the different approaches. I think this is a great chance to learn tuning models in R.</p>
<p>First up, before we start training and running cross-validation, I would like to try simple, plain-old logistic regression. We'll not be training but simply fitting a model and checking how the different parameters we've created contribute to the predictions.</p>
<p>Before we get started we need to split the &quot;train.csv&quot; file we're holding in the train dataframe to train/test sets. The reason we do this is so we have a baseline to run our model against before the submission to Kaggle. It enables a good approximation on how well the model can generalize.</p>
<p>We'll be using the <em>caret</em> package for the rest of this approach. The caret package has several functions that attempt to streamline the model building and evaluation process. One of them is the createDataPartition function which can be used to create a stratified random sample of the data into training and test sets.</p>
</div>
<div class="cell border-box-sizing code_cell vbox">
<div class="input hbox">
<div class="prompt input_prompt">
In&nbsp;[23]:
</div>
<div class="input_area box-flex1">
<div class="highlight"><pre><span class="o">%%</span><span class="k">R</span>
<span class="c">#75/25 Train/Test Split</span>
<span class="c">#install.packages(&#39;caret&#39;)</span>
<span class="c">#Setting a random seed. We will be using this throughout to make sure our results are consistently comparable.</span>
<span class="n">library</span><span class="p">(</span><span class="n">caret</span><span class="p">)</span>
<span class="nb">set</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">35</span><span class="p">)</span> 
<span class="n">trainrows</span><span class="o">&lt;-</span><span class="n">createDataPartition</span><span class="p">(</span><span class="n">train</span><span class="err">$</span><span class="n">Survived</span><span class="p">,</span> <span class="n">p</span> <span class="o">=</span> <span class="mf">0.8</span><span class="p">,</span> <span class="nb">list</span><span class="o">=</span><span class="n">FALSE</span><span class="p">)</span>
<span class="n">train</span><span class="o">.</span><span class="n">set</span><span class="o">&lt;-</span><span class="n">train</span><span class="p">[</span><span class="n">trainrows</span><span class="p">,]</span>
<span class="n">test</span><span class="o">.</span><span class="n">set</span><span class="o">&lt;-</span><span class="n">train</span><span class="p">[</span><span class="o">-</span><span class="n">trainrows</span><span class="p">,]</span>

<span class="k">print</span><span class="p">(</span><span class="n">nrow</span><span class="p">(</span><span class="n">train</span><span class="o">.</span><span class="n">set</span><span class="p">))</span>
<span class="k">print</span><span class="p">(</span><span class="n">nrow</span><span class="p">(</span><span class="n">test</span><span class="o">.</span><span class="n">set</span><span class="p">))</span>
      
<span class="c">#Remember, from this point on Test does NOT refer to the test.csv file. I will call out explicitly when it does and it won&#39;t</span>
<span class="c">#until the very end when we submit predictions to Kaggle for each model.</span>
</pre></div>

</div>
</div>

<div class="vbox output_wrapper">
<div class="output vbox">


<div class="hbox output_area"><div class="prompt"></div>
<div class="box-flex1 output_subarea output_display_data">


<pre>
Loading required package: lattice
Loading required package: ggplot2
[1] 714
[1] 177

</pre>

</div>
</div>

</div>
</div>

</div>
<div class="text_cell_render border-box-sizing rendered_html">
<h4 id="logistic-regression">Logistic Regression</h4>
<p>Before we start training models with caret, I would like to first explore simple logistic regression through the glm() method. glm (Generalized Linear Models) is easy-to-use and lets us several types of linear models, logistic regression being one of them. Let's begin</p>
</div>
<div class="cell border-box-sizing code_cell vbox">
<div class="input hbox">
<div class="prompt input_prompt">
In&nbsp;[24]:
</div>
<div class="input_area box-flex1">
<div class="highlight"><pre><span class="o">%%</span><span class="k">R</span>
<span class="c">#To start with I am not including any of the features we manufactured. Let&#39;s see how the raw features perform.</span>

<span class="n">Titan</span><span class="o">.</span><span class="n">logit</span><span class="o">.</span><span class="mi">1</span> <span class="o">&lt;-</span> <span class="n">glm</span><span class="p">(</span><span class="n">Survived</span> <span class="o">~</span> <span class="n">Sex</span> <span class="o">+</span> <span class="n">Pclass</span> <span class="o">+</span> <span class="n">Age</span> <span class="o">+</span> <span class="n">SibSp</span> <span class="o">+</span> <span class="n">Parch</span> <span class="o">+</span> <span class="n">Embarked</span> <span class="o">+</span> <span class="n">Fare</span><span class="p">,</span> 
                       <span class="n">data</span> <span class="o">=</span> <span class="n">train</span><span class="o">.</span><span class="n">set</span><span class="p">,</span> <span class="n">family</span><span class="o">=</span><span class="n">binomial</span><span class="p">(</span><span class="s">&quot;logit&quot;</span><span class="p">))</span>
<span class="k">print</span><span class="p">(</span><span class="n">Titan</span><span class="o">.</span><span class="n">logit</span><span class="o">.</span><span class="mi">1</span><span class="p">)</span>
</pre></div>

</div>
</div>

<div class="vbox output_wrapper">
<div class="output vbox">


<div class="hbox output_area"><div class="prompt"></div>
<div class="box-flex1 output_subarea output_display_data">


<pre>

Call:  glm(formula = Survived ~ Sex + Pclass + Age + SibSp + Parch + 
    Embarked + Fare, family = binomial(&quot;logit&quot;), data = train.set)

Coefficients:
(Intercept)      Sexmale      Pclass2      Pclass3          Age        SibSp  
   4.034633    -2.640662    -1.101916    -2.263913    -0.038039    -0.263821  
      Parch    EmbarkedQ    EmbarkedS         Fare  
  -0.112988    -0.001405    -0.455287     0.002163  

Degrees of Freedom: 713 Total (i.e. Null);  704 Residual
Null Deviance:	    950.9 
Residual Deviance: 633.3 	AIC: 653.3

</pre>

</div>
</div>

</div>
</div>

</div>
<div class="text_cell_render border-box-sizing rendered_html">
<p>Couple of observations on the results above. The factors we're interested in are Deviance and Degrees of Freedom. The null observations are based on how well we can predict survival given a &quot;null&quot; model, which works only based on a constant, mean of means or a &quot;grand mean&quot;. The null deviance is expected to be high. While the residual deviance tells us how much the inclusion of features has brought down the null deviance. So for instance, in our first run, the null deviance was <strong>950.9</strong> and the residual deviance was <strong>633.3</strong>. So including the raw features (after the data munging process) brought down the deviance by <strong>~327</strong> points with a 713-704=<strong>9</strong> change in degrees of freedom. If you're interested like I am, google to learn more about these topics. The coefficients are the parameters (theta) for each of the features and the Intercept is the theta0 term.</p>
<p>Let's run the extractor function, anova(), which gives us the result of analysis. I am using the chi-square or &quot;goodness of fit&quot; statistic. Lower the value the better.</p>
</div>
<div class="cell border-box-sizing code_cell vbox">
<div class="input hbox">
<div class="prompt input_prompt">
In&nbsp;[25]:
</div>
<div class="input_area box-flex1">
<div class="highlight"><pre><span class="o">%%</span><span class="k">R</span>
<span class="n">anova</span><span class="p">(</span><span class="n">Titan</span><span class="o">.</span><span class="n">logit</span><span class="o">.</span><span class="mi">1</span><span class="p">,</span> <span class="n">test</span><span class="o">=</span><span class="s">&quot;Chisq&quot;</span><span class="p">)</span>
</pre></div>

</div>
</div>

<div class="vbox output_wrapper">
<div class="output vbox">


<div class="hbox output_area"><div class="prompt"></div>
<div class="box-flex1 output_subarea output_display_data">


<pre>
Analysis of Deviance Table

Model: binomial, link: logit

Response: Survived

Terms added sequentially (first to last)


         Df Deviance Resid. Df Resid. Dev  Pr(&gt;Chi)    
NULL                       713     950.86              
Sex       1  206.206       712     744.66 &lt; 2.2e-16 ***
Pclass    2   77.642       710     667.02 &lt; 2.2e-16 ***
Age       1   18.755       709     648.26 1.486e-05 ***
SibSp     1    8.977       708     639.29  0.002734 ** 
Parch     1    0.640       707     638.65  0.423776    
Embarked  2    4.625       705     634.02  0.098991 .  
Fare      1    0.723       704     633.30  0.395187    
---
Signif. codes:  0 *** 0.001 ** 0.01 * 0.05 . 0.1   1

</pre>

</div>
</div>

</div>
</div>

</div>
<div class="text_cell_render border-box-sizing rendered_html">
<p>Looking at the individual deviances, we see that Sex and Pclass accounted for the biggest reductions while Age and SibSp seem to be contributing somewhat. Embarked and Fare are on the lower end while the contribution of Parch is negligible. Let's now make some changes, include our new features and remove Fare and Parch.</p>
</div>
<div class="cell border-box-sizing code_cell vbox">
<div class="input hbox">
<div class="prompt input_prompt">
In&nbsp;[26]:
</div>
<div class="input_area box-flex1">
<div class="highlight"><pre><span class="o">%%</span><span class="k">R</span>
<span class="n">Titan</span><span class="o">.</span><span class="n">logit</span><span class="o">.</span><span class="mi">2</span> <span class="o">&lt;-</span> <span class="n">glm</span><span class="p">(</span><span class="n">Survived</span> <span class="o">~</span> <span class="n">Sex</span> <span class="o">+</span> <span class="n">Pclass</span> <span class="o">+</span> <span class="n">Age</span> <span class="o">+</span> <span class="n">SibSp</span> <span class="o">+</span> <span class="n">Embarked</span> <span class="o">+</span> <span class="n">FareGroup</span> <span class="o">+</span> <span class="n">FamID</span> <span class="o">+</span> <span class="n">Title</span> <span class="o">+</span> <span class="n">FamSize</span><span class="p">,</span> 
                       <span class="n">data</span> <span class="o">=</span> <span class="n">train</span><span class="o">.</span><span class="n">set</span><span class="p">,</span> <span class="n">family</span><span class="o">=</span><span class="n">binomial</span><span class="p">(</span><span class="s">&quot;logit&quot;</span><span class="p">))</span>
<span class="k">print</span><span class="p">(</span><span class="n">Titan</span><span class="o">.</span><span class="n">logit</span><span class="o">.</span><span class="mi">2</span><span class="p">)</span>
</pre></div>

</div>
</div>

<div class="vbox output_wrapper">
<div class="output vbox">


<div class="hbox output_area"><div class="prompt"></div>
<div class="box-flex1 output_subarea output_display_data">


<pre>

Call:  glm(formula = Survived ~ Sex + Pclass + Age + SibSp + Embarked + 
    FareGroup + FamID + Title + FamSize, family = binomial(&quot;logit&quot;), 
    data = train.set)

Coefficients:
              (Intercept)                    Sexmale  
                3.022e+01                 -2.932e+01  
                  Pclass2                    Pclass3  
               -1.165e+00                 -1.093e+00  
                      Age                      SibSp  
               -2.415e-02                  2.153e-01  
                EmbarkedQ                  EmbarkedS  
                2.933e-01                 -2.709e-01  
           FareGroup10-20             FareGroup20-40  
                5.610e-01                  1.247e+00  
             FareGroup40+              FamIDAbelson2  
                1.058e+00                 -1.144e-01  
                FamIDAks2              FamIDAllison4  
                4.504e+15                 -2.955e+01  
    FamIDAndersen-Jensen2            FamIDAndersson7  
                2.559e+01                 -2.594e+00  
            FamIDAndrews2             FamIDAppleton3  
                2.591e+01                  2.754e+01  
     FamIDArnold-Franchi2              FamIDAsplund7  
               -2.780e+01                 -9.996e-01  
          FamIDBackstrom2            FamIDBackstrom4  
               -2.342e+01                  2.432e+01  
            FamIDBaclini4              FamIDBarbara2  
                2.514e+01                 -2.695e+01  
             FamIDBaxter2                FamIDBeane2  
               -6.829e-01                  3.796e+01  
             FamIDBecker4             FamIDBeckwith3  
                4.504e+15                  2.686e+01  
             FamIDBishop2               FamIDBoulos3  
                1.901e+01                 -2.693e+01  
             FamIDBourke3             FamIDBowerman2  
               -2.735e+01                  2.270e+01  
              FamIDBrown3                FamIDBryhl2  
                6.636e-01                 -4.504e+15  
           FamIDCaldwell3                FamIDCaram2  
                2.510e+01                 -3.145e+01  
            FamIDCardeza2               FamIDCarter2  
                2.719e+01                 -2.599e+01  
             FamIDCarter4            FamIDCavendish2  
                1.396e+01                 -2.490e+01  
           FamIDChambers2              FamIDChristy3  
                2.565e+01                  2.697e+01  
       FamIDChronopoulos2               FamIDClarke2  
               -2.292e+01                  2.775e+01  
            FamIDCollyer3              FamIDCompton3  
                1.118e+00                  2.399e+01  
             FamIDCoutts3                FamIDCribb2  
                2.256e+01                 -7.634e+01  
             FamIDCrosby3              FamIDCumings2  
                8.250e-01                  2.315e+01  
             FamIDDanbom3             FamIDDavidson2  
               -2.789e+01                 -4.445e+01  
             FamIDDavies3              FamIDDavison2  
                7.337e-01                  2.443e+01  
               FamIDDean4             FamIDdelCarlo2  
                7.449e-01                 -2.444e+01  
      FamIDdeMessemaeker2                 FamIDDick2  
                2.064e+01                  2.697e+01  
              FamIDDodge3               FamIDDoling2  
                2.502e+01                  4.261e+01  
            FamIDDouglas2           FamIDDuffGordon2  
               -2.482e+01                  2.711e+01  
        FamIDDurany More2                FamIDElias3  
                2.638e+01                 -2.680e+01  
             FamIDEustis2           FamIDFaunthorpe2  
                4.504e+15                  2.679e+01  
               FamIDFord5              FamIDFortune6  
               -1.731e+01                 -6.254e-01  
         FamIDFrauenthal2           FamIDFrauenthal3  
                2.072e+01                  2.958e+01  
          FamIDFrolicher3     FamIDFrolicher-Stehli3  
                2.450e+01                  2.806e+01  
           FamIDFutrelle2                 FamIDGale2  
               -6.513e-01                 -2.397e+01  
              FamIDGiles2           FamIDGoldenberg2  
               -2.348e+01                  2.839e+01  
          FamIDGoldsmith3              FamIDGoodwin8  
                2.487e+01                 -3.330e+01  
             FamIDGraham2           FamIDGreenfield2  
                2.441e+01                  2.620e+01  
         FamIDGustafsson3              FamIDHagland2  
               -4.187e+01                 -1.861e+01  
         FamIDHamalainen3               FamIDHansen2  
                2.591e+01                 -2.340e+01  
             FamIDHansen3               FamIDHarder2  
               -5.239e+01                  2.766e+01  
             FamIDHarper2               FamIDHarris2  
                2.961e+00                 -5.547e-01  
               FamIDHart3                 FamIDHays3  
                1.289e+00                  2.229e+01  
             FamIDHerman4              FamIDHickman3  
                2.614e+01                 -3.538e+01  
            FamIDHippach2             FamIDHirvonen2  
                5.357e+01                  2.910e+01  
            FamIDHocking4                 FamIDHold2  
               -2.375e+01                 -2.059e+01  
          FamIDHolverson2                 FamIDHoyt2  
               -2.258e+01                  1.834e+01  
         FamIDIlmakangas2            FamIDJacobsohn2  
               -2.598e+01                 -1.966e+01  
          FamIDJacobsohn4               FamIDJensen2  
                2.239e+01                 -2.301e+01  
            FamIDJohnson3             FamIDJohnston4  
                2.611e+01                 -2.985e+01  
            FamIDJussila2               FamIDKantor2  
               -2.704e+01                  1.565e-01  
             FamIDKenyon2              FamIDKiernan2  
                2.598e+01                 -1.207e+03  
            FamIDKimball2                 FamIDKink3  
                2.856e+01                 -2.513e+01  
      FamIDKink-Heilmann3               FamIDKlasen3  
                2.618e+01                 -2.429e+01  
           FamIDLahtinen3              FamIDLaroche4  
               -2.831e+01                  8.050e-01  
            FamIDLefebre5               FamIDLennon2  
               -2.767e+01                 -4.504e+15  
            FamIDLindell2            FamIDLindqvist2  
               -2.437e+01                  2.823e+01  
              FamIDLines2                 FamIDLobb2  
                2.471e+01                 -2.340e+01  
              FamIDLouch2               FamIDMadill2  
                2.383e+01                  2.414e+01  
             FamIDMallet3               FamIDMarvin2  
                7.140e-01                 -2.524e+01  
              FamIDMcCoy3              FamIDMcNamee2  
                3.043e+01                 -2.358e+01  
              FamIDMeyer2              FamIDMinahan2  
               -1.188e+00                  2.485e+01  
            FamIDMinahan3                 FamIDMoor2  
               -2.357e+01                  2.595e+01  
              FamIDMoran2             FamIDMoubarek3  
                3.095e-01                  1.393e+01  
             FamIDMurphy2                FamIDNakid3  
                2.723e+01                  2.852e+01  
             FamIDNasser2               FamIDNatsch2  
               -2.532e-01                 -2.146e+01  
           FamIDNavratil3               FamIDNewell2  
                2.643e+01                  2.878e+01  
             FamIDNewell3               FamIDNewsom3  
               -2.082e+01                  2.493e+01  
           FamIDNicholls3        FamIDNicola-Yarred2  
               -1.773e+01                  2.645e+01  
            FamIDO&apos;Brien2                FamIDOlsen2  
                2.950e+01                 -2.216e+01  
            FamIDPalsson5               FamIDPanula6  
               -4.936e+01                 -2.862e+01  
            FamIDParrish2                FamIDPears2  
                3.472e+01                 -9.049e-01  
FamIDPenascoy Castellana2              FamIDPersson2  
               -1.369e+00                  3.023e+01  
              FamIDPeter3            FamIDPetterson2  
                2.598e+01                 -2.278e+01  
             FamIDPotter2                FamIDQuick3  
                2.398e+01                  2.556e+01  
             FamIDRenouf4                 FamIDRice6  
                2.379e+01                 -2.202e+01  
           FamIDRichards3             FamIDRichards6  
                2.988e+01                  2.444e+01  
             FamIDRobert2               FamIDRobins2  
                2.393e+01                 -2.787e+01  
            FamIDRosblom3              FamIDRyerson5  
               -1.694e+01                  2.468e+01  
              FamIDSage11               FamIDSamaan3  
               -2.948e+01                 -2.481e+01  
          FamIDSandstrom3              FamIDShelley2  
                2.597e+01                  2.361e+01  
             FamIDSilven3               FamIDSilvey2  
                2.797e+01                 -4.461e-01  
              FamIDSkoog6                  FamIDSolo  
               -2.788e+01                  1.459e+00  
            FamIDSpencer2           FamIDStephenson2  
                2.281e+01                  2.347e+01  
              FamIDStrom2                FamIDStrom3  
               -2.698e+01                 -2.850e+01  
            FamIDTaussig3               FamIDTaylor2  
                2.470e+01                  2.732e+01  
             FamIDThayer3               FamIDThomas2  
                2.664e+01                  2.664e+01  
       FamIDThorneycroft2               FamIDTurpin2  
                6.012e-01                 -2.782e+01  
        FamIDvanBilliard3         FamIDVanderPlanke2  
               -2.289e+01                 -4.026e+02  
       FamIDVanderPlanke3              FamIDVanImpe3  
               -2.312e+05                 -2.825e+01  
             FamIDWarren2                FamIDWeisz2  
                2.370e+01                  2.415e+01  
              FamIDWells3                 FamIDWest4  
                2.545e+01                  1.068e+00  
              FamIDWhite2                 FamIDWick3  
               -2.411e+01                  2.541e+01  
            FamIDWidener3             FamIDWilliams2  
               -2.544e+01                 -2.437e+01  
             FamIDZabour2                  TitleMiss  
               -2.698e+01                 -2.917e+01  
                  TitleMr                   TitleMrs  
               -2.822e+00                 -2.725e+01  
               TitleNoble                    FamSize  
               -3.994e+00                         NA  

Degrees of Freedom: 713 Total (i.e. Null);  517 Residual
Null Deviance:	    950.9 
Residual Deviance: 373.3 	AIC: 767.3

</pre>

</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell vbox">
<div class="input hbox">
<div class="prompt input_prompt">
In&nbsp;[27]:
</div>
<div class="input_area box-flex1">
<div class="highlight"><pre><span class="o">%%</span><span class="k">R</span>
<span class="n">anova</span><span class="p">(</span><span class="n">Titan</span><span class="o">.</span><span class="n">logit</span><span class="o">.</span><span class="mi">2</span><span class="p">,</span> <span class="n">test</span><span class="o">=</span><span class="s">&quot;Chisq&quot;</span><span class="p">)</span>
</pre></div>

</div>
</div>

<div class="vbox output_wrapper">
<div class="output vbox">


<div class="hbox output_area"><div class="prompt"></div>
<div class="box-flex1 output_subarea output_display_data">


<pre>
Analysis of Deviance Table

Model: binomial, link: logit

Response: Survived

Terms added sequentially (first to last)


           Df Deviance Resid. Df Resid. Dev  Pr(&gt;Chi)    
NULL                         713     950.86              
Sex         1  206.206       712     744.66 &lt; 2.2e-16 ***
Pclass      2   77.642       710     667.02 &lt; 2.2e-16 ***
Age         1   18.755       709     648.26 1.486e-05 ***
SibSp       1    8.977       708     639.29 0.0027343 ** 
Embarked    2    4.742       706     634.54 0.0933863 .  
FareGroup   3    1.034       703     633.51 0.7930468    
FamID     182  248.620       521     384.89 0.0007554 ***
Title       4   11.591       517     373.30 0.0206677 *  
FamSize     0    0.000       517     373.30              
---
Signif. codes:  0 *** 0.001 ** 0.01 * 0.05 . 0.1   1

</pre>

</div>
</div>

</div>
</div>

</div>
<div class="text_cell_render border-box-sizing rendered_html">
<p>Looks like FamID and to an extent FareGroup contribute well to the model. Although looking at the extraordinarily high deviance and df for FamID, I am suspicious that this might cause overfitting - meaning we've modeled in extreme based on the training set hence won't generalize very well on new examples. This can be addressed by resampling and hypertuning parameters based on crossvalidation. We essentially split the training set further into train and cv, then hypertune parameters against the cv set. This is repeated multiple times, each with a different sample of train/cv.</p>
<p>OK let's proceed to use the train method of the caret package to train a logistic regression model. We'll use one of the most common crossvalidation methods namely the 3x 10-fold CV. That is 10 folds of data to split train and cv repeated 3 times.</p>
</div>
<div class="cell border-box-sizing code_cell vbox">
<div class="input hbox">
<div class="prompt input_prompt">
In&nbsp;[28]:
</div>
<div class="input_area box-flex1">
<div class="highlight"><pre><span class="o">%%</span><span class="k">R</span>
<span class="c">#Define the 3x 10 fold cv control using the traincontrol method of caret.</span>
<span class="n">tenfoldcv</span><span class="o">&lt;-</span><span class="n">trainControl</span><span class="p">(</span><span class="n">method</span><span class="o">=</span><span class="s">&#39;repeatedcv&#39;</span><span class="p">,</span> <span class="n">number</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">repeats</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
</pre></div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell vbox">
<div class="input hbox">
<div class="prompt input_prompt">
In&nbsp;[283]:
</div>
<div class="input_area box-flex1">
<div class="highlight"><pre><span class="o">%%</span><span class="k">R</span>
<span class="c">#Train a logistic regression classifier using the train method of the caret package. Everything is same as before except</span>
<span class="c">#we use the train function and pass glm as the method.</span>

<span class="c">#Install the doSNOW package to leverage multiple cores - parallelization</span>
<span class="c">#install.packages(doSNOW)</span>
<span class="n">library</span><span class="p">(</span><span class="n">doSNOW</span><span class="p">)</span>

<span class="c">#Set 4 below to the number of cores you&#39;d like to run in parallel. I have 4 and using 3 of them!</span>
<span class="n">cl</span> <span class="o">&lt;-</span> <span class="n">makeCluster</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="s">&quot;SOCK&quot;</span><span class="p">)</span>
<span class="n">registerDoSNOW</span><span class="p">(</span><span class="n">cl</span><span class="p">)</span>

<span class="c">#Note that I&#39;ve also added options below to normalize the features (Feature Scaling)</span>
<span class="nb">set</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">35</span><span class="p">)</span> 
<span class="n">logit</span><span class="o">.</span><span class="n">tune1</span><span class="o">&lt;-</span><span class="n">train</span><span class="p">(</span><span class="n">Survived</span> <span class="o">~</span> <span class="n">Sex</span> <span class="o">+</span> <span class="n">Pclass</span> <span class="o">+</span> <span class="n">Age</span> <span class="o">+</span> <span class="n">SibSp</span> <span class="o">+</span> <span class="n">Embarked</span> <span class="o">+</span> <span class="n">FareGroup</span> <span class="o">+</span> <span class="n">FamID</span> <span class="o">+</span> <span class="n">Title</span><span class="p">,</span>
                <span class="n">data</span><span class="o">=</span><span class="n">train</span><span class="o">.</span><span class="n">set</span><span class="p">,</span>
                <span class="n">method</span><span class="o">=</span><span class="s">&#39;glm&#39;</span><span class="p">,</span>
                <span class="n">preProcess</span> <span class="o">=</span> <span class="n">c</span><span class="p">(</span><span class="s">&quot;center&quot;</span><span class="p">,</span> <span class="s">&quot;scale&quot;</span><span class="p">),</span>
                <span class="n">trControl</span><span class="o">=</span><span class="n">tenfoldcv</span><span class="p">)</span>

<span class="n">logit</span><span class="o">.</span><span class="n">tune1</span>

<span class="c">#May need to install a dependency for caret train</span>
<span class="c">#install.packages(&#39;e1071&#39;, dependencies=TRUE)</span>
</pre></div>

</div>
</div>

<div class="vbox output_wrapper">
<div class="output vbox">


<div class="hbox output_area"><div class="prompt"></div>
<div class="box-flex1 output_subarea output_display_data">


<pre>
Generalized Linear Model 

714 samples
 14 predictors
  2 classes: &apos;0&apos;, &apos;1&apos; 

Pre-processing: centered, scaled 
Resampling: Cross-Validated (10 fold, repeated 3 times) 

Summary of sample sizes: 643, 643, 643, 642, 643, 643, ... 

Resampling results

  Accuracy   Kappa      Accuracy SD  Kappa SD 
  0.7829812  0.5332698  0.05484398   0.1230111

 

</pre>

</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell vbox">
<div class="input hbox">
<div class="prompt input_prompt">
In&nbsp;[284]:
</div>
<div class="input_area box-flex1">
<div class="highlight"><pre><span class="o">%%</span><span class="k">R</span>
<span class="n">summary</span><span class="p">(</span><span class="n">logit</span><span class="o">.</span><span class="n">tune1</span><span class="p">)</span>
</pre></div>

</div>
</div>

<div class="vbox output_wrapper">
<div class="output vbox">


<div class="hbox output_area"><div class="prompt"></div>
<div class="box-flex1 output_subarea output_display_data">


<pre>

Call:
NULL

Deviance Residuals: 
     Min        1Q    Median        3Q       Max  
-2.28940  -0.43374  -0.00008   0.00010   2.42885  

Coefficients: (45 not defined because of singularities)
                              Estimate Std. Error z value Pr(&gt;|z|)  
(Intercept)                 -6.178e-01  2.122e+02  -0.003   0.9977  
Sexmale                     -1.065e+01  3.540e+03  -0.003   0.9976  
Pclass2                     -4.784e-01  2.887e-01  -1.657   0.0975 .
Pclass3                     -5.451e-01  3.414e-01  -1.597   0.1103  
Age                         -3.162e-01  1.743e-01  -1.814   0.0697 .
SibSp                        2.275e-01  6.706e-01   0.339   0.7344  
EmbarkedQ                    8.080e-02  1.658e-01   0.487   0.6259  
EmbarkedS                   -1.214e-01  1.804e-01  -0.673   0.5010  
&#96;FareGroup10-20&#96;             2.253e-01  2.610e-01   0.863   0.3880  
&#96;FareGroup20-40&#96;             5.179e-01  2.891e-01   1.792   0.0732 .
&#96;FareGroup40+&#96;               4.250e-01  2.883e-01   1.474   0.1404  
FamIDAbelson2               -6.050e-03  1.922e-01  -0.031   0.9749  
FamIDAhlin2                         NA         NA      NA       NA  
FamIDAks2                    6.886e-01  4.025e+02   0.002   0.9986  
FamIDAllison4               -1.184e+00  3.883e+02  -0.003   0.9976  
&#96;FamIDAndersen-Jensen2&#96;      7.532e-01  4.025e+02   0.002   0.9985  
FamIDAndersson7             -1.938e-01  2.168e-01  -0.894   0.3714  
FamIDAndrews2                7.125e-01  4.025e+02   0.002   0.9986  
FamIDAngle2                         NA         NA      NA       NA  
FamIDAppleton3               6.236e-01  4.025e+02   0.002   0.9988  
&#96;FamIDArnold-Franchi2&#96;      -1.073e+00  3.092e+02  -0.003   0.9972  
FamIDAsplund7               -6.470e-02  1.963e-01  -0.330   0.7417  
FamIDAstor2                         NA         NA      NA       NA  
FamIDBackstrom2             -6.092e-01  4.025e+02  -0.002   0.9988  
FamIDBackstrom4              6.570e-01  4.025e+02   0.002   0.9987  
FamIDBaclini4                9.648e-01  3.949e+02   0.002   0.9981  
FamIDBarbara2               -1.079e+00  3.893e+02  -0.003   0.9978  
FamIDBaxter2                -3.612e-02  1.847e-01  -0.195   0.8450  
FamIDBeane2                  8.323e-01  4.025e+02   0.002   0.9983  
FamIDBecker4                 6.907e-01  4.025e+02   0.002   0.9986  
FamIDBeckwith3               1.070e+00  3.166e+02   0.003   0.9973  
FamIDBishop2                 5.908e-01  4.025e+02   0.001   0.9988  
FamIDBoulos3                -7.514e-01  4.025e+02  -0.002   0.9985  
FamIDBourke3                -1.310e+00  3.150e+02  -0.004   0.9967  
FamIDBowerman2               6.835e-01  4.025e+02   0.002   0.9986  
FamIDBraund2                        NA         NA      NA       NA  
FamIDBrown3                  3.510e-02  2.015e-01   0.174   0.8617  
FamIDBryhl2                 -6.385e-01  4.025e+02  -0.002   0.9987  
FamIDCaldwell3               9.659e-01  3.860e+02   0.003   0.9980  
FamIDCaram2                 -8.114e-01  4.025e+02  -0.002   0.9984  
FamIDCardeza2                7.973e-01  4.025e+02   0.002   0.9984  
FamIDCarter2                -1.066e+00  2.916e+02  -0.004   0.9971  
FamIDCarter4                 1.284e+00  3.196e+02   0.004   0.9968  
FamIDCavendish2             -6.651e-01  4.025e+02  -0.002   0.9987  
FamIDChaffee2                       NA         NA      NA       NA  
FamIDChambers2               1.056e+00  3.148e+02   0.003   0.9973  
FamIDChapman2                       NA         NA      NA       NA  
FamIDChibnall2                      NA         NA      NA       NA  
FamIDChristy3                7.147e-01  4.025e+02   0.002   0.9986  
FamIDChronopoulos2          -6.247e-01  4.025e+02  -0.002   0.9988  
FamIDClark2                         NA         NA      NA       NA  
FamIDClarke2                 6.457e-01  4.025e+02   0.002   0.9987  
FamIDCollyer3                7.236e-02  2.007e-01   0.361   0.7184  
FamIDCompton3                6.806e-01  4.025e+02   0.002   0.9987  
FamIDCornell3                       NA         NA      NA       NA  
FamIDCoutts3                 7.235e-01  4.025e+02   0.002   0.9986  
FamIDCribb2                 -5.903e-01  4.025e+02  -0.001   0.9988  
FamIDCrosby3                 4.363e-02  1.757e-01   0.248   0.8038  
FamIDCumings2                6.080e-01  4.025e+02   0.002   0.9988  
FamIDDanbom3                -1.061e+00  3.096e+02  -0.003   0.9973  
FamIDDavidson2              -6.696e-01  4.025e+02  -0.002   0.9987  
FamIDDavidson4                      NA         NA      NA       NA  
FamIDDavies3                 3.880e-02  1.637e-01   0.237   0.8126  
FamIDDavison2                6.632e-01  4.025e+02   0.002   0.9987  
FamIDDean4                   3.940e-02  1.691e-01   0.233   0.8157  
FamIDdelCarlo2              -6.450e-01  4.025e+02  -0.002   0.9987  
FamIDdeMessemaeker2          6.759e-01  4.025e+02   0.002   0.9987  
FamIDDick2                   1.058e+00  3.063e+02   0.003   0.9972  
FamIDDodge3                  6.729e-01  4.025e+02   0.002   0.9987  
FamIDDoling2                 7.164e-01  4.025e+02   0.002   0.9986  
FamIDDouglas2               -6.626e-01  4.025e+02  -0.002   0.9987  
FamIDDouglas3                       NA         NA      NA       NA  
FamIDDrew3                          NA         NA      NA       NA  
FamIDDuffGordon2             1.068e+00  3.094e+02   0.003   0.9972  
&#96;FamIDDurany More2&#96;          7.320e-01  4.025e+02   0.002   0.9985  
FamIDDyker2                         NA         NA      NA       NA  
FamIDEarnshaw2                      NA         NA      NA       NA  
FamIDElias3                 -6.119e-01  4.025e+02  -0.002   0.9988  
FamIDEustis2                 6.942e-01  4.025e+02   0.002   0.9986  
FamIDFaunthorpe2             6.466e-01  4.025e+02   0.002   0.9987  
FamIDFord5                  -1.315e+00  3.334e+02  -0.004   0.9969  
FamIDFortune6               -4.048e-02  2.085e-01  -0.194   0.8460  
FamIDFrauenthal2             6.037e-01  4.025e+02   0.001   0.9988  
FamIDFrauenthal3             8.479e-01  4.025e+02   0.002   0.9983  
FamIDFrolicher3              6.733e-01  4.025e+02   0.002   0.9987  
&#96;FamIDFrolicher-Stehli3&#96;     8.109e-01  4.025e+02   0.002   0.9984  
FamIDFutrelle2              -3.445e-02  1.937e-01  -0.178   0.8588  
FamIDGale2                  -6.303e-01  4.025e+02  -0.002   0.9988  
FamIDGibson2                        NA         NA      NA       NA  
FamIDGiles2                 -6.164e-01  4.025e+02  -0.002   0.9988  
FamIDGoldenberg2             1.065e+00  3.013e+02   0.004   0.9972  
FamIDGoldsmith3              6.457e-01  4.025e+02   0.002   0.9987  
FamIDGoodwin8               -1.580e+00  3.994e+02  -0.004   0.9968  
FamIDGraham2                 6.443e-01  4.025e+02   0.002   0.9987  
FamIDGreenfield2             7.856e-01  4.025e+02   0.002   0.9984  
FamIDGustafsson3            -8.422e-01  4.018e+02  -0.002   0.9983  
FamIDHagland2               -6.182e-01  4.025e+02  -0.002   0.9988  
FamIDHakkarainen2                   NA         NA      NA       NA  
FamIDHamalainen3             9.970e-01  3.930e+02   0.003   0.9980  
FamIDHansen2                -5.936e-01  4.025e+02  -0.001   0.9988  
FamIDHansen3                -6.091e-01  4.025e+02  -0.002   0.9988  
FamIDHarder2                 7.793e-01  4.025e+02   0.002   0.9985  
FamIDHarper2                 2.212e-01  2.270e-01   0.974   0.3300  
FamIDHarris2                -2.934e-02  1.980e-01  -0.148   0.8822  
FamIDHart3                   8.346e-02  2.031e-01   0.411   0.6811  
FamIDHays3                   6.308e-01  4.025e+02   0.002   0.9987  
FamIDHerman4                 7.208e-01  4.025e+02   0.002   0.9986  
FamIDHickman3               -9.069e-01  4.021e+02  -0.002   0.9982  
FamIDHiltunen3                      NA         NA      NA       NA  
FamIDHippach2                9.173e-01  3.896e+02   0.002   0.9981  
FamIDHirvonen2               7.249e-01  4.025e+02   0.002   0.9986  
FamIDHirvonen3                      NA         NA      NA       NA  
FamIDHocking4               -6.227e-01  4.025e+02  -0.002   0.9988  
FamIDHocking5                       NA         NA      NA       NA  
FamIDHogeboom2                      NA         NA      NA       NA  
FamIDHold2                  -6.213e-01  4.025e+02  -0.002   0.9988  
FamIDHolverson2             -6.597e-01  4.025e+02  -0.002   0.9987  
FamIDHoward2                        NA         NA      NA       NA  
FamIDHoyt2                   6.154e-01  4.025e+02   0.002   0.9988  
FamIDIlmakangas2            -7.058e-01  4.025e+02  -0.002   0.9986  
FamIDJacobsohn2             -6.231e-01  4.025e+02  -0.002   0.9988  
FamIDJacobsohn4              6.340e-01  4.025e+02   0.002   0.9987  
FamIDJefferys3                      NA         NA      NA       NA  
FamIDJensen2                -6.017e-01  4.025e+02  -0.001   0.9988  
FamIDJohnson3                1.017e+00  3.989e+02   0.003   0.9980  
FamIDJohnston4              -7.552e-01  4.025e+02  -0.002   0.9985  
FamIDJussila2               -1.003e+00  4.022e+02  -0.002   0.9980  
FamIDKantor2                 8.279e-03  1.951e-01   0.042   0.9661  
FamIDKarun2                         NA         NA      NA       NA  
FamIDKenyon2                 6.037e-01  4.025e+02   0.001   0.9988  
FamIDKhalil2                        NA         NA      NA       NA  
FamIDKiernan2               -6.183e-01  4.025e+02  -0.002   0.9988  
FamIDKimball2                8.048e-01  4.025e+02   0.002   0.9984  
FamIDKink3                  -6.017e-01  4.025e+02  -0.001   0.9988  
&#96;FamIDKink-Heilmann3&#96;        7.011e-01  4.025e+02   0.002   0.9986  
&#96;FamIDKink-Heilmann5&#96;               NA         NA      NA       NA  
FamIDKlasen3                -6.008e-01  4.025e+02  -0.001   0.9988  
FamIDLahtinen3              -8.206e-01  4.025e+02  -0.002   0.9984  
FamIDLaroche4                5.211e-02  2.064e-01   0.252   0.8007  
FamIDLefebre5               -1.330e+00  3.994e+02  -0.003   0.9973  
FamIDLennon2                -6.393e-01  4.025e+02  -0.002   0.9987  
FamIDLindell2               -6.056e-01  4.025e+02  -0.002   0.9988  
FamIDLindqvist2              8.655e-01  4.025e+02   0.002   0.9983  
FamIDLines2                  6.710e-01  4.025e+02   0.002   0.9987  
FamIDLobb2                  -6.110e-01  4.025e+02  -0.002   0.9988  
FamIDLouch2                  6.583e-01  4.025e+02   0.002   0.9987  
FamIDMadill2                 6.771e-01  4.025e+02   0.002   0.9987  
FamIDMallet3                 3.776e-02  1.753e-01   0.215   0.8294  
FamIDMarvin2                -6.804e-01  4.025e+02  -0.002   0.9987  
FamIDMcCoy3                  1.063e+00  3.296e+02   0.003   0.9974  
FamIDMcNamee2               -6.164e-01  4.025e+02  -0.002   0.9988  
FamIDMellinger2                     NA         NA      NA       NA  
FamIDMeyer2                 -6.282e-02  1.958e-01  -0.321   0.7484  
FamIDMinahan2                6.642e-01  4.025e+02   0.002   0.9987  
FamIDMinahan3               -6.432e-01  4.025e+02  -0.002   0.9987  
FamIDMock2                          NA         NA      NA       NA  
FamIDMoor2                   1.008e+00  3.892e+02   0.003   0.9979  
FamIDMoran2                  1.637e-02  1.617e-01   0.101   0.9193  
FamIDMoubarek3               1.032e+00  4.022e+02   0.003   0.9980  
FamIDMurphy2                 7.138e-01  4.025e+02   0.002   0.9986  
FamIDNakid3                  1.121e+00  3.216e+02   0.003   0.9972  
FamIDNasser2                -1.339e-02  2.015e-01  -0.066   0.9470  
FamIDNatsch2                -6.733e-01  4.025e+02  -0.002   0.9987  
FamIDNavratil3               7.005e-01  4.025e+02   0.002   0.9986  
FamIDNewell2                 9.467e-01  4.019e+02   0.002   0.9981  
FamIDNewell3                -6.473e-01  4.025e+02  -0.002   0.9987  
FamIDNewsom3                 6.737e-01  4.025e+02   0.002   0.9987  
FamIDNicholls3              -6.439e-01  4.025e+02  -0.002   0.9987  
&#96;FamIDNicola-Yarred2&#96;        1.016e+00  3.995e+02   0.003   0.9980  
&#96;FamIDO&apos;Brien2&#96;              6.421e-01  4.025e+02   0.002   0.9987  
FamIDOlsen2                 -5.711e-01  4.025e+02  -0.001   0.9989  
FamIDOstby2                         NA         NA      NA       NA  
FamIDPalsson5               -1.583e+00  3.966e+02  -0.004   0.9968  
FamIDPanula6                -1.702e+00  3.394e+02  -0.005   0.9960  
FamIDParrish2                6.736e-01  4.025e+02   0.002   0.9987  
FamIDPeacock3                       NA         NA      NA       NA  
FamIDPears2                 -4.786e-02  1.964e-01  -0.244   0.8074  
&#96;FamIDPenascoy Castellana2&#96; -7.240e-02  1.934e-01  -0.374   0.7082  
FamIDPersson2                8.700e-01  4.025e+02   0.002   0.9983  
FamIDPeter3                  9.555e-01  3.847e+02   0.002   0.9980  
FamIDPetterson2             -5.945e-01  4.025e+02  -0.001   0.9988  
FamIDPhillips2                      NA         NA      NA       NA  
FamIDPotter2                 6.323e-01  4.025e+02   0.002   0.9987  
FamIDQuick3                  6.939e-01  4.025e+02   0.002   0.9986  
FamIDRenouf2                        NA         NA      NA       NA  
FamIDRenouf4                 6.314e-01  4.025e+02   0.002   0.9987  
FamIDRice6                  -1.813e+00  4.006e+02  -0.005   0.9964  
FamIDRichards3               7.262e-01  4.025e+02   0.002   0.9986  
FamIDRichards6               6.597e-01  4.025e+02   0.002   0.9987  
FamIDRobert2                 6.307e-01  4.025e+02   0.002   0.9987  
FamIDRobins2                -7.787e-01  4.025e+02  -0.002   0.9985  
FamIDRosblom3               -1.074e+00  3.243e+02  -0.003   0.9974  
FamIDRothschild2                    NA         NA      NA       NA  
FamIDRyerson5                6.536e-01  4.025e+02   0.002   0.9987  
FamIDSage11                 -1.755e+00  3.590e+02  -0.005   0.9961  
FamIDSamaan3                -6.621e-01  4.025e+02  -0.002   0.9987  
FamIDSandstrom3              9.897e-01  3.910e+02   0.003   0.9980  
FamIDSchabert2                      NA         NA      NA       NA  
FamIDShelley2                6.510e-01  4.025e+02   0.002   0.9987  
FamIDSilven3                 7.421e-01  4.025e+02   0.002   0.9985  
FamIDSilvey2                -2.359e-02  1.986e-01  -0.119   0.9055  
FamIDSkoog6                 -1.722e+00  3.458e+02  -0.005   0.9960  
FamIDSmith2                         NA         NA      NA       NA  
FamIDSnyder2                        NA         NA      NA       NA  
FamIDSolo                    7.131e-01  1.282e+00   0.556   0.5781  
FamIDSpedden3                       NA         NA      NA       NA  
FamIDSpencer2                5.935e-01  4.025e+02   0.001   0.9988  
FamIDStengel2                       NA         NA      NA       NA  
FamIDStephenson2             6.207e-01  4.025e+02   0.002   0.9988  
FamIDStraus2                        NA         NA      NA       NA  
FamIDStrom2                 -7.396e-01  4.025e+02  -0.002   0.9985  
FamIDStrom3                 -7.949e-01  4.025e+02  -0.002   0.9984  
FamIDTaussig3                9.287e-01  3.840e+02   0.002   0.9981  
FamIDTaylor2                 1.078e+00  3.017e+02   0.004   0.9971  
FamIDThayer3                 1.042e+00  3.205e+02   0.003   0.9974  
FamIDThomas2                 7.401e-01  4.025e+02   0.002   0.9985  
FamIDThomas3                        NA         NA      NA       NA  
FamIDThorneycroft2           3.180e-02  1.904e-01   0.167   0.8674  
FamIDTouma3                         NA         NA      NA       NA  
FamIDTurpin2                -1.095e+00  3.113e+02  -0.004   0.9972  
FamIDvanBilliard3           -5.934e-01  4.025e+02  -0.001   0.9988  
FamIDVanderPlanke2          -7.931e-01  4.025e+02  -0.002   0.9984  
FamIDVanderPlanke3          -9.929e-01  3.306e+02  -0.003   0.9976  
FamIDVanderPlanke4                  NA         NA      NA       NA  
FamIDVanImpe3               -1.126e+00  3.838e+02  -0.003   0.9977  
FamIDWare2                          NA         NA      NA       NA  
FamIDWarren2                 6.279e-01  4.025e+02   0.002   0.9988  
FamIDWeisz2                  6.466e-01  4.025e+02   0.002   0.9987  
FamIDWells3                  6.957e-01  4.025e+02   0.002   0.9986  
FamIDWest4                   6.913e-02  2.036e-01   0.340   0.7341  
FamIDWhite2                 -6.408e-01  4.025e+02  -0.002   0.9987  
FamIDWick3                   6.916e-01  4.025e+02   0.002   0.9986  
FamIDWidener3               -6.753e-01  4.025e+02  -0.002   0.9987  
FamIDWiklund2                       NA         NA      NA       NA  
FamIDWilkes2                        NA         NA      NA       NA  
FamIDWilliams2              -6.536e-01  4.025e+02  -0.002   0.9987  
FamIDYasbeck2                       NA         NA      NA       NA  
FamIDZabour2                -7.397e-01  4.025e+02  -0.002   0.9985  
TitleMiss                   -8.997e+00  3.011e+03  -0.003   0.9976  
TitleMr                     -1.393e+00  7.860e-01  -1.772   0.0764 .
TitleMrs                    -7.105e+00  2.603e+03  -0.003   0.9978  
TitleNoble                  -5.542e-01  2.803e-01  -1.977   0.0480 *
---
Signif. codes:  0 *** 0.001 ** 0.01 * 0.05 . 0.1   1

(Dispersion parameter for binomial family taken to be 1)

    Null deviance: 950.86  on 713  degrees of freedom
Residual deviance: 373.30  on 517  degrees of freedom
AIC: 767.3

Number of Fisher Scoring iterations: 18


</pre>

</div>
</div>

</div>
</div>

</div>
<div class="text_cell_render border-box-sizing rendered_html">
<p>Okay looks like we're doing (un)reasonably well. Let's try a couple of interesting ideas. <strong>Class Compression</strong> refers to collapsing some levels on a categorical variable. In layman terms, making a factor two-level. So for instance, we have Embarked, most of which has the value 'S' as we saw earlier. We can use the I() function when training to shrink this to S or otherwise. Let's do that.</p>
</div>
<div class="cell border-box-sizing code_cell vbox">
<div class="input hbox">
<div class="prompt input_prompt">
In&nbsp;[285]:
</div>
<div class="input_area box-flex1">
<div class="highlight"><pre><span class="o">%%</span><span class="k">R</span>
<span class="c">#Let&#39;s set class compression on Embarked to &#39;S&#39; or otherwise.</span>
<span class="nb">set</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">35</span><span class="p">)</span> 

<span class="n">logit</span><span class="o">.</span><span class="n">tune2</span><span class="o">&lt;-</span><span class="n">train</span><span class="p">(</span><span class="n">Survived</span> <span class="o">~</span> <span class="n">Sex</span> <span class="o">+</span> <span class="n">Pclass</span> <span class="o">+</span> <span class="n">Age</span> <span class="o">+</span> <span class="n">SibSp</span> <span class="o">+</span> <span class="n">I</span><span class="p">(</span><span class="n">Embarked</span><span class="o">==</span><span class="s">&#39;S&#39;</span><span class="p">)</span> <span class="o">+</span> <span class="n">FareGroup</span> <span class="o">+</span> <span class="n">FamID</span> <span class="o">+</span> <span class="n">Title</span><span class="p">,</span>
                <span class="n">data</span><span class="o">=</span><span class="n">train</span><span class="o">.</span><span class="n">set</span><span class="p">,</span>
                <span class="n">method</span><span class="o">=</span><span class="s">&#39;glm&#39;</span><span class="p">,</span>
                <span class="n">preProcess</span> <span class="o">=</span> <span class="n">c</span><span class="p">(</span><span class="s">&quot;center&quot;</span><span class="p">,</span> <span class="s">&quot;scale&quot;</span><span class="p">),</span>
                <span class="n">trControl</span><span class="o">=</span><span class="n">tenfoldcv</span><span class="p">)</span>

<span class="n">logit</span><span class="o">.</span><span class="n">tune2</span>
</pre></div>

</div>
</div>

<div class="vbox output_wrapper">
<div class="output vbox">


<div class="hbox output_area"><div class="prompt"></div>
<div class="box-flex1 output_subarea output_display_data">


<pre>
Generalized Linear Model 

714 samples
 14 predictors
  2 classes: &apos;0&apos;, &apos;1&apos; 

Pre-processing: centered, scaled 
Resampling: Cross-Validated (10 fold, repeated 3 times) 

Summary of sample sizes: 643, 643, 643, 642, 643, 643, ... 

Resampling results

  Accuracy   Kappa    Accuracy SD  Kappa SD 
  0.7820488  0.53063  0.05507752   0.1240941

 

</pre>

</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell vbox">
<div class="input hbox">
<div class="prompt input_prompt">
In&nbsp;[286]:
</div>
<div class="input_area box-flex1">
<div class="highlight"><pre><span class="o">%%</span><span class="k">R</span>
<span class="n">summary</span><span class="p">(</span><span class="n">logit</span><span class="o">.</span><span class="n">tune2</span><span class="p">)</span>
</pre></div>

</div>
</div>

<div class="vbox output_wrapper">
<div class="output vbox">


<div class="hbox output_area"><div class="prompt"></div>
<div class="box-flex1 output_subarea output_display_data">


<pre>

Call:
NULL

Deviance Residuals: 
     Min        1Q    Median        3Q       Max  
-2.34231  -0.43582  -0.00008   0.00010   2.42395  

Coefficients: (45 not defined because of singularities)
                              Estimate Std. Error z value Pr(&gt;|z|)  
(Intercept)                 -6.156e-01  2.122e+02  -0.003   0.9977  
Sexmale                     -1.065e+01  3.548e+03  -0.003   0.9976  
Pclass2                     -4.596e-01  2.869e-01  -1.602   0.1092  
Pclass3                     -5.264e-01  3.407e-01  -1.545   0.1223  
Age                         -3.148e-01  1.749e-01  -1.800   0.0718 .
SibSp                        2.230e-01  6.716e-01   0.332   0.7398  
&#96;I(Embarked == &quot;S&quot;)TRUE&#96;    -1.728e-01  1.444e-01  -1.197   0.2315  
&#96;FareGroup10-20&#96;             2.101e-01  2.593e-01   0.810   0.4177  
&#96;FareGroup20-40&#96;             5.142e-01  2.900e-01   1.773   0.0762 .
&#96;FareGroup40+&#96;               4.068e-01  2.876e-01   1.415   0.1572  
FamIDAbelson2               -1.258e-02  1.918e-01  -0.066   0.9477  
FamIDAhlin2                         NA         NA      NA       NA  
FamIDAks2                    6.882e-01  4.025e+02   0.002   0.9986  
FamIDAllison4               -1.181e+00  3.885e+02  -0.003   0.9976  
&#96;FamIDAndersen-Jensen2&#96;      7.511e-01  4.025e+02   0.002   0.9985  
FamIDAndersson7             -1.949e-01  2.170e-01  -0.898   0.3690  
FamIDAndrews2                7.132e-01  4.025e+02   0.002   0.9986  
FamIDAngle2                         NA         NA      NA       NA  
FamIDAppleton3               6.264e-01  4.025e+02   0.002   0.9988  
&#96;FamIDArnold-Franchi2&#96;      -1.072e+00  3.092e+02  -0.003   0.9972  
FamIDAsplund7               -6.467e-02  1.965e-01  -0.329   0.7421  
FamIDAstor2                         NA         NA      NA       NA  
FamIDBackstrom2             -6.081e-01  4.025e+02  -0.002   0.9988  
FamIDBackstrom4              6.584e-01  4.025e+02   0.002   0.9987  
FamIDBaclini4                9.586e-01  3.950e+02   0.002   0.9981  
FamIDBarbara2               -1.085e+00  3.895e+02  -0.003   0.9978  
FamIDBaxter2                -3.857e-02  1.849e-01  -0.209   0.8347  
FamIDBeane2                  8.320e-01  4.025e+02   0.002   0.9984  
FamIDBecker4                 6.901e-01  4.025e+02   0.002   0.9986  
FamIDBeckwith3               1.073e+00  3.164e+02   0.003   0.9973  
FamIDBishop2                 5.893e-01  4.025e+02   0.001   0.9988  
FamIDBoulos3                -7.564e-01  4.025e+02  -0.002   0.9985  
FamIDBourke3                -1.297e+00  3.146e+02  -0.004   0.9967  
FamIDBowerman2               6.842e-01  4.025e+02   0.002   0.9986  
FamIDBraund2                        NA         NA      NA       NA  
FamIDBrown3                  3.452e-02  2.015e-01   0.171   0.8640  
FamIDBryhl2                 -6.388e-01  4.025e+02  -0.002   0.9987  
FamIDCaldwell3               9.648e-01  3.862e+02   0.002   0.9980  
FamIDCaram2                 -8.146e-01  4.025e+02  -0.002   0.9984  
FamIDCardeza2                7.956e-01  4.025e+02   0.002   0.9984  
FamIDCarter2                -1.067e+00  2.919e+02  -0.004   0.9971  
FamIDCarter4                 1.289e+00  3.194e+02   0.004   0.9968  
FamIDCavendish2             -6.623e-01  4.025e+02  -0.002   0.9987  
FamIDChaffee2                       NA         NA      NA       NA  
FamIDChambers2               1.060e+00  3.146e+02   0.003   0.9973  
FamIDChapman2                       NA         NA      NA       NA  
FamIDChibnall2                      NA         NA      NA       NA  
FamIDChristy3                7.125e-01  4.025e+02   0.002   0.9986  
FamIDChronopoulos2          -6.279e-01  4.025e+02  -0.002   0.9988  
FamIDClark2                         NA         NA      NA       NA  
FamIDClarke2                 6.453e-01  4.025e+02   0.002   0.9987  
FamIDCollyer3                7.044e-02  2.012e-01   0.350   0.7262  
FamIDCompton3                6.772e-01  4.025e+02   0.002   0.9987  
FamIDCornell3                       NA         NA      NA       NA  
FamIDCoutts3                 7.242e-01  4.025e+02   0.002   0.9986  
FamIDCribb2                 -5.894e-01  4.025e+02  -0.001   0.9988  
FamIDCrosby3                 4.598e-02  1.763e-01   0.261   0.7943  
FamIDCumings2                6.064e-01  4.025e+02   0.002   0.9988  
FamIDDanbom3                -1.059e+00  3.096e+02  -0.003   0.9973  
FamIDDavidson2              -6.668e-01  4.025e+02  -0.002   0.9987  
FamIDDavidson4                      NA         NA      NA       NA  
FamIDDavies3                 3.841e-02  1.639e-01   0.234   0.8148  
FamIDDavison2                6.643e-01  4.025e+02   0.002   0.9987  
FamIDDean4                   3.913e-02  1.693e-01   0.231   0.8172  
FamIDdelCarlo2              -6.496e-01  4.025e+02  -0.002   0.9987  
FamIDdeMessemaeker2          6.769e-01  4.025e+02   0.002   0.9987  
FamIDDick2                   1.062e+00  3.064e+02   0.003   0.9972  
FamIDDodge3                  6.751e-01  4.025e+02   0.002   0.9987  
FamIDDoling2                 7.141e-01  4.025e+02   0.002   0.9986  
FamIDDouglas2               -6.642e-01  4.025e+02  -0.002   0.9987  
FamIDDouglas3                       NA         NA      NA       NA  
FamIDDrew3                          NA         NA      NA       NA  
FamIDDuffGordon2             1.065e+00  3.082e+02   0.003   0.9972  
&#96;FamIDDurany More2&#96;          7.266e-01  4.025e+02   0.002   0.9986  
FamIDDyker2                         NA         NA      NA       NA  
FamIDEarnshaw2                      NA         NA      NA       NA  
FamIDElias3                 -6.165e-01  4.025e+02  -0.002   0.9988  
FamIDEustis2                 6.907e-01  4.025e+02   0.002   0.9986  
FamIDFaunthorpe2             6.462e-01  4.025e+02   0.002   0.9987  
FamIDFord5                  -1.315e+00  3.326e+02  -0.004   0.9968  
FamIDFortune6               -3.674e-02  2.089e-01  -0.176   0.8604  
FamIDFrauenthal2             6.064e-01  4.025e+02   0.002   0.9988  
FamIDFrauenthal3             8.513e-01  4.025e+02   0.002   0.9983  
FamIDFrolicher3              6.698e-01  4.025e+02   0.002   0.9987  
&#96;FamIDFrolicher-Stehli3&#96;     8.093e-01  4.025e+02   0.002   0.9984  
FamIDFutrelle2              -3.060e-02  1.936e-01  -0.158   0.8744  
FamIDGale2                  -6.307e-01  4.025e+02  -0.002   0.9987  
FamIDGibson2                        NA         NA      NA       NA  
FamIDGiles2                 -6.156e-01  4.025e+02  -0.002   0.9988  
FamIDGoldenberg2             1.063e+00  3.015e+02   0.004   0.9972  
FamIDGoldsmith3              6.456e-01  4.025e+02   0.002   0.9987  
FamIDGoodwin8               -1.578e+00  3.993e+02  -0.004   0.9968  
FamIDGraham2                 6.467e-01  4.025e+02   0.002   0.9987  
FamIDGreenfield2             7.839e-01  4.025e+02   0.002   0.9984  
FamIDGustafsson3            -8.424e-01  4.018e+02  -0.002   0.9983  
FamIDHagland2               -6.171e-01  4.025e+02  -0.002   0.9988  
FamIDHakkarainen2                   NA         NA      NA       NA  
FamIDHamalainen3             9.976e-01  3.930e+02   0.003   0.9980  
FamIDHansen2                -5.939e-01  4.025e+02  -0.001   0.9988  
FamIDHansen3                -6.079e-01  4.025e+02  -0.002   0.9988  
FamIDHarder2                 7.778e-01  4.025e+02   0.002   0.9985  
FamIDHarper2                 2.196e-01  2.276e-01   0.965   0.3347  
FamIDHarris2                -2.551e-02  1.979e-01  -0.129   0.8974  
FamIDHart3                   8.158e-02  2.036e-01   0.401   0.6886  
FamIDHays3                   6.334e-01  4.025e+02   0.002   0.9987  
FamIDHerman4                 7.200e-01  4.025e+02   0.002   0.9986  
FamIDHickman3               -9.052e-01  4.021e+02  -0.002   0.9982  
FamIDHiltunen3                      NA         NA      NA       NA  
FamIDHippach2                9.129e-01  3.897e+02   0.002   0.9981  
FamIDHirvonen2               7.241e-01  4.025e+02   0.002   0.9986  
FamIDHirvonen3                      NA         NA      NA       NA  
FamIDHocking4               -6.217e-01  4.025e+02  -0.002   0.9988  
FamIDHocking5                       NA         NA      NA       NA  
FamIDHogeboom2                      NA         NA      NA       NA  
FamIDHold2                  -6.217e-01  4.025e+02  -0.002   0.9988  
FamIDHolverson2             -6.569e-01  4.025e+02  -0.002   0.9987  
FamIDHoward2                        NA         NA      NA       NA  
FamIDHoyt2                   6.181e-01  4.025e+02   0.002   0.9988  
FamIDIlmakangas2            -7.080e-01  4.025e+02  -0.002   0.9986  
FamIDJacobsohn2             -6.235e-01  4.025e+02  -0.002   0.9988  
FamIDJacobsohn4              6.338e-01  4.025e+02   0.002   0.9987  
FamIDJefferys3                      NA         NA      NA       NA  
FamIDJensen2                -6.020e-01  4.025e+02  -0.001   0.9988  
FamIDJohnson3                1.017e+00  3.987e+02   0.003   0.9980  
FamIDJohnston4              -7.571e-01  4.025e+02  -0.002   0.9985  
FamIDJussila2               -1.006e+00  4.022e+02  -0.003   0.9980  
FamIDKantor2                 7.818e-03  1.951e-01   0.040   0.9680  
FamIDKarun2                         NA         NA      NA       NA  
FamIDKenyon2                 6.064e-01  4.025e+02   0.002   0.9988  
FamIDKhalil2                        NA         NA      NA       NA  
FamIDKiernan2               -6.120e-01  4.025e+02  -0.002   0.9988  
FamIDKimball2                8.075e-01  4.025e+02   0.002   0.9984  
FamIDKink3                  -6.018e-01  4.025e+02  -0.001   0.9988  
&#96;FamIDKink-Heilmann3&#96;        6.991e-01  4.025e+02   0.002   0.9986  
&#96;FamIDKink-Heilmann5&#96;               NA         NA      NA       NA  
FamIDKlasen3                -6.011e-01  4.025e+02  -0.001   0.9988  
FamIDLahtinen3              -8.210e-01  4.025e+02  -0.002   0.9984  
FamIDLaroche4                4.529e-02  2.065e-01   0.219   0.8264  
FamIDLefebre5               -1.332e+00  3.992e+02  -0.003   0.9973  
FamIDLennon2                -6.315e-01  4.025e+02  -0.002   0.9987  
FamIDLindell2               -6.045e-01  4.025e+02  -0.002   0.9988  
FamIDLindqvist2              8.652e-01  4.025e+02   0.002   0.9983  
FamIDLines2                  6.704e-01  4.025e+02   0.002   0.9987  
FamIDLobb2                  -6.099e-01  4.025e+02  -0.002   0.9988  
FamIDLouch2                  6.579e-01  4.025e+02   0.002   0.9987  
FamIDMadill2                 6.779e-01  4.025e+02   0.002   0.9987  
FamIDMallet3                 3.085e-02  1.749e-01   0.176   0.8600  
FamIDMarvin2                -6.776e-01  4.025e+02  -0.002   0.9987  
FamIDMcCoy3                  1.072e+00  3.278e+02   0.003   0.9974  
FamIDMcNamee2               -6.153e-01  4.025e+02  -0.002   0.9988  
FamIDMellinger2                     NA         NA      NA       NA  
FamIDMeyer2                 -6.498e-02  1.959e-01  -0.332   0.7401  
FamIDMinahan2                6.718e-01  4.025e+02   0.002   0.9987  
FamIDMinahan3               -6.330e-01  4.025e+02  -0.002   0.9987  
FamIDMock2                          NA         NA      NA       NA  
FamIDMoor2                   1.008e+00  3.893e+02   0.003   0.9979  
FamIDMoran2                  2.453e-02  1.613e-01   0.152   0.8791  
FamIDMoubarek3               1.027e+00  4.022e+02   0.003   0.9980  
FamIDMurphy2                 7.197e-01  4.025e+02   0.002   0.9986  
FamIDNakid3                  1.116e+00  3.201e+02   0.003   0.9972  
FamIDNasser2                -1.989e-02  2.010e-01  -0.099   0.9212  
FamIDNatsch2                -6.764e-01  4.025e+02  -0.002   0.9987  
FamIDNavratil3               6.998e-01  4.025e+02   0.002   0.9986  
FamIDNewell2                 9.419e-01  4.019e+02   0.002   0.9981  
FamIDNewell3                -6.491e-01  4.025e+02  -0.002   0.9987  
FamIDNewsom3                 6.731e-01  4.025e+02   0.002   0.9987  
FamIDNicholls3              -6.442e-01  4.025e+02  -0.002   0.9987  
&#96;FamIDNicola-Yarred2&#96;        1.010e+00  3.993e+02   0.003   0.9980  
&#96;FamIDO&apos;Brien2&#96;              6.498e-01  4.025e+02   0.002   0.9987  
FamIDOlsen2                 -5.716e-01  4.025e+02  -0.001   0.9989  
FamIDOstby2                         NA         NA      NA       NA  
FamIDPalsson5               -1.585e+00  3.966e+02  -0.004   0.9968  
FamIDPanula6                -1.702e+00  3.386e+02  -0.005   0.9960  
FamIDParrish2                6.730e-01  4.025e+02   0.002   0.9987  
FamIDPeacock3                       NA         NA      NA       NA  
FamIDPears2                 -4.395e-02  1.963e-01  -0.224   0.8228  
&#96;FamIDPenascoy Castellana2&#96; -7.452e-02  1.935e-01  -0.385   0.7001  
FamIDPersson2                8.697e-01  4.025e+02   0.002   0.9983  
FamIDPeter3                  9.473e-01  3.850e+02   0.002   0.9980  
FamIDPetterson2             -5.948e-01  4.025e+02  -0.001   0.9988  
FamIDPhillips2                      NA         NA      NA       NA  
FamIDPotter2                 6.305e-01  4.025e+02   0.002   0.9988  
FamIDQuick3                  6.918e-01  4.025e+02   0.002   0.9986  
FamIDRenouf2                        NA         NA      NA       NA  
FamIDRenouf4                 6.313e-01  4.025e+02   0.002   0.9987  
FamIDRice6                  -1.799e+00  4.005e+02  -0.004   0.9964  
FamIDRichards3               7.265e-01  4.025e+02   0.002   0.9986  
FamIDRichards6               6.606e-01  4.025e+02   0.002   0.9987  
FamIDRobert2                 6.332e-01  4.025e+02   0.002   0.9987  
FamIDRobins2                -7.777e-01  4.025e+02  -0.002   0.9985  
FamIDRosblom3               -1.075e+00  3.238e+02  -0.003   0.9974  
FamIDRothschild2                    NA         NA      NA       NA  
FamIDRyerson5                6.504e-01  4.025e+02   0.002   0.9987  
FamIDSage11                 -1.752e+00  3.578e+02  -0.005   0.9961  
FamIDSamaan3                -6.662e-01  4.025e+02  -0.002   0.9987  
FamIDSandstrom3              9.893e-01  3.912e+02   0.003   0.9980  
FamIDSchabert2                      NA         NA      NA       NA  
FamIDShelley2                6.505e-01  4.025e+02   0.002   0.9987  
FamIDSilven3                 7.408e-01  4.025e+02   0.002   0.9985  
FamIDSilvey2                -1.979e-02  1.986e-01  -0.100   0.9206  
FamIDSkoog6                 -1.723e+00  3.454e+02  -0.005   0.9960  
FamIDSmith2                         NA         NA      NA       NA  
FamIDSnyder2                        NA         NA      NA       NA  
FamIDSolo                    7.121e-01  1.284e+00   0.555   0.5791  
FamIDSpedden3                       NA         NA      NA       NA  
FamIDSpencer2                5.920e-01  4.025e+02   0.001   0.9988  
FamIDStengel2                       NA         NA      NA       NA  
FamIDStephenson2             6.190e-01  4.025e+02   0.002   0.9988  
FamIDStraus2                        NA         NA      NA       NA  
FamIDStrom2                 -7.404e-01  4.025e+02  -0.002   0.9985  
FamIDStrom3                 -7.939e-01  4.025e+02  -0.002   0.9984  
FamIDTaussig3                9.304e-01  3.843e+02   0.002   0.9981  
FamIDTaylor2                 1.082e+00  3.019e+02   0.004   0.9971  
FamIDThayer3                 1.040e+00  3.203e+02   0.003   0.9974  
FamIDThomas2                 7.349e-01  4.025e+02   0.002   0.9985  
FamIDThomas3                        NA         NA      NA       NA  
FamIDThorneycroft2           3.334e-02  1.905e-01   0.175   0.8611  
FamIDTouma3                         NA         NA      NA       NA  
FamIDTurpin2                -1.096e+00  3.112e+02  -0.004   0.9972  
FamIDvanBilliard3           -5.926e-01  4.025e+02  -0.001   0.9988  
FamIDVanderPlanke2          -7.921e-01  4.025e+02  -0.002   0.9984  
FamIDVanderPlanke3          -9.930e-01  3.288e+02  -0.003   0.9976  
FamIDVanderPlanke4                  NA         NA      NA       NA  
FamIDVanImpe3               -1.127e+00  3.840e+02  -0.003   0.9977  
FamIDWare2                          NA         NA      NA       NA  
FamIDWarren2                 6.262e-01  4.025e+02   0.002   0.9988  
FamIDWeisz2                  6.462e-01  4.025e+02   0.002   0.9987  
FamIDWells3                  6.936e-01  4.025e+02   0.002   0.9986  
FamIDWest4                   6.739e-02  2.041e-01   0.330   0.7412  
FamIDWhite2                 -6.383e-01  4.025e+02  -0.002   0.9987  
FamIDWick3                   6.923e-01  4.025e+02   0.002   0.9986  
FamIDWidener3               -6.770e-01  4.025e+02  -0.002   0.9987  
FamIDWiklund2                       NA         NA      NA       NA  
FamIDWilkes2                        NA         NA      NA       NA  
FamIDWilliams2              -6.554e-01  4.025e+02  -0.002   0.9987  
FamIDYasbeck2                       NA         NA      NA       NA  
FamIDZabour2                -7.448e-01  4.025e+02  -0.002   0.9985  
TitleMiss                   -8.980e+00  3.017e+03  -0.003   0.9976  
TitleMr                     -1.399e+00  7.872e-01  -1.778   0.0755 .
TitleMrs                    -7.107e+00  2.608e+03  -0.003   0.9978  
TitleNoble                  -5.585e-01  2.807e-01  -1.989   0.0467 *
---
Signif. codes:  0 *** 0.001 ** 0.01 * 0.05 . 0.1   1

(Dispersion parameter for binomial family taken to be 1)

    Null deviance: 950.86  on 713  degrees of freedom
Residual deviance: 373.54  on 518  degrees of freedom
AIC: 765.54

Number of Fisher Scoring iterations: 18


</pre>

</div>
</div>

</div>
</div>

</div>
<div class="text_cell_render border-box-sizing rendered_html">
<p>So that didn't really help. Let's try one last trick, <strong>Interaction</strong>. Let's work in an interaction effect between passenger class and sex, as passenger class showed a much bigger difference in survival rate amongst the women compared to the men (i.e. Higher class women were much more likely to survive than lower class women, whereas first class Men were more likely to survive than 2nd or 3rd class men, but not by the same margin as amongst the women). We saw this during our initial visualizations. Besides Pclass and Sex have been the biggest determining factors so far.</p>
</div>
<div class="cell border-box-sizing code_cell vbox">
<div class="input hbox">
<div class="prompt input_prompt">
In&nbsp;[287]:
</div>
<div class="input_area box-flex1">
<div class="highlight"><pre><span class="o">%%</span><span class="k">R</span>
<span class="c">#Let&#39;s work in an interaction between Pclass and Sex.</span>
<span class="nb">set</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">35</span><span class="p">)</span> 

<span class="n">logit</span><span class="o">.</span><span class="n">tune3</span><span class="o">&lt;-</span><span class="n">train</span><span class="p">(</span><span class="n">Survived</span> <span class="o">~</span> <span class="n">Sex</span> <span class="o">+</span> <span class="n">Pclass</span> <span class="o">+</span> <span class="n">Sex</span><span class="p">:</span><span class="n">Pclass</span> <span class="o">+</span> <span class="n">Age</span> <span class="o">+</span> <span class="n">SibSp</span> <span class="o">+</span> <span class="n">Embarked</span> <span class="o">+</span> <span class="n">FareGroup</span> <span class="o">+</span> <span class="n">FamID</span> <span class="o">+</span> <span class="n">Title</span><span class="p">,</span>
                <span class="n">data</span><span class="o">=</span><span class="n">train</span><span class="o">.</span><span class="n">set</span><span class="p">,</span>
                <span class="n">method</span><span class="o">=</span><span class="s">&#39;glm&#39;</span><span class="p">,</span>
                <span class="n">preProcess</span> <span class="o">=</span> <span class="n">c</span><span class="p">(</span><span class="s">&quot;center&quot;</span><span class="p">,</span> <span class="s">&quot;scale&quot;</span><span class="p">),</span>
                <span class="n">trControl</span><span class="o">=</span><span class="n">tenfoldcv</span><span class="p">)</span>

<span class="n">logit</span><span class="o">.</span><span class="n">tune3</span>
</pre></div>

</div>
</div>

<div class="vbox output_wrapper">
<div class="output vbox">


<div class="hbox output_area"><div class="prompt"></div>
<div class="box-flex1 output_subarea output_display_data">


<pre>
Generalized Linear Model 

714 samples
 14 predictors
  2 classes: &apos;0&apos;, &apos;1&apos; 

Pre-processing: centered, scaled 
Resampling: Cross-Validated (10 fold, repeated 3 times) 

Summary of sample sizes: 643, 643, 643, 642, 643, 643, ... 

Resampling results

  Accuracy   Kappa      Accuracy SD  Kappa SD 
  0.7904864  0.5472096  0.05401862   0.1249195

 

</pre>

</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell vbox">
<div class="input hbox">
<div class="prompt input_prompt">
In&nbsp;[288]:
</div>
<div class="input_area box-flex1">
<div class="highlight"><pre><span class="o">%%</span><span class="k">R</span>
<span class="n">summary</span><span class="p">(</span><span class="n">logit</span><span class="o">.</span><span class="n">tune3</span><span class="p">)</span>
</pre></div>

</div>
</div>

<div class="vbox output_wrapper">
<div class="output vbox">


<div class="hbox output_area"><div class="prompt"></div>
<div class="box-flex1 output_subarea output_display_data">


<pre>

Call:
NULL

Deviance Residuals: 
     Min        1Q    Median        3Q       Max  
-2.85112  -0.46296  -0.00009   0.00009   2.54282  

Coefficients: (45 not defined because of singularities)
                              Estimate Std. Error z value Pr(&gt;|z|)  
(Intercept)                 -5.350e-01  2.135e+02  -0.003   0.9980  
Sexmale                     -1.099e+01  3.407e+03  -0.003   0.9974  
Pclass2                     -7.112e-01  6.345e-01  -1.121   0.2623  
Pclass3                     -1.487e+00  7.122e-01  -2.088   0.0368 *
Age                         -3.107e-01  1.799e-01  -1.727   0.0842 .
SibSp                        2.551e-02  6.888e-01   0.037   0.9705  
EmbarkedQ                    1.342e-01  1.615e-01   0.831   0.4058  
EmbarkedS                   -1.049e-01  1.818e-01  -0.577   0.5640  
&#96;FareGroup10-20&#96;             1.840e-01  2.615e-01   0.704   0.4816  
&#96;FareGroup20-40&#96;             5.310e-01  2.953e-01   1.798   0.0721 .
&#96;FareGroup40+&#96;               3.425e-01  3.013e-01   1.137   0.2556  
FamIDAbelson2               -2.723e-02  1.935e-01  -0.141   0.8881  
FamIDAhlin2                         NA         NA      NA       NA  
FamIDAks2                    7.047e-01  4.025e+02   0.002   0.9986  
FamIDAllison4               -1.250e+00  3.928e+02  -0.003   0.9975  
&#96;FamIDAndersen-Jensen2&#96;      7.543e-01  4.025e+02   0.002   0.9985  
FamIDAndersson7             -1.563e-01  1.910e-01  -0.818   0.4132  
FamIDAndrews2                6.498e-01  4.025e+02   0.002   0.9987  
FamIDAngle2                         NA         NA      NA       NA  
FamIDAppleton3               5.904e-01  4.025e+02   0.001   0.9988  
&#96;FamIDArnold-Franchi2&#96;      -1.044e+00  3.351e+02  -0.003   0.9975  
FamIDAsplund7               -3.992e-02  1.723e-01  -0.232   0.8168  
FamIDAstor2                         NA         NA      NA       NA  
FamIDBackstrom2             -6.261e-01  4.025e+02  -0.002   0.9988  
FamIDBackstrom4              6.981e-01  4.025e+02   0.002   0.9986  
FamIDBaclini4                9.878e-01  3.963e+02   0.002   0.9980  
FamIDBarbara2               -1.059e+00  3.933e+02  -0.003   0.9979  
FamIDBaxter2                -7.557e-02  1.924e-01  -0.393   0.6945  
FamIDBeane2                  8.272e-01  4.025e+02   0.002   0.9984  
FamIDBecker4                 7.046e-01  4.025e+02   0.002   0.9986  
FamIDBeckwith3               1.064e+00  3.177e+02   0.003   0.9973  
FamIDBishop2                 5.524e-01  4.025e+02   0.001   0.9989  
FamIDBoulos3                -7.450e-01  4.025e+02  -0.002   0.9985  
FamIDBourke3                -1.292e+00  3.411e+02  -0.004   0.9970  
FamIDBowerman2               6.143e-01  4.025e+02   0.002   0.9988  
FamIDBraund2                        NA         NA      NA       NA  
FamIDBrown3                  1.151e-02  2.058e-01   0.056   0.9554  
FamIDBryhl2                 -6.435e-01  4.025e+02  -0.002   0.9987  
FamIDCaldwell3               9.558e-01  3.665e+02   0.003   0.9979  
FamIDCaram2                 -7.831e-01  4.025e+02  -0.002   0.9984  
FamIDCardeza2                7.874e-01  4.025e+02   0.002   0.9984  
FamIDCarter2                -1.102e+00  2.822e+02  -0.004   0.9969  
FamIDCarter4                 1.278e+00  3.216e+02   0.004   0.9968  
FamIDCavendish2             -6.692e-01  4.025e+02  -0.002   0.9987  
FamIDChaffee2                       NA         NA      NA       NA  
FamIDChambers2               1.051e+00  3.161e+02   0.003   0.9973  
FamIDChapman2                       NA         NA      NA       NA  
FamIDChibnall2                      NA         NA      NA       NA  
FamIDChristy3                6.650e-01  4.025e+02   0.002   0.9987  
FamIDChronopoulos2          -6.402e-01  4.025e+02  -0.002   0.9987  
FamIDClark2                         NA         NA      NA       NA  
FamIDClarke2                 6.180e-01  4.025e+02   0.002   0.9988  
FamIDCollyer3                2.449e-02  2.003e-01   0.122   0.9027  
FamIDCompton3                6.197e-01  4.025e+02   0.002   0.9988  
FamIDCornell3                       NA         NA      NA       NA  
FamIDCoutts3                 7.184e-01  4.025e+02   0.002   0.9986  
FamIDCribb2                 -6.146e-01  4.025e+02  -0.002   0.9988  
FamIDCrosby3                -8.693e-03  1.950e-01  -0.045   0.9644  
FamIDCumings2                5.693e-01  4.025e+02   0.001   0.9989  
FamIDDanbom3                -1.032e+00  3.356e+02  -0.003   0.9975  
FamIDDavidson2              -6.737e-01  4.025e+02  -0.002   0.9987  
FamIDDavidson4                      NA         NA      NA       NA  
FamIDDavies3                 3.311e-02  1.406e-01   0.235   0.8138  
FamIDDavison2                6.902e-01  4.025e+02   0.002   0.9986  
FamIDDean4                   1.679e-02  1.481e-01   0.113   0.9097  
FamIDdelCarlo2              -6.487e-01  4.025e+02  -0.002   0.9987  
FamIDdeMessemaeker2          7.026e-01  4.025e+02   0.002   0.9986  
FamIDDick2                   1.053e+00  3.083e+02   0.003   0.9973  
FamIDDodge3                  6.735e-01  4.025e+02   0.002   0.9987  
FamIDDoling2                 6.597e-01  4.025e+02   0.002   0.9987  
FamIDDouglas2               -6.656e-01  4.025e+02  -0.002   0.9987  
FamIDDouglas3                       NA         NA      NA       NA  
FamIDDrew3                          NA         NA      NA       NA  
FamIDDuffGordon2             1.063e+00  3.093e+02   0.003   0.9973  
&#96;FamIDDurany More2&#96;          6.887e-01  4.025e+02   0.002   0.9986  
FamIDDyker2                         NA         NA      NA       NA  
FamIDEarnshaw2                      NA         NA      NA       NA  
FamIDElias3                 -6.311e-01  4.025e+02  -0.002   0.9987  
FamIDEustis2                 6.331e-01  4.025e+02   0.002   0.9987  
FamIDFaunthorpe2             6.189e-01  4.025e+02   0.002   0.9988  
FamIDFord5                  -1.295e+00  3.571e+02  -0.004   0.9971  
FamIDFortune6               -7.440e-02  2.115e-01  -0.352   0.7250  
FamIDFrauenthal2             5.638e-01  4.025e+02   0.001   0.9989  
FamIDFrauenthal3             8.475e-01  4.025e+02   0.002   0.9983  
FamIDFrolicher3              6.055e-01  4.025e+02   0.002   0.9988  
&#96;FamIDFrolicher-Stehli3&#96;     8.078e-01  4.025e+02   0.002   0.9984  
FamIDFutrelle2              -6.571e-02  2.075e-01  -0.317   0.7515  
FamIDGale2                  -6.355e-01  4.025e+02  -0.002   0.9987  
FamIDGibson2                        NA         NA      NA       NA  
FamIDGiles2                 -6.164e-01  4.025e+02  -0.002   0.9988  
FamIDGoldenberg2             1.061e+00  3.036e+02   0.003   0.9972  
FamIDGoldsmith3              6.675e-01  4.025e+02   0.002   0.9987  
FamIDGoodwin8               -1.520e+00  3.999e+02  -0.004   0.9970  
FamIDGraham2                 5.967e-01  4.025e+02   0.001   0.9988  
FamIDGreenfield2             7.758e-01  4.025e+02   0.002   0.9985  
FamIDGustafsson3            -8.615e-01  4.018e+02  -0.002   0.9983  
FamIDHagland2               -6.350e-01  4.025e+02  -0.002   0.9987  
FamIDHakkarainen2                   NA         NA      NA       NA  
FamIDHamalainen3             9.973e-01  3.640e+02   0.003   0.9978  
FamIDHansen2                -6.143e-01  4.025e+02  -0.002   0.9988  
FamIDHansen3                -6.191e-01  4.025e+02  -0.002   0.9988  
FamIDHarder2                 7.767e-01  4.025e+02   0.002   0.9985  
FamIDHarper2                 1.991e-01  2.017e-01   0.987   0.3236  
FamIDHarris2                -6.069e-02  2.139e-01  -0.284   0.7766  
FamIDHart3                   3.698e-02  2.039e-01   0.181   0.8561  
FamIDHays3                   5.905e-01  4.025e+02   0.001   0.9988  
FamIDHerman4                 6.800e-01  4.025e+02   0.002   0.9987  
FamIDHickman3               -8.913e-01  4.021e+02  -0.002   0.9982  
FamIDHiltunen3                      NA         NA      NA       NA  
FamIDHippach2                8.313e-01  3.934e+02   0.002   0.9983  
FamIDHirvonen2               7.229e-01  4.025e+02   0.002   0.9986  
FamIDHirvonen3                      NA         NA      NA       NA  
FamIDHocking4               -6.155e-01  4.025e+02  -0.002   0.9988  
FamIDHocking5                       NA         NA      NA       NA  
FamIDHogeboom2                      NA         NA      NA       NA  
FamIDHold2                  -6.266e-01  4.025e+02  -0.002   0.9988  
FamIDHolverson2             -6.639e-01  4.025e+02  -0.002   0.9987  
FamIDHoward2                        NA         NA      NA       NA  
FamIDHoyt2                   5.754e-01  4.025e+02   0.001   0.9989  
FamIDIlmakangas2            -7.049e-01  4.025e+02  -0.002   0.9986  
FamIDJacobsohn2             -6.284e-01  4.025e+02  -0.002   0.9988  
FamIDJacobsohn4              6.136e-01  4.025e+02   0.002   0.9988  
FamIDJefferys3                      NA         NA      NA       NA  
FamIDJensen2                -6.223e-01  4.025e+02  -0.002   0.9988  
FamIDJohnson3                1.018e+00  4.013e+02   0.003   0.9980  
FamIDJohnston4              -7.554e-01  4.025e+02  -0.002   0.9985  
FamIDJussila2               -1.002e+00  4.022e+02  -0.002   0.9980  
FamIDKantor2                -1.484e-02  1.977e-01  -0.075   0.9401  
FamIDKarun2                         NA         NA      NA       NA  
FamIDKenyon2                 5.638e-01  4.025e+02   0.001   0.9989  
FamIDKhalil2                        NA         NA      NA       NA  
FamIDKiernan2               -6.449e-01  4.025e+02  -0.002   0.9987  
FamIDKimball2                8.006e-01  4.025e+02   0.002   0.9984  
FamIDKink3                  -6.152e-01  4.025e+02  -0.002   0.9988  
&#96;FamIDKink-Heilmann3&#96;        6.940e-01  4.025e+02   0.002   0.9986  
&#96;FamIDKink-Heilmann5&#96;               NA         NA      NA       NA  
FamIDKlasen3                -6.214e-01  4.025e+02  -0.002   0.9988  
FamIDLahtinen3              -8.482e-01  4.025e+02  -0.002   0.9983  
FamIDLaroche4                2.688e-02  2.057e-01   0.131   0.8960  
FamIDLefebre5               -1.312e+00  4.011e+02  -0.003   0.9974  
FamIDLennon2                -6.620e-01  4.025e+02  -0.002   0.9987  
FamIDLindell2               -6.226e-01  4.025e+02  -0.002   0.9988  
FamIDLindqvist2              8.448e-01  4.025e+02   0.002   0.9983  
FamIDLines2                  5.931e-01  4.025e+02   0.001   0.9988  
FamIDLobb2                  -6.279e-01  4.025e+02  -0.002   0.9988  
FamIDLouch2                  6.305e-01  4.025e+02   0.002   0.9988  
FamIDMadill2                 6.081e-01  4.025e+02   0.002   0.9988  
FamIDMallet3                 3.582e-02  1.574e-01   0.228   0.8200  
FamIDMarvin2                -6.843e-01  4.025e+02  -0.002   0.9986  
FamIDMcCoy3                  1.042e+00  3.470e+02   0.003   0.9976  
FamIDMcNamee2               -6.332e-01  4.025e+02  -0.002   0.9987  
FamIDMellinger2                     NA         NA      NA       NA  
FamIDMeyer2                 -9.190e-02  2.106e-01  -0.436   0.6625  
FamIDMinahan2                5.962e-01  4.025e+02   0.001   0.9988  
FamIDMinahan3               -6.493e-01  4.025e+02  -0.002   0.9987  
FamIDMock2                          NA         NA      NA       NA  
FamIDMoor2                   1.003e+00  3.969e+02   0.003   0.9980  
FamIDMoran2                 -7.498e-03  1.385e-01  -0.054   0.9568  
FamIDMoubarek3               1.027e+00  4.022e+02   0.003   0.9980  
FamIDMurphy2                 7.128e-01  4.025e+02   0.002   0.9986  
FamIDNakid3                  1.104e+00  3.350e+02   0.003   0.9974  
FamIDNasser2                -3.445e-02  2.056e-01  -0.168   0.8669  
FamIDNatsch2                -6.921e-01  4.025e+02  -0.002   0.9986  
FamIDNavratil3               7.073e-01  4.025e+02   0.002   0.9986  
FamIDNewell2                 8.609e-01  4.019e+02   0.002   0.9983  
FamIDNewell3                -6.576e-01  4.025e+02  -0.002   0.9987  
FamIDNewsom3                 5.957e-01  4.025e+02   0.001   0.9988  
FamIDNicholls3              -6.488e-01  4.025e+02  -0.002   0.9987  
&#96;FamIDNicola-Yarred2&#96;        1.019e+00  4.013e+02   0.003   0.9980  
&#96;FamIDO&apos;Brien2&#96;              6.632e-01  4.025e+02   0.002   0.9987  
FamIDOlsen2                 -5.992e-01  4.025e+02  -0.001   0.9988  
FamIDOstby2                         NA         NA      NA       NA  
FamIDPalsson5               -1.559e+00  3.981e+02  -0.004   0.9969  
FamIDPanula6                -1.680e+00  3.489e+02  -0.005   0.9962  
FamIDParrish2                6.385e-01  4.025e+02   0.002   0.9987  
FamIDPeacock3                       NA         NA      NA       NA  
FamIDPears2                 -7.889e-02  2.114e-01  -0.373   0.7090  
&#96;FamIDPenascoy Castellana2&#96; -1.013e-01  2.069e-01  -0.490   0.6243  
FamIDPersson2                8.493e-01  4.025e+02   0.002   0.9983  
FamIDPeter3                  9.624e-01  3.894e+02   0.002   0.9980  
FamIDPetterson2             -6.152e-01  4.025e+02  -0.002   0.9988  
FamIDPhillips2                      NA         NA      NA       NA  
FamIDPotter2                 5.861e-01  4.025e+02   0.001   0.9988  
FamIDQuick3                  6.446e-01  4.025e+02   0.002   0.9987  
FamIDRenouf2                        NA         NA      NA       NA  
FamIDRenouf4                 6.180e-01  4.025e+02   0.002   0.9988  
FamIDRice6                  -1.800e+00  4.008e+02  -0.004   0.9964  
FamIDRichards3               7.379e-01  4.025e+02   0.002   0.9985  
FamIDRichards6               6.443e-01  4.025e+02   0.002   0.9987  
FamIDRobert2                 5.834e-01  4.025e+02   0.001   0.9988  
FamIDRobins2                -7.521e-01  4.025e+02  -0.002   0.9985  
FamIDRosblom3               -1.063e+00  3.483e+02  -0.003   0.9976  
FamIDRothschild2                    NA         NA      NA       NA  
FamIDRyerson5                6.002e-01  4.025e+02   0.001   0.9988  
FamIDSage11                 -1.635e+00  3.694e+02  -0.004   0.9965  
FamIDSamaan3                -6.754e-01  4.025e+02  -0.002   0.9987  
FamIDSandstrom3              1.003e+00  3.942e+02   0.003   0.9980  
FamIDSchabert2                      NA         NA      NA       NA  
FamIDShelley2                6.163e-01  4.025e+02   0.002   0.9988  
FamIDSilven3                 6.904e-01  4.025e+02   0.002   0.9986  
FamIDSilvey2                -5.504e-02  2.148e-01  -0.256   0.7977  
FamIDSkoog6                 -1.697e+00  3.623e+02  -0.005   0.9963  
FamIDSmith2                         NA         NA      NA       NA  
FamIDSnyder2                        NA         NA      NA       NA  
FamIDSolo                    4.404e-01  1.094e+00   0.403   0.6872  
FamIDSpedden3                       NA         NA      NA       NA  
FamIDSpencer2                5.550e-01  4.025e+02   0.001   0.9989  
FamIDStengel2                       NA         NA      NA       NA  
FamIDStephenson2             5.817e-01  4.025e+02   0.001   0.9988  
FamIDStraus2                        NA         NA      NA       NA  
FamIDStrom2                 -7.416e-01  4.025e+02  -0.002   0.9985  
FamIDStrom3                 -7.681e-01  4.025e+02  -0.002   0.9985  
FamIDTaussig3                8.421e-01  3.904e+02   0.002   0.9983  
FamIDTaylor2                 1.073e+00  3.040e+02   0.004   0.9972  
FamIDThayer3                 1.030e+00  3.244e+02   0.003   0.9975  
FamIDThomas2                 7.254e-01  4.025e+02   0.002   0.9986  
FamIDThomas3                        NA         NA      NA       NA  
FamIDThorneycroft2           3.898e-02  1.546e-01   0.252   0.8010  
FamIDTouma3                         NA         NA      NA       NA  
FamIDTurpin2                -1.127e+00  2.917e+02  -0.004   0.9969  
FamIDvanBilliard3           -6.177e-01  4.025e+02  -0.002   0.9988  
FamIDVanderPlanke2          -7.663e-01  4.025e+02  -0.002   0.9985  
FamIDVanderPlanke3          -9.833e-01  3.480e+02  -0.003   0.9977  
FamIDVanderPlanke4                  NA         NA      NA       NA  
FamIDVanImpe3               -1.106e+00  3.902e+02  -0.003   0.9977  
FamIDWare2                          NA         NA      NA       NA  
FamIDWarren2                 5.888e-01  4.025e+02   0.001   0.9988  
FamIDWeisz2                  6.189e-01  4.025e+02   0.002   0.9988  
FamIDWells3                  6.463e-01  4.025e+02   0.002   0.9987  
FamIDWest4                   2.669e-02  2.030e-01   0.132   0.8954  
FamIDWhite2                 -6.523e-01  4.025e+02  -0.002   0.9987  
FamIDWick3                   6.223e-01  4.025e+02   0.002   0.9988  
FamIDWidener3               -6.851e-01  4.025e+02  -0.002   0.9986  
FamIDWiklund2                       NA         NA      NA       NA  
FamIDWilkes2                        NA         NA      NA       NA  
FamIDWilliams2              -6.638e-01  4.025e+02  -0.002   0.9987  
FamIDYasbeck2                       NA         NA      NA       NA  
FamIDZabour2                -7.335e-01  4.025e+02  -0.002   0.9985  
TitleMiss                   -8.526e+00  2.897e+03  -0.003   0.9977  
TitleMr                     -1.242e+00  7.618e-01  -1.630   0.1030  
TitleMrs                    -6.906e+00  2.505e+03  -0.003   0.9978  
TitleNoble                  -5.001e-01  2.775e-01  -1.802   0.0716 .
&#96;Sexmale:Pclass2&#96;            1.211e-01  4.900e-01   0.247   0.8048  
&#96;Sexmale:Pclass3&#96;            1.035e+00  6.352e-01   1.630   0.1031  
---
Signif. codes:  0 *** 0.001 ** 0.01 * 0.05 . 0.1   1

(Dispersion parameter for binomial family taken to be 1)

    Null deviance: 950.86  on 713  degrees of freedom
Residual deviance: 366.58  on 515  degrees of freedom
AIC: 764.58

Number of Fisher Scoring iterations: 18


</pre>

</div>
</div>

</div>
</div>

</div>
<div class="text_cell_render border-box-sizing rendered_html">
<p>So we did a little bit better. I would just like to test a theory. We manufactured the FamilyID and have been doing well so far. What happens if we take it out? Will we do worse or better? Let's check it out.</p>
</div>
<div class="cell border-box-sizing code_cell vbox">
<div class="input hbox">
<div class="prompt input_prompt">
In&nbsp;[289]:
</div>
<div class="input_area box-flex1">
<div class="highlight"><pre><span class="o">%%</span><span class="k">R</span>
<span class="c">#Let&#39;s work in an interaction between Pclass and Sex.</span>
<span class="nb">set</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">35</span><span class="p">)</span> 

<span class="n">logit</span><span class="o">.</span><span class="n">tune4</span><span class="o">&lt;-</span><span class="n">train</span><span class="p">(</span><span class="n">Survived</span> <span class="o">~</span> <span class="n">Sex</span> <span class="o">+</span> <span class="n">Pclass</span> <span class="o">+</span> <span class="n">Sex</span><span class="p">:</span><span class="n">Pclass</span> <span class="o">+</span> <span class="n">Age</span> <span class="o">+</span> <span class="n">SibSp</span> <span class="o">+</span> <span class="n">Embarked</span> <span class="o">+</span> <span class="n">FareGroup</span> <span class="o">+</span> <span class="n">Title</span><span class="p">,</span>
                <span class="n">data</span><span class="o">=</span><span class="n">train</span><span class="o">.</span><span class="n">set</span><span class="p">,</span>
                <span class="n">method</span><span class="o">=</span><span class="s">&#39;glm&#39;</span><span class="p">,</span>
                <span class="n">preProcess</span> <span class="o">=</span> <span class="n">c</span><span class="p">(</span><span class="s">&quot;center&quot;</span><span class="p">,</span> <span class="s">&quot;scale&quot;</span><span class="p">),</span>
                <span class="n">trControl</span><span class="o">=</span><span class="n">tenfoldcv</span><span class="p">)</span>

<span class="n">logit</span><span class="o">.</span><span class="n">tune4</span>
</pre></div>

</div>
</div>

<div class="vbox output_wrapper">
<div class="output vbox">


<div class="hbox output_area"><div class="prompt"></div>
<div class="box-flex1 output_subarea output_display_data">


<pre>
Generalized Linear Model 

714 samples
 14 predictors
  2 classes: &apos;0&apos;, &apos;1&apos; 

Pre-processing: centered, scaled 
Resampling: Cross-Validated (10 fold, repeated 3 times) 

Summary of sample sizes: 643, 643, 643, 642, 643, 643, ... 

Resampling results

  Accuracy   Kappa      Accuracy SD  Kappa SD  
  0.8123305  0.5934912  0.04130739   0.09243173

 

</pre>

</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell vbox">
<div class="input hbox">
<div class="prompt input_prompt">
In&nbsp;[290]:
</div>
<div class="input_area box-flex1">
<div class="highlight"><pre><span class="o">%%</span><span class="k">R</span>
<span class="n">summary</span><span class="p">(</span><span class="n">logit</span><span class="o">.</span><span class="n">tune4</span><span class="p">)</span>
</pre></div>

</div>
</div>

<div class="vbox output_wrapper">
<div class="output vbox">


<div class="hbox output_area"><div class="prompt"></div>
<div class="box-flex1 output_subarea output_display_data">


<pre>

Call:
NULL

Deviance Residuals: 
    Min       1Q   Median       3Q      Max  
-2.6591  -0.5397  -0.4099   0.3937   2.4194  

Coefficients:
                   Estimate Std. Error z value Pr(&gt;|z|)    
(Intercept)        -0.56336    0.12309  -4.577 4.72e-06 ***
Sexmale            -8.13159  278.33333  -0.029 0.976693    
Pclass2            -0.36485    0.33842  -1.078 0.280987    
Pclass3            -1.62269    0.37865  -4.285 1.82e-05 ***
Age                -0.30128    0.13506  -2.231 0.025693 *  
SibSp              -0.62972    0.17467  -3.605 0.000312 ***
EmbarkedQ           0.04973    0.11805   0.421 0.673568    
EmbarkedS          -0.17619    0.12541  -1.405 0.160047    
&#96;FareGroup10-20&#96;    0.07364    0.14908   0.494 0.621326    
&#96;FareGroup20-40&#96;   -0.01342    0.17629  -0.076 0.939314    
&#96;FareGroup40+&#96;      0.11277    0.22144   0.509 0.610572    
TitleMiss          -6.75940  236.67998  -0.029 0.977216    
TitleMr            -1.55762    0.29962  -5.199 2.01e-07 ***
TitleMrs           -5.78595  204.63657  -0.028 0.977443    
TitleNoble         -0.46573    0.14315  -3.253 0.001140 ** 
&#96;Sexmale:Pclass2&#96;  -0.32045    0.29394  -1.090 0.275630    
&#96;Sexmale:Pclass3&#96;   0.65008    0.35598   1.826 0.067823 .  
---
Signif. codes:  0 *** 0.001 ** 0.01 * 0.05 . 0.1   1

(Dispersion parameter for binomial family taken to be 1)

    Null deviance: 950.86  on 713  degrees of freedom
Residual deviance: 576.85  on 697  degrees of freedom
AIC: 610.85

Number of Fisher Scoring iterations: 13


</pre>

</div>
</div>

</div>
</div>

</div>
<div class="text_cell_render border-box-sizing rendered_html">
<p>So we actually did <strong>much</strong> better. So lesson learnt, engineering new features is a great idea but may or may not positively impact your model. In fact, if we don't get it right, it could have an adverse impact. Let's see if we can make anymore tiny improvements with the Title. We have 4 possible values and I am going to class compress each.</p>
</div>
<div class="cell border-box-sizing code_cell vbox">
<div class="input hbox">
<div class="prompt input_prompt">
In&nbsp;[291]:
</div>
<div class="input_area box-flex1">
<div class="highlight"><pre><span class="o">%%</span><span class="k">R</span>
<span class="c">#Let&#39;s work in an interaction between Pclass and Sex.</span>
<span class="nb">set</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">35</span><span class="p">)</span> 

<span class="n">logit</span><span class="o">.</span><span class="n">tune5</span><span class="o">&lt;-</span><span class="n">train</span><span class="p">(</span><span class="n">Survived</span> <span class="o">~</span> <span class="n">Sex</span> <span class="o">+</span> <span class="n">Pclass</span> <span class="o">+</span> <span class="n">Sex</span><span class="p">:</span><span class="n">Pclass</span> <span class="o">+</span> <span class="n">Age</span> <span class="o">+</span> <span class="n">SibSp</span> <span class="o">+</span> <span class="n">Embarked</span> <span class="o">+</span> <span class="n">FareGroup</span> <span class="o">+</span> <span class="n">I</span><span class="p">(</span><span class="n">Title</span><span class="o">==</span><span class="s">&#39;Mr&#39;</span><span class="p">)</span> <span class="o">+</span>
                   <span class="n">I</span><span class="p">(</span><span class="n">Title</span><span class="o">==</span><span class="s">&#39;Mrs&#39;</span><span class="p">)</span> <span class="o">+</span> <span class="n">I</span><span class="p">(</span><span class="n">Title</span><span class="o">==</span><span class="s">&#39;Miss&#39;</span><span class="p">)</span> <span class="o">+</span> <span class="n">I</span><span class="p">(</span><span class="n">Title</span><span class="o">==</span><span class="s">&#39;Noble&#39;</span><span class="p">),</span>
                <span class="n">data</span><span class="o">=</span><span class="n">train</span><span class="o">.</span><span class="n">set</span><span class="p">,</span>
                <span class="n">method</span><span class="o">=</span><span class="s">&#39;glm&#39;</span><span class="p">,</span>
                <span class="n">preProcess</span> <span class="o">=</span> <span class="n">c</span><span class="p">(</span><span class="s">&quot;center&quot;</span><span class="p">,</span> <span class="s">&quot;scale&quot;</span><span class="p">),</span>
                <span class="n">trControl</span><span class="o">=</span><span class="n">tenfoldcv</span><span class="p">)</span>

<span class="n">logit</span><span class="o">.</span><span class="n">tune5</span>
</pre></div>

</div>
</div>

<div class="vbox output_wrapper">
<div class="output vbox">


<div class="hbox output_area"><div class="prompt"></div>
<div class="box-flex1 output_subarea output_display_data">


<pre>
Generalized Linear Model 

714 samples
 14 predictors
  2 classes: &apos;0&apos;, &apos;1&apos; 

Pre-processing: centered, scaled 
Resampling: Cross-Validated (10 fold, repeated 3 times) 

Summary of sample sizes: 643, 643, 643, 642, 643, 643, ... 

Resampling results

  Accuracy   Kappa      Accuracy SD  Kappa SD  
  0.8123305  0.5934912  0.04130739   0.09243173

 

</pre>

</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell vbox">
<div class="input hbox">
<div class="prompt input_prompt">
In&nbsp;[292]:
</div>
<div class="input_area box-flex1">
<div class="highlight"><pre><span class="o">%%</span><span class="k">R</span>
<span class="n">summary</span><span class="p">(</span><span class="n">logit</span><span class="o">.</span><span class="n">tune5</span><span class="p">)</span>
</pre></div>

</div>
</div>

<div class="vbox output_wrapper">
<div class="output vbox">


<div class="hbox output_area"><div class="prompt"></div>
<div class="box-flex1 output_subarea output_display_data">


<pre>

Call:
NULL

Deviance Residuals: 
    Min       1Q   Median       3Q      Max  
-2.6591  -0.5397  -0.4099   0.3937   2.4194  

Coefficients:
                           Estimate Std. Error z value Pr(&gt;|z|)    
(Intercept)                -0.56336    0.12309  -4.577 4.72e-06 ***
Sexmale                    -8.13159  278.33333  -0.029 0.976693    
Pclass2                    -0.36485    0.33842  -1.078 0.280987    
Pclass3                    -1.62269    0.37865  -4.285 1.82e-05 ***
Age                        -0.30128    0.13506  -2.231 0.025693 *  
SibSp                      -0.62972    0.17467  -3.605 0.000312 ***
EmbarkedQ                   0.04973    0.11805   0.421 0.673568    
EmbarkedS                  -0.17619    0.12541  -1.405 0.160047    
&#96;FareGroup10-20&#96;            0.07364    0.14908   0.494 0.621326    
&#96;FareGroup20-40&#96;           -0.01342    0.17629  -0.076 0.939314    
&#96;FareGroup40+&#96;              0.11277    0.22144   0.509 0.610572    
&#96;I(Title == &quot;Mr&quot;)TRUE&#96;     -1.55762    0.29962  -5.199 2.01e-07 ***
&#96;I(Title == &quot;Mrs&quot;)TRUE&#96;    -5.78595  204.63657  -0.028 0.977443    
&#96;I(Title == &quot;Miss&quot;)TRUE&#96;   -6.75940  236.67998  -0.029 0.977216    
&#96;I(Title == &quot;Noble&quot;)TRUE&#96;  -0.46573    0.14315  -3.253 0.001140 ** 
&#96;Sexmale:Pclass2&#96;          -0.32045    0.29394  -1.090 0.275630    
&#96;Sexmale:Pclass3&#96;           0.65008    0.35598   1.826 0.067823 .  
---
Signif. codes:  0 *** 0.001 ** 0.01 * 0.05 . 0.1   1

(Dispersion parameter for binomial family taken to be 1)

    Null deviance: 950.86  on 713  degrees of freedom
Residual deviance: 576.85  on 697  degrees of freedom
AIC: 610.85

Number of Fisher Scoring iterations: 13


</pre>

</div>
</div>

</div>
</div>

</div>
<div class="text_cell_render border-box-sizing rendered_html">
<p>Hmm, didn't really make a difference. Let's try one last thing, adding Child, which we derived during the feature engineering exercise.</p>
</div>
<div class="cell border-box-sizing code_cell vbox">
<div class="input hbox">
<div class="prompt input_prompt">
In&nbsp;[120]:
</div>
<div class="input_area box-flex1">
<div class="highlight"><pre><span class="o">%%</span><span class="k">R</span>
<span class="c">#Let&#39;s add Child to the mix.</span>
<span class="nb">set</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">35</span><span class="p">)</span> 

<span class="n">logit</span><span class="o">.</span><span class="n">tune6</span><span class="o">&lt;-</span><span class="n">train</span><span class="p">(</span><span class="n">Survived</span> <span class="o">~</span> <span class="n">Sex</span> <span class="o">+</span> <span class="n">Pclass</span> <span class="o">+</span> <span class="n">Sex</span><span class="p">:</span><span class="n">Pclass</span> <span class="o">+</span> <span class="n">Age</span> <span class="o">+</span> <span class="n">SibSp</span> <span class="o">+</span> <span class="n">Embarked</span> <span class="o">+</span> <span class="n">FareGroup</span> <span class="o">+</span> <span class="n">Title</span> <span class="o">+</span> <span class="n">Child</span><span class="p">,</span>
                <span class="n">data</span><span class="o">=</span><span class="n">train</span><span class="o">.</span><span class="n">set</span><span class="p">,</span>
                <span class="n">method</span><span class="o">=</span><span class="s">&#39;glm&#39;</span><span class="p">,</span>
                <span class="n">preProcess</span> <span class="o">=</span> <span class="n">c</span><span class="p">(</span><span class="s">&quot;center&quot;</span><span class="p">,</span> <span class="s">&quot;scale&quot;</span><span class="p">),</span>
                <span class="n">trControl</span><span class="o">=</span><span class="n">tenfoldcv</span><span class="p">)</span>

<span class="n">logit</span><span class="o">.</span><span class="n">tune6</span>
</pre></div>

</div>
</div>

<div class="vbox output_wrapper">
<div class="output vbox">


<div class="hbox output_area"><div class="prompt"></div>
<div class="box-flex1 output_subarea output_display_data">


<pre>
Generalized Linear Model 

714 samples
 14 predictors
  2 classes: &apos;0&apos;, &apos;1&apos; 

Pre-processing: centered, scaled 
Resampling: Cross-Validated (10 fold, repeated 3 times) 

Summary of sample sizes: 643, 643, 643, 642, 643, 643, ... 

Resampling results

  Accuracy   Kappa      Accuracy SD  Kappa SD
  0.8144806  0.5969237  0.04436537   0.101153

 

</pre>

</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell vbox">
<div class="input hbox">
<div class="prompt input_prompt">
In&nbsp;[294]:
</div>
<div class="input_area box-flex1">
<div class="highlight"><pre><span class="o">%%</span><span class="k">R</span>
<span class="n">summary</span><span class="p">(</span><span class="n">logit</span><span class="o">.</span><span class="n">tune6</span><span class="p">)</span>
</pre></div>

</div>
</div>

<div class="vbox output_wrapper">
<div class="output vbox">


<div class="hbox output_area"><div class="prompt"></div>
<div class="box-flex1 output_subarea output_display_data">


<pre>

Call:
NULL

Deviance Residuals: 
    Min       1Q   Median       3Q      Max  
-2.7285  -0.5465  -0.4164   0.4031   2.4338  

Coefficients:
                   Estimate Std. Error z value Pr(&gt;|z|)    
(Intercept)        -0.56186    0.12306  -4.566 4.98e-06 ***
Sexmale            -8.16008  276.99294  -0.029 0.976498    
Pclass2            -0.36500    0.33876  -1.077 0.281271    
Pclass3            -1.62927    0.37881  -4.301 1.70e-05 ***
Age                -0.25715    0.14521  -1.771 0.076581 .  
SibSp              -0.64181    0.17585  -3.650 0.000262 ***
EmbarkedQ           0.05690    0.11859   0.480 0.631327    
EmbarkedS          -0.17477    0.12575  -1.390 0.164569    
&#96;FareGroup10-20&#96;    0.05529    0.15150   0.365 0.715165    
&#96;FareGroup20-40&#96;   -0.03809    0.17965  -0.212 0.832083    
&#96;FareGroup40+&#96;      0.09460    0.22321   0.424 0.671714    
TitleMiss          -6.73181  235.54018  -0.029 0.977199    
TitleMr            -1.47297    0.31722  -4.643 3.43e-06 ***
TitleMrs           -5.73725  203.65108  -0.028 0.977525    
TitleNoble         -0.44396    0.14534  -3.055 0.002254 ** 
Child               0.11549    0.14579   0.792 0.428237    
&#96;Sexmale:Pclass2&#96;  -0.31971    0.29422  -1.087 0.277200    
&#96;Sexmale:Pclass3&#96;   0.64601    0.35560   1.817 0.069267 .  
---
Signif. codes:  0 *** 0.001 ** 0.01 * 0.05 . 0.1   1

(Dispersion parameter for binomial family taken to be 1)

    Null deviance: 950.86  on 713  degrees of freedom
Residual deviance: 576.23  on 696  degrees of freedom
AIC: 612.23

Number of Fisher Scoring iterations: 13


</pre>

</div>
</div>

</div>
</div>

</div>
<div class="text_cell_render border-box-sizing rendered_html">
<p>So we got that tiny push we were looking for. Let's now go ahead and try this model on our test set as well as submit to Kaggle.</p>
<p><strong>Model Evaluation - Logistic Regression</strong><br />We can now begin to evaluate model performance by putting together some cross-tabulations of the observed and predicted Survival for the passengers in the test.set data. caret makes this easy with the confusionMatrix function.</p>
</div>
<div class="cell border-box-sizing code_cell vbox">
<div class="input hbox">
<div class="prompt input_prompt">
In&nbsp;[295]:
</div>
<div class="input_area box-flex1">
<div class="highlight"><pre><span class="o">%%</span><span class="k">R</span>
<span class="c">#Derive predictions using our final LR model on the test set (this is NOT the test.csv file from Kaggle)</span>
<span class="n">logit</span><span class="o">.</span><span class="n">pred</span><span class="o">&lt;-</span><span class="n">predict</span><span class="p">(</span><span class="n">logit</span><span class="o">.</span><span class="n">tune6</span><span class="p">,</span> <span class="n">test</span><span class="o">.</span><span class="n">set</span><span class="p">)</span>

<span class="c">#Generate the confusion matrix</span>
<span class="n">confusionMatrix</span><span class="p">(</span><span class="n">logit</span><span class="o">.</span><span class="n">pred</span><span class="p">,</span> <span class="n">test</span><span class="o">.</span><span class="n">set</span><span class="err">$</span><span class="n">Survived</span><span class="p">)</span>
</pre></div>

</div>
</div>

<div class="vbox output_wrapper">
<div class="output vbox">


<div class="hbox output_area"><div class="prompt"></div>
<div class="box-flex1 output_subarea output_display_data">


<pre>
Confusion Matrix and Statistics

          Reference
Prediction  0  1
         0 99 18
         1 10 50
                                          
               Accuracy : 0.8418          
                 95% CI : (0.7795, 0.8922)
    No Information Rate : 0.6158          
    P-Value [Acc &gt; NIR] : 4.229e-11       
                                          
                  Kappa : 0.6581          
 Mcnemar&apos;s Test P-Value : 0.1859          
                                          
            Sensitivity : 0.9083          
            Specificity : 0.7353          
         Pos Pred Value : 0.8462          
         Neg Pred Value : 0.8333          
             Prevalence : 0.6158          
         Detection Rate : 0.5593          
   Detection Prevalence : 0.6610          
      Balanced Accuracy : 0.8218          
                                          
       &apos;Positive&apos; Class : 0               
                                          

</pre>

</div>
</div>

</div>
</div>

</div>
<div class="text_cell_render border-box-sizing rendered_html">
<p>The metric we're looking for here is called Specificity. It basically is, out of all that actually survived how many we predicted will survive. So, it's 50/68 = 73.53%. Not too shabby though I'd like to do better. Let's anyway try to make a submission and find out for real.</p>
<p><strong>Submit Results to Kaggle</strong><br />Let's now submit the results from the LR model to Kaggle to see how we fare.</p>
</div>
<div class="cell border-box-sizing code_cell vbox">
<div class="input hbox">
<div class="prompt input_prompt">
In&nbsp;[356]:
</div>
<div class="input_area box-flex1">
<div class="highlight"><pre><span class="o">%%</span><span class="k">R</span>
<span class="c">#Generate predictions and write as a dataframe, then include PassengerID</span>
<span class="n">Survived</span><span class="o">&lt;-</span><span class="n">predict</span><span class="p">(</span><span class="n">logit</span><span class="o">.</span><span class="n">tune6</span><span class="p">,</span> <span class="n">kaggletest</span><span class="p">)</span>
<span class="n">lr</span><span class="o">.</span><span class="n">predictions</span><span class="o">&lt;-</span><span class="k">as</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">frame</span><span class="p">(</span><span class="n">Survived</span><span class="p">)</span>
<span class="n">lr</span><span class="o">.</span><span class="n">predictions</span><span class="err">$</span><span class="n">PassengerId</span><span class="o">&lt;-</span><span class="n">kaggletest</span><span class="err">$</span><span class="n">PassengerId</span>

<span class="c">#Write results as a CSV file</span>
<span class="n">write</span><span class="o">.</span><span class="n">csv</span><span class="p">(</span><span class="n">lr</span><span class="o">.</span><span class="n">predictions</span><span class="p">[,</span><span class="n">c</span><span class="p">(</span><span class="s">&#39;PassengerId&#39;</span><span class="p">,</span><span class="s">&#39;Survived&#39;</span><span class="p">)],</span> <span class="nb">file</span><span class="o">=</span><span class="s">&quot;LR_Titanic_Predictions.csv&quot;</span><span class="p">,</span> <span class="n">row</span><span class="o">.</span><span class="n">names</span><span class="o">=</span><span class="n">FALSE</span><span class="p">,</span> <span class="n">quote</span><span class="o">=</span><span class="n">FALSE</span><span class="p">)</span>
</pre></div>

</div>
</div>

</div>
<div class="text_cell_render border-box-sizing rendered_html">
<p>The model scored <strong>0.76555</strong> which put us ahead of only about 1/4th of the teams on the leaderboard. Let us keep trying to improve.</p>
</div>
<div class="text_cell_render border-box-sizing rendered_html">
<p><strong>Support Vector Machines</strong><br />Support Vector Machines (SVMs) are a powerful supervised learning algorithm used for classification or for regression. SVMs are a discriminative classifier: that is, they draw a boundary between clusters of data. The process of fitting an SVM based model to our dataset is very similar to what we just did with glm but involves an additional step to hypertune parameters. The key parameter for SVM is C, which can be considered as 1/lambda where lambda is the regularization term. We talked about overfitting previously, regularization is the process of offsetting it. If there is overfitting, we would increase lambda, so conversely decrease C.</p>
<p>The caret package automatically selects the best C value by hypertuning it during crossvalidation. But we need to supply a range of C values for the train method to try. For SVMs, this could be handled by updating the parameter, tunelength (or tunegrid). By default, the length is 3 and the values tried are 0.25, 0.5 and 1. Setting it to 6 would try 0.25 - 8. Let's get started.</p>
</div>
<div class="cell border-box-sizing code_cell vbox">
<div class="input hbox">
<div class="prompt input_prompt">
In&nbsp;[124]:
</div>
<div class="input_area box-flex1">
<div class="highlight"><pre><span class="o">%%</span><span class="k">R</span>
<span class="nb">set</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">35</span><span class="p">)</span> 

<span class="c">#Training an SVM model with the RBF kernel - Radial Basis Function</span>
<span class="n">svm</span><span class="o">.</span><span class="n">tune1</span><span class="o">&lt;-</span><span class="n">train</span><span class="p">(</span><span class="n">Survived</span> <span class="o">~</span> <span class="n">Sex</span> <span class="o">+</span> <span class="n">Pclass</span> <span class="o">+</span>  <span class="n">Sex</span><span class="p">:</span><span class="n">Pclass</span> <span class="o">+</span> <span class="n">Age</span> <span class="o">+</span> <span class="n">SibSp</span> <span class="o">+</span> <span class="n">Embarked</span> <span class="o">+</span> <span class="n">FareGroup</span> <span class="o">+</span> <span class="n">Title</span> <span class="o">+</span> <span class="n">Child</span><span class="p">,</span>
                <span class="n">data</span><span class="o">=</span><span class="n">train</span><span class="o">.</span><span class="n">set</span><span class="p">,</span>
                <span class="n">method</span><span class="o">=</span><span class="s">&#39;svmRadial&#39;</span><span class="p">,</span>
                <span class="n">tuneLength</span><span class="o">=</span><span class="mi">9</span><span class="p">,</span>
                <span class="n">preProcess</span> <span class="o">=</span> <span class="n">c</span><span class="p">(</span><span class="s">&quot;center&quot;</span><span class="p">,</span> <span class="s">&quot;scale&quot;</span><span class="p">),</span>
                <span class="n">trControl</span><span class="o">=</span><span class="n">tenfoldcv</span><span class="p">)</span>

<span class="n">svm</span><span class="o">.</span><span class="n">tune1</span>
</pre></div>

</div>
</div>

<div class="vbox output_wrapper">
<div class="output vbox">


<div class="hbox output_area"><div class="prompt"></div>
<div class="box-flex1 output_subarea output_display_data">


<pre>
Support Vector Machines with Radial Basis Function Kernel 

714 samples
 14 predictors
  2 classes: &apos;0&apos;, &apos;1&apos; 

Pre-processing: centered, scaled 
Resampling: Cross-Validated (10 fold, repeated 3 times) 

Summary of sample sizes: 643, 643, 643, 642, 643, 643, ... 

Resampling results across tuning parameters:

  C      Accuracy   Kappa      Accuracy SD  Kappa SD 
   0.25  0.8049426  0.5722555  0.05162691   0.1132959
   0.50  0.8117884  0.5843046  0.05585971   0.1259916
   1.00  0.8226591  0.6100882  0.05152085   0.1165301
   2.00  0.8249804  0.6164518  0.05146277   0.1156968
   4.00  0.8160650  0.5986011  0.05477380   0.1213830
   8.00  0.8131307  0.5934170  0.04906936   0.1095503
  16.00  0.8131172  0.5940660  0.05068143   0.1116418
  32.00  0.8150599  0.5995714  0.05261309   0.1151817
  64.00  0.8092588  0.5876340  0.05748809   0.1249829

Tuning parameter &apos;sigma&apos; was held constant at a value of 0.07616343
Accuracy was used to select the optimal model using  the largest value.
The final values used for the model were sigma = 0.07616343 and C = 2. 

</pre>

</div>
</div>

</div>
</div>

</div>
<div class="text_cell_render border-box-sizing rendered_html">
<p>Great, so SVM automatically tried 9 different values of C while holding the other parameter Sigma constant and picked the values that gave the best results. We really didn't have to do much there. Let's go ahead and evaluate the model as well as submit to Kaggle.</p>
<p><strong>Model Evaluation - SVM</strong></p>
</div>
<div class="cell border-box-sizing code_cell vbox">
<div class="input hbox">
<div class="prompt input_prompt">
In&nbsp;[312]:
</div>
<div class="input_area box-flex1">
<div class="highlight"><pre><span class="o">%%</span><span class="k">R</span>
<span class="c">#Derive predictions using our final LR model on the test set (this is NOT the test.csv file from Kaggle)</span>
<span class="n">svm</span><span class="o">.</span><span class="n">pred</span><span class="o">&lt;-</span><span class="n">predict</span><span class="p">(</span><span class="n">svm</span><span class="o">.</span><span class="n">tune1</span><span class="p">,</span> <span class="n">test</span><span class="o">.</span><span class="n">set</span><span class="p">)</span>

<span class="c">#Generate the confusion matrix</span>
<span class="n">confusionMatrix</span><span class="p">(</span><span class="n">svm</span><span class="o">.</span><span class="n">pred</span><span class="p">,</span> <span class="n">test</span><span class="o">.</span><span class="n">set</span><span class="err">$</span><span class="n">Survived</span><span class="p">)</span>
</pre></div>

</div>
</div>

<div class="vbox output_wrapper">
<div class="output vbox">


<div class="hbox output_area"><div class="prompt"></div>
<div class="box-flex1 output_subarea output_display_data">


<pre>
Confusion Matrix and Statistics

          Reference
Prediction   0   1
         0 100  20
         1   9  48
                                          
               Accuracy : 0.8362          
                 95% CI : (0.7732, 0.8874)
    No Information Rate : 0.6158          
    P-Value [Acc &gt; NIR] : 1.38e-10        
                                          
                  Kappa : 0.6429          
 Mcnemar&apos;s Test P-Value : 0.06332         
                                          
            Sensitivity : 0.9174          
            Specificity : 0.7059          
         Pos Pred Value : 0.8333          
         Neg Pred Value : 0.8421          
             Prevalence : 0.6158          
         Detection Rate : 0.5650          
   Detection Prevalence : 0.6780          
      Balanced Accuracy : 0.8117          
                                          
       &apos;Positive&apos; Class : 0               
                                          

</pre>

</div>
</div>

</div>
</div>

</div>
<div class="text_cell_render border-box-sizing rendered_html">
<p>The specificity is actually a bit down from the LR model, we're at 70%. Other than that eveyrthing looks pretty similar. I also just discovered that a Support Vector Machine automatically captures interaction between variables. So the Pclass:Sex interaction we put in has no importance to this model. We'll remove it going forward since Random Forests also automatically identifies interactions.</p>
<p><strong>Submit to Kaggle</strong></p>
</div>
<div class="cell border-box-sizing code_cell vbox">
<div class="input hbox">
<div class="prompt input_prompt">
In&nbsp;[355]:
</div>
<div class="input_area box-flex1">
<div class="highlight"><pre><span class="o">%%</span><span class="k">R</span>
<span class="c">#Generate predictions and write as a dataframe, then include PassengerID</span>
<span class="n">Survived</span><span class="o">&lt;-</span><span class="n">predict</span><span class="p">(</span><span class="n">svm</span><span class="o">.</span><span class="n">tune1</span><span class="p">,</span> <span class="n">kaggletest</span><span class="p">)</span>
<span class="n">svm</span><span class="o">.</span><span class="n">predictions</span><span class="o">&lt;-</span><span class="k">as</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">frame</span><span class="p">(</span><span class="n">Survived</span><span class="p">)</span>
<span class="n">svm</span><span class="o">.</span><span class="n">predictions</span><span class="err">$</span><span class="n">PassengerId</span><span class="o">&lt;-</span><span class="n">kaggletest</span><span class="err">$</span><span class="n">PassengerId</span>

<span class="c">#Write results as a CSV file</span>
<span class="n">write</span><span class="o">.</span><span class="n">csv</span><span class="p">(</span><span class="n">svm</span><span class="o">.</span><span class="n">predictions</span><span class="p">[,</span><span class="n">c</span><span class="p">(</span><span class="s">&#39;PassengerId&#39;</span><span class="p">,</span><span class="s">&#39;Survived&#39;</span><span class="p">)],</span> <span class="nb">file</span><span class="o">=</span><span class="s">&quot;SVM_Titanic_Predictions.csv&quot;</span><span class="p">,</span> <span class="n">row</span><span class="o">.</span><span class="n">names</span><span class="o">=</span><span class="n">FALSE</span><span class="p">,</span> <span class="n">quote</span><span class="o">=</span><span class="n">FALSE</span><span class="p">)</span>
</pre></div>

</div>
</div>

</div>
<div class="text_cell_render border-box-sizing rendered_html">
<p>We scored <strong>0.77512</strong>, an improvement over the Logistic Regression model that took us up the leaderboard a few notches. We're not going to let this go!</p>
</div>
<div class="text_cell_render border-box-sizing rendered_html">
<p><strong>Random Forests</strong><br />Next up, a very popular and easy to use model, Random Forests. RF builds on the concept of decision trees and expands it by growing multiple trees and averaging out the results to find the best fit. The parameter we need to tune is mtry, that number of features to try at each node. The best recommended value for this parameter is typically the square root of the number of features. Let's give this a shot.</p>
</div>
<div class="cell border-box-sizing code_cell vbox">
<div class="input hbox">
<div class="prompt input_prompt">
In&nbsp;[365]:
</div>
<div class="input_area box-flex1">
<div class="highlight"><pre><span class="o">%%</span><span class="k">R</span>
<span class="nb">set</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">35</span><span class="p">)</span> 

<span class="n">rfgrid</span><span class="o">&lt;-</span><span class="n">data</span><span class="o">.</span><span class="n">frame</span><span class="p">(</span><span class="o">.</span><span class="n">mtry</span><span class="o">=</span><span class="n">c</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">4</span><span class="p">))</span>

<span class="c">#Training a Random Forest model</span>
<span class="n">rf</span><span class="o">.</span><span class="n">tune1</span><span class="o">&lt;-</span><span class="n">train</span><span class="p">(</span><span class="n">Survived</span> <span class="o">~</span> <span class="n">Sex</span> <span class="o">+</span> <span class="n">Pclass</span> <span class="o">+</span> <span class="n">Age</span> <span class="o">+</span> <span class="n">SibSp</span> <span class="o">+</span> <span class="n">Embarked</span> <span class="o">+</span> <span class="n">FareGroup</span> <span class="o">+</span> <span class="n">Title</span> <span class="o">+</span> <span class="n">Child</span><span class="p">,</span>
                <span class="n">data</span><span class="o">=</span><span class="n">train</span><span class="o">.</span><span class="n">set</span><span class="p">,</span>
                <span class="n">method</span><span class="o">=</span><span class="s">&#39;rf&#39;</span><span class="p">,</span>
                <span class="n">tuneGrid</span><span class="o">=</span><span class="n">rfgrid</span><span class="p">,</span>
                <span class="n">trControl</span><span class="o">=</span><span class="n">tenfoldcv</span><span class="p">)</span>

<span class="n">rf</span><span class="o">.</span><span class="n">tune1</span>
</pre></div>

</div>
</div>

<div class="vbox output_wrapper">
<div class="output vbox">


<div class="hbox output_area"><div class="prompt"></div>
<div class="box-flex1 output_subarea output_display_data">


<pre>
Random Forest 

714 samples
 14 predictors
  2 classes: &apos;0&apos;, &apos;1&apos; 

No pre-processing
Resampling: Cross-Validated (10 fold, repeated 3 times) 

Summary of sample sizes: 643, 643, 643, 642, 643, 643, ... 

Resampling results across tuning parameters:

  mtry  Accuracy   Kappa      Accuracy SD  Kappa SD 
  2     0.8096114  0.5868040  0.05614486   0.1231515
  3     0.8120599  0.5869056  0.05485173   0.1228654
  4     0.8151139  0.5951016  0.05099510   0.1145908

Accuracy was used to select the optimal model using  the largest value.
The final value used for the model was mtry = 4. 

</pre>

</div>
</div>

</div>
</div>

</div>
<div class="text_cell_render border-box-sizing rendered_html">
<p>Looks like the best mtry value found was 4. Let's complete the formalities.</p>
<p><strong>Model Evaluation - Random Forests</strong></p>
</div>
<div class="cell border-box-sizing code_cell vbox">
<div class="input hbox">
<div class="prompt input_prompt">
In&nbsp;[353]:
</div>
<div class="input_area box-flex1">
<div class="highlight"><pre><span class="o">%%</span><span class="k">R</span>
<span class="c">#Derive predictions using our final LR model on the test set (this is NOT the test.csv file from Kaggle)</span>
<span class="n">rf</span><span class="o">.</span><span class="n">pred</span><span class="o">&lt;-</span><span class="n">predict</span><span class="p">(</span><span class="n">rf</span><span class="o">.</span><span class="n">tune1</span><span class="p">,</span> <span class="n">test</span><span class="o">.</span><span class="n">set</span><span class="p">)</span>

<span class="c">#Generate the confusion matrix</span>
<span class="n">confusionMatrix</span><span class="p">(</span><span class="n">rf</span><span class="o">.</span><span class="n">pred</span><span class="p">,</span> <span class="n">test</span><span class="o">.</span><span class="n">set</span><span class="err">$</span><span class="n">Survived</span><span class="p">)</span>
</pre></div>

</div>
</div>

<div class="vbox output_wrapper">
<div class="output vbox">


<div class="hbox output_area"><div class="prompt"></div>
<div class="box-flex1 output_subarea output_display_data">


<pre>
Confusion Matrix and Statistics

          Reference
Prediction   0   1
         0 101  20
         1   8  48
                                          
               Accuracy : 0.8418          
                 95% CI : (0.7795, 0.8922)
    No Information Rate : 0.6158          
    P-Value [Acc &gt; NIR] : 4.229e-11       
                                          
                  Kappa : 0.6542          
 Mcnemar&apos;s Test P-Value : 0.03764         
                                          
            Sensitivity : 0.9266          
            Specificity : 0.7059          
         Pos Pred Value : 0.8347          
         Neg Pred Value : 0.8571          
             Prevalence : 0.6158          
         Detection Rate : 0.5706          
   Detection Prevalence : 0.6836          
      Balanced Accuracy : 0.8162          
                                          
       &apos;Positive&apos; Class : 0               
                                          

</pre>

</div>
</div>

</div>
</div>

</div>
<div class="text_cell_render border-box-sizing rendered_html">
<p>Well, the specificity is exactly the same, at 70%. I doubt this is going to give us a different result with Kaggle but let's try anyway.</p>
<p><strong>Submit to Kaggle</strong></p>
</div>
<div class="cell border-box-sizing code_cell vbox">
<div class="input hbox">
<div class="prompt input_prompt">
In&nbsp;[357]:
</div>
<div class="input_area box-flex1">
<div class="highlight"><pre><span class="o">%%</span><span class="k">R</span>
<span class="c">#Generate predictions and write as a dataframe, then include PassengerID</span>
<span class="n">Survived</span><span class="o">&lt;-</span><span class="n">predict</span><span class="p">(</span><span class="n">rf</span><span class="o">.</span><span class="n">tune1</span><span class="p">,</span> <span class="n">kaggletest</span><span class="p">)</span>
<span class="n">rf</span><span class="o">.</span><span class="n">predictions</span><span class="o">&lt;-</span><span class="k">as</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">frame</span><span class="p">(</span><span class="n">Survived</span><span class="p">)</span>
<span class="n">rf</span><span class="o">.</span><span class="n">predictions</span><span class="err">$</span><span class="n">PassengerId</span><span class="o">&lt;-</span><span class="n">kaggletest</span><span class="err">$</span><span class="n">PassengerId</span>

<span class="c">#Write results as a CSV file</span>
<span class="n">write</span><span class="o">.</span><span class="n">csv</span><span class="p">(</span><span class="n">rf</span><span class="o">.</span><span class="n">predictions</span><span class="p">[,</span><span class="n">c</span><span class="p">(</span><span class="s">&#39;PassengerId&#39;</span><span class="p">,</span><span class="s">&#39;Survived&#39;</span><span class="p">)],</span> <span class="nb">file</span><span class="o">=</span><span class="s">&quot;RF_Titanic_Predictions.csv&quot;</span><span class="p">,</span> <span class="n">row</span><span class="o">.</span><span class="n">names</span><span class="o">=</span><span class="n">FALSE</span><span class="p">,</span> <span class="n">quote</span><span class="o">=</span><span class="n">FALSE</span><span class="p">)</span>
</pre></div>

</div>
</div>

</div>
<div class="text_cell_render border-box-sizing rendered_html">
<p>Surprise, we scored <strong>0.78469</strong> bringing us midway on the leaderboard. So we're definitely making headway!</p>
<p><strong>Feature Importances</strong><br />Before we move ahead let's look at a key statistic that comes from running a tree based model. It's called feature importances, which tells us how much of an impact each of the features we're feeding to the model has to the final outcome.</p>
</div>
<div class="cell border-box-sizing code_cell vbox">
<div class="input hbox">
<div class="prompt input_prompt">
In&nbsp;[370]:
</div>
<div class="input_area box-flex1">
<div class="highlight"><pre><span class="o">%%</span><span class="k">R</span>
<span class="c">#Print variable importan</span>
<span class="n">varImp</span><span class="p">(</span><span class="n">rf</span><span class="o">.</span><span class="n">tune1</span><span class="err">$</span><span class="n">finalModel</span><span class="p">)</span>
</pre></div>

</div>
</div>

<div class="vbox output_wrapper">
<div class="output vbox">


<div class="hbox output_area"><div class="prompt"></div>
<div class="box-flex1 output_subarea output_display_data">


<pre>
                 Overall
Sexmale        41.576129
Pclass2         6.801074
Pclass3        21.558667
Age            36.931313
SibSp          15.046491
EmbarkedQ       2.972848
EmbarkedS       6.683872
FareGroup10-20  3.980921
FareGroup20-40  6.418674
FareGroup40+   10.203688
TitleMiss      11.145308
TitleMr        36.630889
TitleMrs       10.509372
TitleNoble      2.862573
Child           4.153887

</pre>

</div>
</div>

</div>
</div>

</div>
<div class="text_cell_render border-box-sizing rendered_html">
<p>That's very interesting. We always knew that Gender was the most important variable. Sexmale by the way shows up there because it's the class that suffered the most. We see here that Age and &quot;Mr.&quot; Title take the second spot. That is a revelation of sorts. SibSp also seems quite important compared to say Embarked.</p>
<p>Before we move ahead with other models, I am really curious to try a few more things out with RF. I would like to measure the impact of adding a couple of features we've left out, Family Size and Parch and see how they pan out in terms of importance. Offline I tried adding FamID and it again created a negative impact so I am leaving it out for good</p>
</div>
<div class="cell border-box-sizing code_cell vbox">
<div class="input hbox">
<div class="prompt input_prompt">
In&nbsp;[41]:
</div>
<div class="input_area box-flex1">
<div class="highlight"><pre><span class="o">%%</span><span class="k">R</span>
<span class="nb">set</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">35</span><span class="p">)</span> 

<span class="c">#Notice how we&#39;re trying out 2-5 features at each node now since we&#39;re adding a couple of features to train.</span>
<span class="n">rfgrid</span><span class="o">&lt;-</span><span class="n">data</span><span class="o">.</span><span class="n">frame</span><span class="p">(</span><span class="o">.</span><span class="n">mtry</span><span class="o">=</span><span class="n">c</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">4</span><span class="p">,</span><span class="mi">5</span><span class="p">))</span>

<span class="c">#Training a Random Forest model</span>
<span class="n">rf</span><span class="o">.</span><span class="n">tune2</span><span class="o">&lt;-</span><span class="n">train</span><span class="p">(</span><span class="n">Survived</span> <span class="o">~</span> <span class="n">Sex</span> <span class="o">+</span> <span class="n">Pclass</span> <span class="o">+</span> <span class="n">Age</span> <span class="o">+</span> <span class="n">SibSp</span> <span class="o">+</span> <span class="n">Embarked</span> <span class="o">+</span> <span class="n">FareGroup</span> <span class="o">+</span> <span class="n">Title</span> <span class="o">+</span> <span class="n">Child</span> <span class="o">+</span> <span class="n">FamSize</span> <span class="o">+</span> <span class="n">Parch</span><span class="p">,</span>
                <span class="n">data</span><span class="o">=</span><span class="n">train</span><span class="o">.</span><span class="n">set</span><span class="p">,</span>
                <span class="n">method</span><span class="o">=</span><span class="s">&#39;rf&#39;</span><span class="p">,</span>
                <span class="n">tuneGrid</span><span class="o">=</span><span class="n">rfgrid</span><span class="p">,</span>
                <span class="n">trControl</span><span class="o">=</span><span class="n">tenfoldcv</span><span class="p">)</span>

<span class="n">rf</span><span class="o">.</span><span class="n">tune2</span>
</pre></div>

</div>
</div>

<div class="vbox output_wrapper">
<div class="output vbox">


<div class="hbox output_area"><div class="prompt"></div>
<div class="box-flex1 output_subarea output_display_data">


<pre>
Random Forest 

714 samples
 14 predictors
  2 classes: &apos;0&apos;, &apos;1&apos; 

No pre-processing
Resampling: Cross-Validated (10 fold, repeated 3 times) 

Summary of sample sizes: 643, 643, 643, 642, 643, 643, ... 

Resampling results across tuning parameters:

  mtry  Accuracy   Kappa      Accuracy SD  Kappa SD  
  2     0.8161450  0.6018844  0.05130416   0.11229173
  3     0.8114502  0.5872835  0.05293296   0.11855522
  4     0.8133020  0.5920896  0.04751211   0.10699385
  5     0.8221049  0.6147302  0.04405445   0.09805046

Accuracy was used to select the optimal model using  the largest value.
The final value used for the model was mtry = 5. 

</pre>

</div>
</div>

</div>
</div>

</div>
<div class="text_cell_render border-box-sizing rendered_html">
<p>As expected, the best mtry value this time was 5. Let's look at the feature importances.</p>
</div>
<div class="cell border-box-sizing code_cell vbox">
<div class="input hbox">
<div class="prompt input_prompt">
In&nbsp;[73]:
</div>
<div class="input_area box-flex1">
<div class="highlight"><pre><span class="o">%%</span><span class="k">R</span>
<span class="n">varImp</span><span class="p">(</span><span class="n">rf</span><span class="o">.</span><span class="n">tune2</span><span class="err">$</span><span class="n">finalModel</span><span class="p">)</span>
</pre></div>

</div>
</div>

<div class="vbox output_wrapper">
<div class="output vbox">


<div class="hbox output_area"><div class="prompt"></div>
<div class="box-flex1 output_subarea output_display_data">


<pre>
                 Overall
Sexmale        43.453469
Pclass2         6.453174
Pclass3        19.967399
Age            42.531124
SibSp          10.604394
EmbarkedQ       2.998889
EmbarkedS       6.815784
FareGroup10-20  4.111547
FareGroup20-40  6.365776
FareGroup40+    9.403774
TitleMiss      10.173660
TitleMr        38.239391
TitleMrs        8.937783
TitleNoble      2.831949
Child           3.719191
FamSize        19.145703
Parch           7.960594

</pre>

</div>
</div>

</div>
</div>

</div>
<div class="text_cell_render border-box-sizing rendered_html">
<p>So it worked out well. Parch and especially FamSize seem to be reasonably important. I believe feature selection plays a very important role in Tree based on models (not that they don't in others but perhaps even more important in this case). OK let's run predictions then re-submit to Kaggle to see if we can improve the score.</p>
</div>
<div class="cell border-box-sizing code_cell vbox">
<div class="input hbox">
<div class="prompt input_prompt">
In&nbsp;[43]:
</div>
<div class="input_area box-flex1">
<div class="highlight"><pre><span class="o">%%</span><span class="k">R</span>
<span class="c">#Derive predictions using our final LR model on the test set (this is NOT the test.csv file from Kaggle)</span>
<span class="n">rf</span><span class="o">.</span><span class="n">pred</span><span class="o">&lt;-</span><span class="n">predict</span><span class="p">(</span><span class="n">rf</span><span class="o">.</span><span class="n">tune2</span><span class="p">,</span> <span class="n">test</span><span class="o">.</span><span class="n">set</span><span class="p">)</span>

<span class="c">#Generate the confusion matrix</span>
<span class="n">confusionMatrix</span><span class="p">(</span><span class="n">rf</span><span class="o">.</span><span class="n">pred</span><span class="p">,</span> <span class="n">test</span><span class="o">.</span><span class="n">set</span><span class="err">$</span><span class="n">Survived</span><span class="p">)</span>
</pre></div>

</div>
</div>

<div class="vbox output_wrapper">
<div class="output vbox">


<div class="hbox output_area"><div class="prompt"></div>
<div class="box-flex1 output_subarea output_display_data">


<pre>
Confusion Matrix and Statistics

          Reference
Prediction  0  1
         0 98 20
         1 11 48
                                          
               Accuracy : 0.8249          
                 95% CI : (0.7607, 0.8778)
    No Information Rate : 0.6158          
    P-Value [Acc &gt; NIR] : 1.304e-09       
                                          
                  Kappa : 0.6204          
 Mcnemar&apos;s Test P-Value : 0.1508          
                                          
            Sensitivity : 0.8991          
            Specificity : 0.7059          
         Pos Pred Value : 0.8305          
         Neg Pred Value : 0.8136          
             Prevalence : 0.6158          
         Detection Rate : 0.5537          
   Detection Prevalence : 0.6667          
      Balanced Accuracy : 0.8025          
                                          
       &apos;Positive&apos; Class : 0               
                                          

</pre>

</div>
</div>

</div>
</div>

</div>
<div class="text_cell_render border-box-sizing rendered_html">
<p>No difference on predictions in our Test set. The sensitivity is the same. But let's try submitting to Kaggle anyway.</p>
</div>
<div class="cell border-box-sizing code_cell vbox">
<div class="input hbox">
<div class="prompt input_prompt">
In&nbsp;[44]:
</div>
<div class="input_area box-flex1">
<div class="highlight"><pre><span class="o">%%</span><span class="k">R</span>
<span class="c">#Generate predictions and write as a dataframe, then include PassengerID</span>
<span class="n">Survived</span><span class="o">&lt;-</span><span class="n">predict</span><span class="p">(</span><span class="n">rf</span><span class="o">.</span><span class="n">tune2</span><span class="p">,</span> <span class="n">kaggletest</span><span class="p">)</span>
<span class="n">rf</span><span class="o">.</span><span class="n">predictions</span><span class="o">&lt;-</span><span class="k">as</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">frame</span><span class="p">(</span><span class="n">Survived</span><span class="p">)</span>
<span class="n">rf</span><span class="o">.</span><span class="n">predictions</span><span class="err">$</span><span class="n">PassengerId</span><span class="o">&lt;-</span><span class="n">kaggletest</span><span class="err">$</span><span class="n">PassengerId</span>

<span class="c">#Write results as a CSV file</span>
<span class="n">write</span><span class="o">.</span><span class="n">csv</span><span class="p">(</span><span class="n">rf</span><span class="o">.</span><span class="n">predictions</span><span class="p">[,</span><span class="n">c</span><span class="p">(</span><span class="s">&#39;PassengerId&#39;</span><span class="p">,</span><span class="s">&#39;Survived&#39;</span><span class="p">)],</span> <span class="nb">file</span><span class="o">=</span><span class="s">&quot;RF_Titanic_Predictions.csv&quot;</span><span class="p">,</span> <span class="n">row</span><span class="o">.</span><span class="n">names</span><span class="o">=</span><span class="n">FALSE</span><span class="p">,</span> <span class="n">quote</span><span class="o">=</span><span class="n">FALSE</span><span class="p">)</span>
</pre></div>

</div>
</div>

</div>
<div class="text_cell_render border-box-sizing rendered_html">
<p>Guess what, we did make an improvement to the Kaggle score. This model scored <strong>0.78947</strong> bringing us to the top 1/3rd of the leaderboard. Since tree based models are giving us great results let's try one more, a very interesting model called <em>Conditional Trees</em>.</p>
<p><strong>Conditional Trees</strong><br />Conditional Tree based models supposedly tend to select variables that have many possible splits or many missing values. So instead of Random Forests which tries to find out which variables are important, using an information measure, these models perform sort of a significance test to see which features will yield the best results at each split. Let's give this a whirl.</p>
<p>Note that there are two Conditional Tree packages in caret (ctree, ctree2). We will be using ctree2 which allows us to tune the Max Depth, how deep the trees can grow.</p>
</div>
<div class="cell border-box-sizing code_cell vbox">
<div class="input hbox">
<div class="prompt input_prompt">
In&nbsp;[75]:
</div>
<div class="input_area box-flex1">
<div class="highlight"><pre><span class="o">%%</span><span class="k">R</span>
<span class="nb">set</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">35</span><span class="p">)</span> 

<span class="n">ctrgrid</span><span class="o">&lt;-</span><span class="n">data</span><span class="o">.</span><span class="n">frame</span><span class="p">(</span><span class="o">.</span><span class="n">maxdepth</span><span class="o">=</span><span class="n">c</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">4</span><span class="p">,</span><span class="mi">5</span><span class="p">,</span><span class="mi">6</span><span class="p">))</span>

<span class="c">#Training a Conditional Tree model</span>
<span class="n">ctr</span><span class="o">.</span><span class="n">tune1</span><span class="o">&lt;-</span><span class="n">train</span><span class="p">(</span><span class="n">Survived</span> <span class="o">~</span> <span class="n">Sex</span> <span class="o">+</span> <span class="n">Pclass</span> <span class="o">+</span> <span class="n">Age</span> <span class="o">+</span> <span class="n">SibSp</span> <span class="o">+</span> <span class="n">Embarked</span> <span class="o">+</span> <span class="n">FareGroup</span> <span class="o">+</span> <span class="n">Title</span> <span class="o">+</span> <span class="n">Child</span> <span class="o">+</span> <span class="n">FamSize</span> <span class="o">+</span> <span class="n">Parch</span><span class="p">,</span>
                <span class="n">data</span><span class="o">=</span><span class="n">train</span><span class="o">.</span><span class="n">set</span><span class="p">,</span>
                <span class="n">method</span><span class="o">=</span><span class="s">&#39;ctree2&#39;</span><span class="p">,</span>
                <span class="n">tuneGrid</span><span class="o">=</span><span class="n">ctrgrid</span><span class="p">,</span>
                <span class="n">trControl</span><span class="o">=</span><span class="n">tenfoldcv</span><span class="p">)</span>

<span class="n">ctr</span><span class="o">.</span><span class="n">tune1</span>
</pre></div>

</div>
</div>

<div class="vbox output_wrapper">
<div class="output vbox">


<div class="hbox output_area"><div class="prompt"></div>
<div class="box-flex1 output_subarea output_display_data">


<pre>
Conditional Inference Tree 

714 samples
 14 predictors
  2 classes: &apos;0&apos;, &apos;1&apos; 

No pre-processing
Resampling: Cross-Validated (10 fold, repeated 3 times) 

Summary of sample sizes: 643, 643, 643, 642, 643, 643, ... 

Resampling results across tuning parameters:

  maxdepth  Accuracy   Kappa      Accuracy SD  Kappa SD 
  2         0.7707812  0.4755401  0.04604332   0.1104954
  3         0.8077726  0.5855616  0.05702946   0.1237835
  4         0.8236502  0.6130369  0.05491988   0.1236674
  5         0.8194444  0.6055659  0.04897090   0.1102774
  6         0.8152061  0.5960590  0.05126715   0.1141253

Accuracy was used to select the optimal model using  the largest value.
The final value used for the model was maxdepth = 4. 

</pre>

</div>
</div>

</div>
</div>

</div>
<div class="text_cell_render border-box-sizing rendered_html">
<p>OK that did give us a better accuracy at Max Depth 4. Before we run predictions, let's visualize the tree that was built for the final model.</p>
</div>
<div class="cell border-box-sizing code_cell vbox">
<div class="input hbox">
<div class="prompt input_prompt">
In&nbsp;[115]:
</div>
<div class="input_area box-flex1">
<div class="highlight"><pre><span class="o">%%</span><span class="k">R</span>
<span class="n">plot</span><span class="p">(</span><span class="n">ctr</span><span class="o">.</span><span class="n">tune1</span><span class="err">$</span><span class="n">finalModel</span><span class="p">)</span>
</pre></div>

</div>
</div>

<div class="vbox output_wrapper">
<div class="output vbox">


<div class="hbox output_area"><div class="prompt"></div>
<div class="box-flex1 output_subarea output_display_data">


<img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAeAAAAHgCAMAAABKCk6nAAADAFBMVEUAAAABAQECAgIDAwMEBAQF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==
">

</div>
</div>

</div>
</div>

</div>
<div class="text_cell_render border-box-sizing rendered_html">
<p>We can observe here that Sexmale as expected was the starting node. From then on, Pclass and TitleMr took the honors for level 2 leading further then to the other variables. We're now ready to evaluate the model and run the predictions.</p>
<p><strong>Model Evaluation - Conditional Trees</strong></p>
</div>
<div class="cell border-box-sizing code_cell vbox">
<div class="input hbox">
<div class="prompt input_prompt">
In&nbsp;[76]:
</div>
<div class="input_area box-flex1">
<div class="highlight"><pre><span class="o">%%</span><span class="k">R</span>
<span class="c">#Derive predictions using our final LR model on the test set (this is NOT the test.csv file from Kaggle)</span>
<span class="n">ctr</span><span class="o">.</span><span class="n">pred</span><span class="o">&lt;-</span><span class="n">predict</span><span class="p">(</span><span class="n">ctr</span><span class="o">.</span><span class="n">tune1</span><span class="p">,</span> <span class="n">test</span><span class="o">.</span><span class="n">set</span><span class="p">)</span>

<span class="c">#Generate the confusion matrix</span>
<span class="n">confusionMatrix</span><span class="p">(</span><span class="n">ctr</span><span class="o">.</span><span class="n">pred</span><span class="p">,</span> <span class="n">test</span><span class="o">.</span><span class="n">set</span><span class="err">$</span><span class="n">Survived</span><span class="p">)</span>
</pre></div>

</div>
</div>

<div class="vbox output_wrapper">
<div class="output vbox">


<div class="hbox output_area"><div class="prompt"></div>
<div class="box-flex1 output_subarea output_display_data">


<pre>
Confusion Matrix and Statistics

          Reference
Prediction   0   1
         0 102  19
         1   7  49
                                          
               Accuracy : 0.8531          
                 95% CI : (0.7922, 0.9017)
    No Information Rate : 0.6158          
    P-Value [Acc &gt; NIR] : 3.506e-12       
                                          
                  Kappa : 0.6789          
 Mcnemar&apos;s Test P-Value : 0.03098         
                                          
            Sensitivity : 0.9358          
            Specificity : 0.7206          
         Pos Pred Value : 0.8430          
         Neg Pred Value : 0.8750          
             Prevalence : 0.6158          
         Detection Rate : 0.5763          
   Detection Prevalence : 0.6836          
      Balanced Accuracy : 0.8282          
                                          
       &apos;Positive&apos; Class : 0               
                                          

</pre>

</div>
</div>

</div>
</div>

</div>
<div class="text_cell_render border-box-sizing rendered_html">
<p>So that gave us a better Specificity on the Test set at 72.06%. I am interested to see how this tests out at Kaggle.</p>
<p><strong>Submit to Kaggle</strong></p>
</div>
<div class="cell border-box-sizing code_cell vbox">
<div class="input hbox">
<div class="prompt input_prompt">
In&nbsp;[91]:
</div>
<div class="input_area box-flex1">
<div class="highlight"><pre><span class="o">%%</span><span class="k">R</span>
<span class="c">#Generate predictions and write as a dataframe, then include PassengerID</span>
<span class="n">Survived</span><span class="o">&lt;-</span><span class="n">predict</span><span class="p">(</span><span class="n">ctr</span><span class="o">.</span><span class="n">tune1</span><span class="p">,</span> <span class="n">kaggletest</span><span class="p">)</span>
<span class="n">ctr</span><span class="o">.</span><span class="n">predictions</span><span class="o">&lt;-</span><span class="k">as</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">frame</span><span class="p">(</span><span class="n">Survived</span><span class="p">)</span>
<span class="n">ctr</span><span class="o">.</span><span class="n">predictions</span><span class="err">$</span><span class="n">PassengerId</span><span class="o">&lt;-</span><span class="n">kaggletest</span><span class="err">$</span><span class="n">PassengerId</span>

<span class="c">#Write results as a CSV file</span>
<span class="n">write</span><span class="o">.</span><span class="n">csv</span><span class="p">(</span><span class="n">ctr</span><span class="o">.</span><span class="n">predictions</span><span class="p">[,</span><span class="n">c</span><span class="p">(</span><span class="s">&#39;PassengerId&#39;</span><span class="p">,</span><span class="s">&#39;Survived&#39;</span><span class="p">)],</span> <span class="nb">file</span><span class="o">=</span><span class="s">&quot;CTR_Titanic_Predictions.csv&quot;</span><span class="p">,</span> <span class="n">row</span><span class="o">.</span><span class="n">names</span><span class="o">=</span><span class="n">FALSE</span><span class="p">,</span> <span class="n">quote</span><span class="o">=</span><span class="n">FALSE</span><span class="p">)</span>
</pre></div>

</div>
</div>

</div>
<div class="text_cell_render border-box-sizing rendered_html">
<p>The model scored <strong>0.77512</strong> which is actually slightly worse than how Random Forests did. So the best model in terms of the Kaggle leaderboard has been Random Forests. But let's run a formal comparison of all the models we've built so far.</p>
</div>
<div class="text_cell_render border-box-sizing rendered_html">
<p><strong>Model Comparison</strong><br />The resamples method in the caret package makes it easy to compare results between different models.</p>
</div>
<div class="cell border-box-sizing code_cell vbox">
<div class="input hbox">
<div class="prompt input_prompt">
In&nbsp;[126]:
</div>
<div class="input_area box-flex1">
<div class="highlight"><pre><span class="o">%%</span><span class="k">R</span>
<span class="n">modelcompare</span><span class="o">&lt;-</span><span class="n">resamples</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">Logit</span> <span class="o">=</span> <span class="n">logit</span><span class="o">.</span><span class="n">tune6</span><span class="p">,</span> <span class="n">SVM</span> <span class="o">=</span> <span class="n">svm</span><span class="o">.</span><span class="n">tune1</span><span class="p">,</span> <span class="n">RF</span> <span class="o">=</span> <span class="n">rf</span><span class="o">.</span><span class="n">tune2</span><span class="p">,</span> <span class="n">CTREE</span> <span class="o">=</span> <span class="n">ctr</span><span class="o">.</span><span class="n">tune1</span> <span class="p">))</span>
<span class="n">summary</span><span class="p">(</span><span class="n">modelcompare</span><span class="p">)</span>
</pre></div>

</div>
</div>

<div class="vbox output_wrapper">
<div class="output vbox">


<div class="hbox output_area"><div class="prompt"></div>
<div class="box-flex1 output_subarea output_display_data">


<pre>

Call:
summary.resamples(object = modelcompare)

Models: Logit, SVM, RF, CTREE 
Number of resamples: 24 

Accuracy 
        Min. 1st Qu. Median   Mean 3rd Qu.   Max. NA&apos;s
Logit 0.7465  0.7887 0.8042 0.8145  0.8333 0.9437    0
SVM   0.7606  0.7778 0.8042 0.8244  0.8677 0.9296    0
RF    0.7606  0.7917 0.8182 0.8250  0.8592 0.9155    0
CTREE 0.7361  0.7770 0.8099 0.8216  0.8502 0.9577    0

Kappa 
        Min. 1st Qu. Median   Mean 3rd Qu.   Max. NA&apos;s
Logit 0.4295  0.5334 0.5747 0.5969  0.6505 0.8787    0
SVM   0.4570  0.5146 0.5612 0.6149  0.7173 0.8495    0
RF    0.4652  0.5392 0.6140 0.6195  0.7012 0.8232    0
CTREE 0.4338  0.5003 0.5771 0.6083  0.6847 0.9097    0


</pre>

</div>
</div>

</div>
</div>

</div>
<div class="text_cell_render border-box-sizing rendered_html">
<p>We can see that for the metric we chose (Accuracy), Random Forests outperformed the other models. Note here that we could've chosen ROC (Receiver Operating Characteristic) as the metric in which case, we'd have needed to generate class probabilties - that is, probability for survived/not survived for every data item rather than letting crossvalidation generate predictions automatically. I intend to learn and demonstrate these concepts in a seperate session. For now, let's plot the results in a couple of different ways.</p>
<p><strong>Box Plot of Model Comparison Results</strong></p>
</div>
<div class="cell border-box-sizing code_cell vbox">
<div class="input hbox">
<div class="prompt input_prompt">
In&nbsp;[128]:
</div>
<div class="input_area box-flex1">
<div class="highlight"><pre><span class="o">%%</span><span class="k">R</span>
<span class="n">bwplot</span><span class="p">(</span><span class="n">modelcompare</span><span class="p">)</span>
</pre></div>

</div>
</div>

<div class="vbox output_wrapper">
<div class="output vbox">


<div class="hbox output_area"><div class="prompt"></div>
<div class="box-flex1 output_subarea output_display_data">


<img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAeAAAAHgCAIAAADytinCAAAgAElEQVR4nO3deUBVdf7/8feFK4oI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">

</div>
</div>

</div>
</div>

</div>
<div class="text_cell_render border-box-sizing rendered_html">
<p><strong>Dot Plot of Model Comparison Results</strong></p>
</div>
<div class="cell border-box-sizing code_cell vbox">
<div class="input hbox">
<div class="prompt input_prompt">
In&nbsp;[129]:
</div>
<div class="input_area box-flex1">
<div class="highlight"><pre><span class="o">%%</span><span class="k">R</span>
<span class="n">dotplot</span><span class="p">(</span><span class="n">modelcompare</span><span class="p">)</span>
</pre></div>

</div>
</div>

<div class="vbox output_wrapper">
<div class="output vbox">


<div class="hbox output_area"><div class="prompt"></div>
<div class="box-flex1 output_subarea output_display_data">


<img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAeAAAAHgCAIAAADytinCAAAgAElEQVR4nO3deVyVdfr/8YvDAWRX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">

</div>
</div>

</div>
</div>

</div>
<div class="text_cell_render border-box-sizing rendered_html">
<p>So there you have it. We took the Titanic dataset presented by Kaggle, imported and visualized the data in a series of plots, munged the data to address gaps and fitted 4 different models with varying results, all in R, special thanks to the caret package. We only managed to get up to 0.7894 on the Kaggle leaderboard but the point of this exercise was to learn and demonstrate machine learning concepts in R. Hope we've achieved that objective.</p>
<p>I will be happy to receive your feedback positive or negative but try to be nice, I am just learning :-)</p>
</div>